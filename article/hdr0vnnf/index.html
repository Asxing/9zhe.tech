<!doctype html><html lang="zh-CN"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="generator" content="VuePress 2.0.0-rc.24" /><meta name="theme" content="VuePress Theme Plume 1.0.0-rc.162" /><script id="check-mac-os">document.documentElement.classList.toggle('mac', /Mac|iPhone|iPod|iPad/i.test(navigator.platform))</script><script id="check-dark-mode">;(function () {const um= localStorage.getItem('vuepress-theme-appearance') || 'auto';const sm = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;const isDark = um === 'dark' || (um !== 'light' && sm);document.documentElement.dataset.theme = isDark ? 'dark' : 'light';})();</script><title>第5章 推理 (Inference) | 面试造飞机-九折技术</title><meta name="description" content="ai,后端,架构,软件开发"><link rel="preload" href="/assets/style-FHgMeouG.css" as="style"><link rel="stylesheet" href="/assets/style-FHgMeouG.css"><link rel="modulepreload" href="/assets/app-zSjPkmgN.js"><link rel="modulepreload" href="/assets/index.html-BrcRTbiv.js"><link rel="prefetch" href="/assets/index.html-CruQpEFZ.js" as="script"><link rel="prefetch" href="/assets/index.html-C3juNrAA.js" as="script"><link rel="prefetch" href="/assets/index.html-WrrmR-U6.js" as="script"><link rel="prefetch" href="/assets/index.html-BxKeGKpB.js" as="script"><link rel="prefetch" href="/assets/index.html-CVFnxwcH.js" as="script"><link rel="prefetch" href="/assets/index.html-DyFE7D4j.js" as="script"><link rel="prefetch" href="/assets/index.html-CU-jv3Kb.js" as="script"><link rel="prefetch" href="/assets/index.html-DtoVbmm-.js" as="script"><link rel="prefetch" href="/assets/index.html-CSuHdEn8.js" as="script"><link rel="prefetch" href="/assets/index.html-B03GQmlV.js" as="script"><link rel="prefetch" href="/assets/index.html-C_ujFDxu.js" as="script"><link rel="prefetch" href="/assets/index.html-D9z3Kqwm.js" as="script"><link rel="prefetch" href="/assets/index.html-joW4Z0Yz.js" as="script"><link rel="prefetch" href="/assets/index.html-9rBiEy0v.js" as="script"><link rel="prefetch" href="/assets/index.html-ha9O2sKE.js" as="script"><link rel="prefetch" href="/assets/index.html-C6djjmAd.js" as="script"><link rel="prefetch" href="/assets/index.html-BzJwyU71.js" as="script"><link rel="prefetch" href="/assets/index.html-CO5JHRFv.js" as="script"><link rel="prefetch" href="/assets/404.html-DomZmev8.js" as="script"><link rel="prefetch" href="/assets/index.html-CruQpEFZ.js" as="script"><link rel="prefetch" href="/assets/index.html-BogfM7G9.js" as="script"><link rel="prefetch" href="/assets/index.html-D2dpQlUH.js" as="script"><link rel="prefetch" href="/assets/index.html-ChsxAPN0.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-CKV1Bsxh.js" as="script"><link rel="prefetch" href="/assets/searchBox-default-U0PWlw1-.js" as="script"><link rel="prefetch" href="/assets/SearchBox-kfhR2hJN.js" as="script"></head><body><div id="app"><!--[--><!--[--><div class="theme-plume vp-layout" vp-container data-v-f306e958><!--[--><!--[--><!--]--><!--[--><span tabindex="-1" data-v-b503e7b0></span><a href="#VPContent" class="vp-skip-link visually-hidden" data-v-b503e7b0> Skip to content </a><!--]--><!----><header class="vp-nav" data-v-f306e958 data-v-5271e5e5><div class="vp-navbar" vp-navbar data-v-5271e5e5 data-v-f21177fa><div class="wrapper" data-v-f21177fa><div class="container" data-v-f21177fa><div class="title" data-v-f21177fa><div class="vp-navbar-title" data-v-f21177fa data-v-15b374d8><a class="vp-link link no-icon title" href="/" data-v-15b374d8><!--[--><!--[--><!--]--><!----><span data-v-15b374d8>面试造飞机-九折技术</span><!--[--><!--]--><!--]--><!----></a></div></div><div class="content" data-v-f21177fa><div class="content-body" data-v-f21177fa><!--[--><!--]--><div class="vp-navbar-search search" data-v-f21177fa><div class="search-wrapper" data-v-bc840d77><!----><div id="local-search" data-v-bc840d77><button type="button" class="mini-search mini-search-button" aria-label="搜索文档" data-v-bc840d77><span class="mini-search-button-container"><span class="mini-search-search-icon vpi-mini-search" aria-label="search icon"></span><span class="mini-search-button-placeholder">搜索文档</span></span><span class="mini-search-button-keys"><kbd class="mini-search-button-key"></kbd><kbd class="mini-search-button-key">K</kbd></span></button></div></div></div><!--[--><!--]--><nav aria-labelledby="main-nav-aria-label" class="vp-navbar-menu menu" data-v-f21177fa data-v-43aff82f><span id="main-nav-aria-label" class="visually-hidden" data-v-43aff82f>Main Navigation</span><!--[--><!--[--><a class="vp-link link navbar-menu-link" href="/" tabindex="0" data-v-43aff82f data-v-4bb27b21><!--[--><!----><span data-v-4bb27b21>首页</span><!----><!--]--><!----></a><!--]--><!--[--><a class="vp-link link navbar-menu-link" href="/ai/" tabindex="0" data-v-43aff82f data-v-4bb27b21><!--[--><!----><span data-v-4bb27b21>AI技术</span><!----><!--]--><!----></a><!--]--><!--[--><a class="vp-link link navbar-menu-link" href="/backend/" tabindex="0" data-v-43aff82f data-v-4bb27b21><!--[--><!----><span data-v-4bb27b21>后端技术</span><!----><!--]--><!----></a><!--]--><!--[--><a class="vp-link link navbar-menu-link" href="/architecture/" tabindex="0" data-v-43aff82f data-v-4bb27b21><!--[--><!----><span data-v-4bb27b21>架构设计</span><!----><!--]--><!----></a><!--]--><!--[--><a class="vp-link link navbar-menu-link" href="/about/" tabindex="0" data-v-43aff82f data-v-4bb27b21><!--[--><!----><span data-v-4bb27b21>关于</span><!----><!--]--><!----></a><!--]--><!--[--><a class="vp-link link navbar-menu-link" href="/friends/" tabindex="0" data-v-43aff82f data-v-4bb27b21><!--[--><!----><span data-v-4bb27b21>友链</span><!----><!--]--><!----></a><!--]--><!--]--></nav><!--[--><!--]--><!----><div class="vp-navbar-appearance appearance" data-v-f21177fa data-v-119dc5f3><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-119dc5f3 data-v-33c3ff14 data-v-918f75ba><span class="check" data-v-918f75ba><span class="icon" data-v-918f75ba><!--[--><span class="vpi-sun sun" data-v-33c3ff14></span><span class="vpi-moon moon" data-v-33c3ff14></span><!--]--></span></span></button></div><!----><div class="vp-flyout vp-navbar-extra extra" data-v-f21177fa data-v-e7760ed7 data-v-c6e51e23><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-c6e51e23><span class="vpi-more-horizontal icon" data-v-c6e51e23></span></button><div class="menu" data-v-c6e51e23><div class="vp-menu" data-v-c6e51e23 data-v-b9b06af5><!----><!--[--><!--[--><!----><div class="group" data-v-e7760ed7><div class="item appearance" data-v-e7760ed7><p class="label" data-v-e7760ed7>外观</p><div class="appearance-action" data-v-e7760ed7><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-e7760ed7 data-v-33c3ff14 data-v-918f75ba><span class="check" data-v-918f75ba><span class="icon" data-v-918f75ba><!--[--><span class="vpi-sun sun" data-v-33c3ff14></span><span class="vpi-moon moon" data-v-33c3ff14></span><!--]--></span></span></button></div></div></div><!----><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="vp-navbar-hamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="nav-screen" data-v-f21177fa data-v-3190614d><span class="container" data-v-3190614d><span class="top" data-v-3190614d></span><span class="middle" data-v-3190614d></span><span class="bottom" data-v-3190614d></span></span></button></div></div></div></div><div class="divider" data-v-f21177fa><div class="divider-line" data-v-f21177fa></div></div></div><!----></header><div class="vp-local-nav fixed reached-top is-blog" data-v-f306e958 data-v-394b6917><button class="hidden menu" disabled aria-expanded="false" aria-controls="SidebarNav" data-v-394b6917><span class="vpi-align-left menu-icon" data-v-394b6917></span><span class="menu-text" data-v-394b6917>Menu</span></button><div class="vp-local-nav-outline-dropdown" style="--vp-vh:0px;" data-v-394b6917 data-v-46264cb5><button data-v-46264cb5>返回顶部</button><!----></div></div><!----><!--[--><div id="VPContent" vp-content class="vp-content" data-v-f306e958 data-v-d7cb234b><div class="vp-doc-container is-blog" data-v-d7cb234b data-v-15e751aa><!--[--><!--]--><div class="container" data-v-15e751aa><!----><div class="content" data-v-15e751aa><div class="content-container" data-v-15e751aa><!--[--><!--]--><main class="main" data-v-15e751aa><nav class="vp-breadcrumb" data-v-15e751aa data-v-118230fd><ol vocab="https://schema.org/" typeof="BreadcrumbList" data-v-118230fd><!--[--><li property="itemListElement" typeof="ListItem" data-v-118230fd><a class="vp-link link breadcrumb" href="/" property="item" typeof="WebPage" data-v-118230fd><!--[-->首页<!--]--><!----></a><span class="vpi-chevron-right" data-v-118230fd></span><meta property="name" content="首页" data-v-118230fd><meta property="position" content="1" data-v-118230fd></li><li property="itemListElement" typeof="ListItem" data-v-118230fd><a class="vp-link link breadcrumb" href="/" property="item" typeof="WebPage" data-v-118230fd><!--[-->博客<!--]--><!----></a><span class="vpi-chevron-right" data-v-118230fd></span><meta property="name" content="博客" data-v-118230fd><meta property="position" content="2" data-v-118230fd></li><li property="itemListElement" typeof="ListItem" data-v-118230fd><a class="vp-link link breadcrumb" href="/blog/categories/?id=4921c0" property="item" typeof="WebPage" data-v-118230fd><!--[-->ai<!--]--><!----></a><span class="vpi-chevron-right" data-v-118230fd></span><meta property="name" content="ai" data-v-118230fd><meta property="position" content="3" data-v-118230fd></li><li property="itemListElement" typeof="ListItem" data-v-118230fd><a class="vp-link link breadcrumb" href="/blog/categories/?id=4a7c22" property="item" typeof="WebPage" data-v-118230fd><!--[-->foundations-of-llms<!--]--><!----></a><span class="vpi-chevron-right" data-v-118230fd></span><meta property="name" content="foundations-of-llms" data-v-118230fd><meta property="position" content="4" data-v-118230fd></li><li property="itemListElement" typeof="ListItem" data-v-118230fd><a class="vp-link link breadcrumb current" href="/article/hdr0vnnf/" property="item" typeof="WebPage" data-v-118230fd><!--[-->第5章 推理 (Inference)<!--]--><!----></a><!----><meta property="name" content="第5章 推理 (Inference)" data-v-118230fd><meta property="position" content="5" data-v-118230fd></li><!--]--></ol></nav><!--[--><!--]--><!--[--><h1 class="vp-doc-title page-title" data-v-0d4fd2de><!----> 第5章 推理 (Inference) <!----></h1><div class="vp-doc-meta" data-v-0d4fd2de><!--[--><!--]--><p class="reading-time" data-v-0d4fd2de><span class="vpi-books icon" data-v-0d4fd2de></span><span data-v-0d4fd2de>约 7452 字</span><span data-v-0d4fd2de>大约 25 分钟</span></p><!----><!--[--><!--]--><p class="create-time" data-v-0d4fd2de><span class="vpi-clock icon" data-v-0d4fd2de></span><span data-v-0d4fd2de>2025-10-05</span></p></div><!--]--><!--[--><!--]--><div class="_article_hdr0vnnf_ external-link-icon-enabled vp-doc plume-content" vp-content data-v-15e751aa><!--[--><!--]--><div data-v-15e751aa><h2 id="第-5-章-推理" tabindex="-1"><a class="header-anchor" href="#第-5-章-推理"><span><strong>第 5 章 推理</strong></span></a></h2><div class="language-mermaid line-numbers-mode" data-highlighter="shiki" data-ext="mermaid" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-mermaid"><span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">mindmap</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">  root((第5章 推理))</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    框架</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      两阶段</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        预填充</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">          上下文编码</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">          KV建立</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        解码</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">          逐步生成</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">          KV复用</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      资源侧重点</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        预填充算力受限</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        解码内存与搜索受限</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    解码策略</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      确定式</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        贪婪</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        束搜索</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">          束宽选择</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">          长度正则</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      采样式</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        Top k</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        Top p</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        温度</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        多样化采样</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      约束控制</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        重复惩罚</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        语法约束</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        结构模板</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    高效推理</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      缓存技术</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        KV分页</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        滑动窗口</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        应用级缓存</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      批处理</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        连续批处理</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        长度分组</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        动态调度</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      并行与加速</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        张量并行</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        流水并行</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        多机并行</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        量化</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        编译优化</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        推测式解码</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    推理时扩展</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      上下文扩展</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        ICL示例</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        CoT提示</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        RAG证据</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      搜索扩展</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        更宽搜索</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        更长思维链</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      输出集成</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        多候选投票</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        重排序融合</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      生成与验证</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        路径生成</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        一致性检查</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        事实校验</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    调度与系统</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      目标函数</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        延迟</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        吞吐</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        成本</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      策略组合</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        预填充解耦</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        多路复用</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        优先级队列</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    评估与权衡</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      质量</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        准确</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        可读</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        一致</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      效率</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        P50延迟</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        P95延迟</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        QPS</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      成本</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        单位token</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        显存占用</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      稳定</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        失败率</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        超时率</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    风险与防护</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      中间丢失</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        片段重排</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        关键句靠近两端</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      量化掉质</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        混合精度</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        校准集合</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">      批过大</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        尾延迟限制</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">        动态批尺寸</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="预填充与解码" tabindex="-1"><a class="header-anchor" href="#预填充与解码"><span><strong>预填充与解码</strong></span></a></h3><p><strong>解释：</strong> 大语言模型的<strong>推理</strong>，指的是它生成文本答案的过程。在技术上通常把这个过程划分为两个阶段：<strong>预填充 (Prefill)</strong> 和<strong>解码 (Decode)</strong> 。打个比方，我们可以把 LLM 想象成一个接龙写故事的人：</p><ul><li>在预填充阶段，模型先<strong>读完输入</strong>（比如你问的问题或给的前文），就像人在正式回答前先把题目或已有内容看懂。这一步模型会把输入通过其 Transformer 层编码，存储成一种内部状态，类似于我们把题目记在脑子里 。技术上，这常通过<strong>KV 缓存</strong>实现：模型对输入序列做一次前向计算，把产生的键值对缓存下来 。这样做的好处是，在后续生成时不用每次都重新处理整个输入，节省了大量计算 。</li><li>在解码阶段，模型开始<strong>一个字（token）接一个字地生成</strong>输出 。它会利用预填充阶段存下的“记忆”（KV 缓存）和已经生成的部分，不断预测下一个可能的词。这个过程是自回归的：每产生一个词，就把它也加入上下文，然后预测下一个，直到遇到终止条件（比如生成了句号或特殊结束符）。解码的目标是在庞大的可能续写中找到一条高概率且合适的序列 。可以说，预填充相当于“大脑蓄力”，解码则是“大显身手”。</li></ul><p><strong>解码算法</strong>决定了模型究竟如何选择每一步的输出 。常见的几种策略：</p><ul><li><strong>贪婪搜索 (Greedy)：</strong> 每一步都选取概率最高的下一个词 。这种方法最快也最确定，生成的文本往往<strong>最平淡常见</strong>（因为模型老选最可能的词）。类比来说，这是最保守的策略，好比每次考试都写老师最想看到的标准答案。但它的缺点是如果某一步有局部最优，会错失全局更优解，可能导致内容<strong>缺乏创意</strong>或重复。此外，一旦某步选错，后面无法反悔纠正。</li><li><strong>束搜索 (Beam Search)：</strong> 同时保留多个候选输出序列，在每一步扩展这些候选，再只保留前 k 个最有希望的，直到完成  。这有点像走迷宫时一箭多雕，平行探索几条路线，希望至少一条能走到宝藏。束搜索在翻译等任务中常用，输出质量往往比贪婪高一些。然而对于非常开放的生成任务（如写故事），束搜索倾向于收敛在相似的高概率套路上，依然<strong>缺乏多样性</strong>。而且 k 太大会消耗计算，k 太小则作用有限，所以要权衡效率和效果 。</li><li><strong>随机采样 (Sampling)：</strong> 给输出引入随机性，而不是总选最优。具体实现有<strong>Top-k 采样</strong>和<strong>Top-p 采样</strong>等  。Top-k 采样是每步从概率前 k 的词中随机选一个，Top-p（又称<strong>核采样</strong>）是从累积概率达到 p（如 0.9）的词集合里选  。这样可以保证不选那些罕见得离谱的词，又保留一定<strong>惊喜</strong>。比如让模型写诗歌或讲笑话，引入随机能产生更多样化、有创造性的结果。同时我们可以调节<strong>温度 (temperature)</strong> 参数控制随机程度：温度高，则概率分布变平，更随机；温度低，模型输出更确定趋于贪婪  。简单说，温度=0 等同贪婪，温度很高相当于每次基本骰子决定下个词。因此采样法能让生成既连贯又有变化，但过高的随机性可能使输出语无伦次，需要把握平衡。</li></ul><p>此外还有<strong>重复惩罚</strong>、<strong>禁止词约束</strong>等技巧，可在解码时扣掉模型生成重复短语或不良词汇的概率，保证输出既不啰嗦也不触雷 。例如，给定 Penalty 函数专门打压那些违背安全规范的输出，模型在解码中会主动避开不当内容 。</p><p>总结一下，解码阶段其实是在做一个搜索问题：模型预测下一个词的概率分布，但要在指数级的可能序列空间里找一条<strong>既合理又满足需要</strong>的路径。不同算法就是不同的“寻路策略”。<strong>没有一种算法适用于所有场景</strong>：生成新闻概要可能需要稳健（低温度或束搜索），而写小说则需要丰富（高温度采样）。好的应用会根据任务选择或混合使用这些策略，让 LLM 发挥最佳水平。</p><p><strong>小结：</strong> 预填充-解码框架让我们理解了 LLM 生成文字的内在流程：先读懂输入再逐步写出回答 。在解码过程中，不同策略影响了<strong>创造性 vs 准确性</strong>的平衡。贪婪搜索快但保守，束搜索更全面探索，随机采样赋予创造力，温度和 Top-k/p 提供调节旋钮。通过调整解码算法，我们可以让同一个模型既能严谨答题，也能妙笔生花。推理阶段还可以引入额外约束，以确保输出不违背设定的要求（比如避免不良词汇）。对于学习者而言，掌握这些解码策略，就好比掌握了<strong>调控 AI 说话风格的遥控器</strong>，能更好地驱动模型输出符合期望的内容。</p><p><strong>实例：</strong> 让我们用一个句子预测的例子来直观感受不同解码策略。假设输入是“机器学习使生活…”。如果用贪婪搜索，模型可能接着输出“更美好”，因为这是最高频的延续，最终句子可能是“机器学习使生活更美好。” 用束搜索(k=3)也许也会得出类似的，因为“更方便”“更智能”这些都有较高概率，束搜索会比较这些完整句子的总概率，可能仍然选“更美好”。如果用 Top-p 采样(p=0.9)，模型也许会尝试一些不一样的词，比如“更有趣”或“更加便利”，有一定随机性但不会太离谱。如果把温度调高，模型甚至可能说出“机器学习使生活变成一场游戏”，更具有奇思妙想的色彩。这展示了<strong>同一个模型</strong>在不同解码策略下风格迥异：严格策略下措辞安全中规中矩，随机策略下可能产生让人耳目一新的句子。当然，过高随机度下，它可能胡说“机器学习使生活充满樱桃味”，这就偏离常理了。这就是为什么我们需要平衡，让模型输出<strong>既合理又不千篇一律</strong>。</p><p><strong>引导性问题：</strong> 你觉得在哪些应用场景下需要引入随机性增强创造力，哪些场景下则必须用确定性方法？如果模型每次都选最高概率词，会发生什么问题（比如重复或卡住在某个循环）？当我们设置一个很低的温度时，模型输出和高温度相比有何明显区别，为什么？</p><p><strong>可视化建议：</strong> 可以设计一个<strong>解码树形图</strong>：起始节点是模型读入的 Prompt，然后分叉代表每一步可能的下一个词，树上标注不同搜索策略如何遍历这棵树（如贪婪是一条直线走，束搜索是几条平行前进，随机采样是在高概率子树里随机跳）。也可以做一个<strong>小实验图表</strong>：用相同开头让模型在不同温度下生成句子，把结果并排展示。例如温度 0、0.7、1.2 下模型生成三句话的对比，用颜色标出不同行为（重复/新颖），帮助理解温度影响。</p><h3 id="高效推理技术" tabindex="-1"><a class="header-anchor" href="#高效推理技术"><span><strong>高效推理技术</strong></span></a></h3><p><strong>解释：</strong> 当我们把 LLM 用于真实应用时，响应速度和资源占用是非常关键的。高效推理技术关注如何<strong>让模型尽快给出答案、用更少的内存和计算</strong> 。考虑这样一个比喻：如果 LLM 回答问题是一家披萨店做披萨，高效推理就是想办法提升出餐速度、减少浪费。以下是主要的高效推理策略：</p><ul><li><strong>更多缓存 (KV Cache)：</strong> 前面提到过，Transformer 模型在生成时会不断用到之前的计算结果。<strong>键-值缓存</strong>技术就是在第一次计算时把每一层的中间表示存下来，后续生成新词时重复利用  。现实意义是，例如在对话中，你问了长长一段话，模型回答第一句时已经处理过这段话；当模型回答第二句时，不需要再把你的长问题过一遍，而是用上次缓存，加快运算。另一个缓存思路是在<strong>应用级别</strong>做缓存：把用户常问的问题及对应答案存在数据库里，下次遇到同样请求直接返回已有答案 。这就好像披萨店把热门披萨先做好一批，顾客一来立刻取出。不用每次都现做，自然更快。需要注意缓存的命中率：只有用户请求重复或相似时缓存才发挥作用 。但在实际系统，比如客服问答里，常见问题缓存可以极大减少模型调用次数，提升效率。</li><li><strong>批处理 (Batching)：</strong> 现代硬件（尤其 GPU）擅长同时处理并行任务。批处理就是把<strong>多个输入一起交给模型</strong>，利用并行计算提升吞吐量 。这有点像披萨店同时烤多张披萨，每张披萨的等待时间并不会线性增加。对于 LLM，如果有 10 个请求，每个单独处理可能要 10 秒总计；但批处理一起处理，可能仍然接近 10 秒就都完成了，而不是 100 秒。批处理的难点在于对齐不同长度的输入/输出：通常需要用填充（padding）使它们并行计算齐头并进。尽管每个请求的<strong>延迟</strong>可能略有上升（因为要等一批凑满或最长的那个完成），但总体<strong>吞吐</strong>高了许多。因此对于同时大量请求的场景（比如 API 服务高峰），批处理能显著降低单位请求的计算成本。开发者经常要在批大小和延迟之间做权衡，找到性价比最佳点。</li><li><strong>并行化 (Parallelism)：</strong> 当模型本身很大，单块 GPU 放不下或者算不动时，就需要把模型计算<strong>分拆到多块设备</strong>并行完成 。并行化有多种：<strong>模型并行</strong>将模型不同层分给不同 GPU，流水线式计算；<strong>张量并行</strong>把每层内部的矩阵拆分到多 GPU 计算再合并；还有<strong>专家模型并行</strong>等等。简单打个比方，如果模型是一本 1000 页的书，一台机器读可能很慢，那让 10 台机器各读 100 页，最后把结果汇总，就快很多。并行化需要解决设备间通信和同步问题，好比多人协作时要互相传递结果，可能会有一些额外开销  。但对于超大模型，这是唯一可行的方法。例如 GPT-3 175B 参数，需要多个 GPU 共同存储计算，否则单 GPU 内存根本装不下全部参数。并行化也可以用于<strong>多节点多机</strong>，构成分布式推理。总之，通过横向扩展硬件，让多份资源共同完成任务，可以线性缩短推理时间（理想情况下），使大模型的响应不至于慢得无法使用。</li><li><strong>量化和剪枝：</strong> 另一类高效技术是减少计算本身的工作量，比如把模型参数从 32 位精度降到 8 位（量化），或者剪掉一些影响小的神经元连接。量化就好比用简略版菜谱做披萨，可能味道几乎一样，但步骤更简洁省料。实践中，量化可以极大降低模型内存占用和计算量（因为低精度乘法更快），代价是可能损失一点点精度。不过对 LLM 来说，经过精心校准的量化（如 4-bit 量化）往往几乎不损伤模型效果，却能把运行成本降很多。目前许多开源模型通过量化在消费级 GPU 上实现了较快推理。模型剪枝则是删除不重要的权重或神经元，让模型“瘦身”，加速推理。这在学术上有研究，但在 LLM 上大规模剪枝可能影响性能，因此更常用的是量化。</li><li><strong>其它加速策略：</strong> 例如<strong>编译优化</strong>（用专门的深度学习编译器或 GPU kernel 提升计算效率）、<strong>异步并行</strong>（生成过程中一边计算下一步一边传输之前结果）、<strong>流水线推理</strong>（不同层同时处理不同 token，如生产线一样）。还有利用<strong>硬件加速器</strong>（如 TPU、ASIC）专门针对 Transformer 结构优化。这些都属于工程层面的改进，把模型的推理速度尽可能榨干硬件能力。对使用者而言不需要深入了解原理，只需知道通过软硬件优化，可以显著缩短模型响应时间、降低每次调用成本。</li></ul><p><strong>小结：</strong> 高效推理技术是保证 LLM 应用<strong>实用化</strong>的关键。缓存让重复计算最小化（就像不重做已经做过的功课） ；批处理和并行化充分利用硬件并行能力，“人多力量大”加快处理；量化剪枝让模型精简，跑得更快更省；各种优化手段则从编译和硬件层面挖潜。这些技术相辅相成，我们经常会组合使用。例如，在一个实际对话系统中：对用户历史对话做缓存、多个用户问题批处理、模型用 8-bit 量化版本部署在多 GPU 上，并针对 GPU 做过推理代码优化——最终实现<strong>毫秒级</strong>响应。对于学习者，这部分内容显示出：<strong>算法高效性和工程优化</strong>对 AI 产品的重要性，不仅要模型聪明，也要跑得快。</p><p><strong>实例：</strong> 想象我们部署一个在线聊天室 AI，同时有 100 个用户提问。如果每个问题独立处理，可能一条回答要 1 秒，那 100 人同时就可能等上接近 1 分钟才能都回复。而如果我们使用批处理，例如一次让模型处理 10 个问题，模型在大约 1.5 秒内就能给出 10 个回答，那么 100 个问题分 10 批不到 15 秒就全部回答完毕了。这对单个用户来说，每个人平均等待也就几秒，大大提升了体验。再比如，一个用户的问题很长，有一大段背景介绍，每次问后续问题都重复那段背景。如果没有缓存，每次模型都要重新读那段背景花费大量计算。有了缓存，模型记住了背景的计算结果，后续回答时直接接着算新内容，速度快了很多。这类似我们看侦探小说，记住了之前章节内容，后面推理时不用每次从头再读。同样，如果模型部署时用了 4-bit 量化，本来需要 16GB 显存的模型现在 8GB 就够了，我们可以用较便宜的硬件服务更多用户且速度更快。这些例子都说明，高效推理技术让强大的模型真正<strong>用得起、用得快</strong>。</p><p><strong>引导性问题：</strong> 你能想到生活中哪些场景相当于缓存和批处理吗？为什么量化模型能加速却不明显降低效果，这背后可能是什么原理？在保证输出一致的前提下，我们有没有可能让模型“跳过”某些计算来更快给结果（提示：思考人类快读和略读的方法）？</p><p><strong>可视化建议：</strong> 制作一个**“提速技巧”集合图**：画出几个象征性的图标，如时钟表示缓存（节省时间）、并行计算机表示批处理/并行、剪刀表示剪枝减小模型、降阶梯表示量化降低位宽等等，每个图标旁用一句话点明作用。也可以做一个<strong>折线图</strong>或柱状图，横轴不同优化开启组合，纵轴响应时间，直观展示优化叠加如何将推理时间从比如 5 秒降到 1 秒。对于缓存，可画两张对比：第一张无缓存，模型每次处理整段文本；第二张有缓存，模型只处理增量部分，用颜色高亮重复部分被跳过的情形。</p><h3 id="推理时扩展" tabindex="-1"><a class="header-anchor" href="#推理时扩展"><span><strong>推理时扩展</strong></span></a></h3><p><strong>解释：</strong> “推理时扩展”指的是在模型<strong>生成推理阶段</strong>投入更多计算资源或策略，以<strong>进一步提高模型性能</strong> 。换句话说，当我们<strong>不增加训练</strong>也不改模型参数的情况下，通过巧妙地利用推理步骤，来解决更复杂的问题。这有点像在考试中不会的题时，允许考生多拿几张草稿纸、多找一些线索，尽可能把答案找对。推理时扩展的方法可以从多个角度展开，主要包括：</p><ul><li>==<strong>上下文扩展：</strong> 在推理时给模型<strong>提供更多有帮助的上下文信息</strong>  。==比如之前提过的 Few-shot 例子，在提示里加入示例，相当于扩展了输入内容。再如<strong>思维链提示</strong>和<strong>问题分解</strong>，也是通过上下文中显式列出推理步骤或子问题，让模型更容易得出正确答案  。另外还有<strong>动态检索</strong>：如 RAG，在推理时根据当前问题检索文档，把相关资料拼到提示里  。上下文扩展的核心是在不改变模型的情况下，<strong>最大化利用上下文窗口</strong>提供的容量，用示例、提示技巧或外部知识填满它。其收益是显而易见的：模型可以借助这些信息完成原本单靠内部知识难以完成的任务。不过受限于上下文长度，过多信息模型未必消化得完，而且上下文窗口有限，不可能无限塞入信息 。因此上下文扩展需要选择<strong>最相关</strong>的信息提供，这本身也是一门学问（比如检索要精准，示例要有代表性)。</li><li>==<strong>搜索扩展：</strong> 把<strong>解码的搜索空间和深度加大</strong>，用更强力的搜索找到更好的输出  。通俗地讲，就是允许模型<strong>尝试更多种可能答案</strong>再选择最佳。==最简单的例子是增大 beam width（束宽），我们之前说过 k 太大消耗高，但如果容许推理时花更多时间，可以把 k 设大一些以免错失好的解答  。另一种是<strong>延长输出长度</strong>：比如对于需要详细推理的题目，鼓励模型生成更长的推理链。研究发现，让模型在数学题上输出更长的思路往往结果更好，因为<strong>详尽思考</strong>有助于正确 。甚至有论文提出让模型在脑海里构建<strong>树形或图形的推理结构</strong>，同时探索多条路径再选优  （类似蒙特卡罗树搜索在决策中的用法）。当然，搜索扩展会显著增加计算量，是跟效率相博弈的——要收获质量就得多算。实践中，我们常在<strong>关键要求高准确</strong>的任务上使用一些搜索扩展，比如关乎安全性或正确率时，让模型多试几遍不同措辞回答，然后选择最好的一个输出用户。这可看作 N-best re-ranking，与前一章推理时对齐的 Best-of-N 思想吻合  。</li><li><strong>输出集成：</strong> 这个概念和前面提示部分的集成类似，但在推理时侧重于<strong>合并多个输出以提高鲁棒性</strong>  。假设我们可以让模型针对同一问题独立生成 5 个答案，那么集成方法可以是投票选最常见答案，或者逐字比较融合，甚至训练一个小模型来挑或合成答案  。输出集成的直观好处是：万一某个单次输出有瑕疵，不会直接呈现给用户，我们可以综合信息后得到<strong>更稳健</strong>的结果  。例如，当问题很难时，不同次生成的答案可能各说一部分对，通过集成我们也许能拼出一个完整正确的答案。这个过程需要额外计算资源，因为要生成和处理多个输出，但换来的是<strong>降低单次出错率</strong>。OpenAI 据传在 GPT-4 开发中尝试过类似方法，让多个 GPT-4 实例互相讨论或投票，以减少错误。这种“群体智慧”思路在 LLM 推理阶段也是有效的。</li><li><strong>生成和验证思维路径：</strong> 这是一种更高级的推理扩展技巧，尤其针对复杂问题（如数学、多步骤推理）  。它超越了简单的链式思维，而是让模型<strong>生成多个可能的思考路径</strong>，并对其进行验证，最终选出正确路径得出答案  。可以理解为模型带有“怀疑”和“检查”能力的推理。例如在解一道难题时，模型先想出一个方案 A 和方案 B，然后模型自己或另一个验证模型检查这两个方案哪个结果正确，淘汰错误的，再深入方案正确的继续推理。这类似人类解决难题时会：尝试不同解法-&gt;验证其中一些是否走得通-&gt;弃掉行不通的。实现上，可以让模型在每一步生成后调用另一个过程来审核这一步是否合理（比如计算检验中间结果正确性），或者在最后让模型基于自己的多条推理链做<strong>一致性判断</strong>，选择大多数链指向的答案（self-consistency，就是前述自洽方法的泛化）  。这种生成+验证的方法显著提高了解复杂推理问题的准确率，因为它<strong>减少了模型走错路不知返</strong>的情况。Google 的“Tree of Thoughts”以及 DeepMind 的“理由者模型”等都是这类思想的体现：用更多计算和自我检验，换来复杂问题上<strong>更可信的解答</strong>。</li></ul><p><strong>小结：</strong> 推理时扩展充分利用了模型在推理阶段的<strong>灵活性</strong>：我们可以给它更多信息（上下文扩展），让它尝试更多方案（搜索扩展），综合多种结果（输出集成），以及自行检查纠错（生成-验证） 。这些方法都不需要改模型参数或重新训练，却往往能显著提升性能，是近年来应对 LLM 复杂任务的<strong>利器</strong> 。当然，这些扩展通常以增加计算为代价，所以实际使用时会考虑场景的重要程度和资源情况。如果是在关键任务（如医学诊断）或模型推理还不够可靠的情况，我们宁可多花几倍算力采用推理扩展以确保正确；但在实时聊天等场景，速度体验重要，就可能少用。总之，推理时扩展为 LLM 提供了<strong>额外的“大脑助推”</strong>：无需更聪明的模型，也能通过“深思熟虑”获得更聪明的结果。</p><p><strong>实例：</strong> 一个具体场景：我们让 ChatGPT 解一题数学竞赛题。如果直接回答，ChatGPT 可能尝试一遍链式思维，给出一个答案，但不保证正确。现在应用推理时扩展：</p><ul><li><strong>上下文扩展：</strong> 在提示里加入相关数学定理或例题作为参考，让模型有更多背景知识。ChatGPT 会先参考这些已知定理，思路更清晰。</li><li><strong>搜索扩展：</strong> 让 ChatGPT 想出<strong>两个不同的解法</strong>：代数法和几何法，各自推理。如果第一次推理没成功，第二种可能成功，提高找到正确解的机会。</li><li><strong>输出集成：</strong> 得到两个解答后，我们让模型对比哪种更简洁正确，或者直接把两种解答的共同结论作为最终答案（如果它们一致，那可信度很高，如果不一致，可以提示模型再检查）。</li><li><strong>生成+验证：</strong> 甚至我们可以让 ChatGPT 在给出答案前，再自己验证一下结果是否符合题意。如果发现矛盾，再返回重新推理。例如算出答案后，把它代回原问题条件检验，ChatGPT 发现不符合就会警觉并修正。</li></ul><p>经过这些扩展，ChatGPT 解这道竞赛题的正确率比单次回答<strong>大大提高</strong>，过程也更令人信服。虽然它为此做了比平常回答多几倍的计算，但对于攻克高难度问题来说是值得的。这个例子体现了在推理阶段给予模型“二次机会”“多角度思考”和“自检纠错”的威力。</p><p><strong>引导性问题：</strong> 你觉得为什么不在训练时就解决这些问题，而选择推理时扩展？上下文提供太多信息可能有什么负面效果？模型自我验证的可靠性如何，能完全相信它自己的判定吗？推理时扩展的方法会不会也有极限（比如模型遇到超出它能力范围的题目）？</p><p><strong>可视化建议：</strong> 制作一个<strong>推理扩展流程图</strong>，以解决一个复杂问题为例，从普通单线推理对比到多分支推理：画出模型尝试方案 A、B、C，然后筛选出正确路径的过程。可以用决策树形式，标注在某步验证失败，于是剪去该分支的情形，最后剩下一条正确分支通向答案。此外，可以准备一张<strong>对比图表</strong>：列出某难题下，不用扩展 vs 用各类扩展后的模型成功率，用柱状图表示提升幅度，以量化展示推理扩展的效果。</p><h3 id="本章小结" tabindex="-1"><a class="header-anchor" href="#本章小结"><span><strong>本章小结</strong></span></a></h3><p>在本章中，我们讨论了大型语言模型（LLMs）的<strong>推理问题</strong> 。我们介绍了<strong>预填充-解码</strong>框架及相关的<strong>解码算法</strong>，了解如何通过不同策略控制模型生成文本的方式和风格 。接着，我们描述了多种<strong>高效推理</strong>的技术，从缓存、批处理到并行化、量化，让模型在实际应用中运行得更快、更省资源。我们还讨论了<strong>推理时的扩展</strong>方法——这被认为是提升 LLM 推理能力的重要手段之一 。通过在推理阶段投入更多计算和策略，如提供更多上下文、扩大搜索、集成输出、验证推理路径，我们可以在不改动模型本身的情况下显著增强其解题能力和可靠性。</p><p>综合而言，推理阶段既涉及<strong>工程优化</strong>，也包含<strong>算法创新</strong>。对于入门学习者，现在可以明白：让大模型给出一个好答案，不仅仅是模型本身够强，还需要我们巧妙地“驾驭”它——既包括用好的<strong>提示</strong>引导（上一章内容），也包括选对<strong>生成策略</strong>、配置好<strong>运行环境</strong>、在必要时让模型“多想一会儿”再答。这些技巧结合起来，才能让大型语言模型真正发挥出最佳表现，为用户提供<strong>又快又好的回答</strong>体验。</p></div><!----><!----><!----></div></main><footer class="vp-doc-footer" data-v-15e751aa data-v-ed2b2ef3><!--[--><!--]--><!----><!----><nav class="prev-next" data-v-ed2b2ef3><div class="pager" data-v-ed2b2ef3><a class="vp-link link pager-link prev" href="/article/p391kv2x/" data-v-ed2b2ef3><!--[--><span class="desc" data-v-ed2b2ef3>上一页</span><span class="title" data-v-ed2b2ef3>概要图</span><!--]--><!----></a></div><div class="pager" data-v-ed2b2ef3><a class="vp-link link pager-link next" href="/article/bm5yadon/" data-v-ed2b2ef3><!--[--><span class="desc" data-v-ed2b2ef3>下一页</span><span class="title" data-v-ed2b2ef3>第4章 对齐 (Alignment)</span><!--]--><!----></a></div></nav></footer><!----><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!--]--><button style="display:none;" type="button" class="vp-back-to-top" aria-label="back to top" data-v-f306e958 data-v-a71e2a30><span class="percent" data-allow-mismatch data-v-a71e2a30>0%</span><span class="show icon vpi-back-to-top" data-v-a71e2a30></span><svg aria-hidden="true" data-v-a71e2a30><circle cx="50%" cy="50%" data-allow-mismatch style="stroke-dasharray:calc(0% - 12.566370614359172px) calc(314.1592653589793% - 12.566370614359172px);" data-v-a71e2a30></circle></svg></button><footer class="vp-footer" vp-footer data-v-f306e958 data-v-27191c5d><!--[--><div class="container" data-v-27191c5d><p class="message" data-v-27191c5d>Released under the <a href="https://github.com/Asxing/9zhe.tech/blob/master/LICENSE">MIT License</a>.</p><p class="copyright" data-v-27191c5d>Copyright © 2019-present <a href="https://github.com/Asxing">Asxing</a></p></div><!--]--></footer><!--[--><!--]--><!--]--></div><!----><!--]--><!--[--><!--]--><!--]--></div><script type="module" src="/assets/app-zSjPkmgN.js" defer></script></body></html>