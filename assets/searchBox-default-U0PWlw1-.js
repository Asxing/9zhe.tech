const t='{"documentCount":131,"nextId":131,"documentIds":{"0":"/article/pb5gi2pw/","1":"/article/pb5gi2pw/#👋-hello-我是-asxing","2":"/article/slq78kbx/","3":"/ai/","4":"/article/pb5gi2pw/#🎯-技术栈","5":"/article/slq78kbx/#🤝-优秀博主","6":"/article/085s1ga0/","7":"/article/pb5gi2pw/#前端技术","8":"/article/slq78kbx/#前端技术","9":"/article/085s1ga0/#🎯-什么是claude插件","10":"/architecture/","11":"/article/pb5gi2pw/#后端技术","12":"/article/slq78kbx/#后端技术","13":"/article/085s1ga0/#🚀-快速开始","14":"/article/o607i2sg/","15":"/backend/","16":"/article/pb5gi2pw/#架构与运维","17":"/article/slq78kbx/#云原生技术","18":"/article/085s1ga0/#环境准备","19":"/article/o607i2sg/#🎯-核心原则","20":"/article/r2831hpp/","21":"/article/pb5gi2pw/#📖-博客理念","22":"/article/slq78kbx/#📝-申请友链","23":"/article/085s1ga0/#第一个插件示例","24":"/article/o607i2sg/#_1-单一职责原则","25":"/article/r2831hpp/#🎯-代码规范","26":"/ai/claude/","27":"/ai/foundations-of-llms/","28":"/article/pb5gi2pw/#🌟-开源贡献","29":"/article/slq78kbx/#申请要求","30":"/article/085s1ga0/#📚-核心概念","31":"/article/o607i2sg/#_2-数据库独立性","32":"/article/r2831hpp/#_1-命名规范","33":"/article/p391kv2x/","34":"/ai/foundations-of-llms/#章节目录","35":"/article/pb5gi2pw/#📬-联系方式","36":"/article/slq78kbx/#申请方式","37":"/article/085s1ga0/#_1-工具函数-tools","38":"/article/o607i2sg/#_3-api设计","39":"/article/r2831hpp/#_2-异常处理","40":"/article/vse0voeg/","41":"/article/avoeswll/","42":"/article/pb5gi2pw/#🎵-生活爱好","43":"/article/085s1ga0/#_2-插件架构","44":"/article/o607i2sg/#🔧-服务间通信","45":"/article/r2831hpp/#🚀-性能优化","46":"/article/vse0voeg/#_1-1-预训练-nlp-模型","47":"/article/y3h97jhw/","48":"/article/avoeswll/#_2-1-大语言模型简介","49":"/article/bm5yadon/","50":"/article/085s1ga0/#_3-最佳实践","51":"/article/o607i2sg/#_1-同步通信","52":"/article/r2831hpp/#_1-集合优化","53":"/article/vse0voeg/#_1-1-1-无监督、监督和自监督预训练","54":"/article/y3h97jhw/#第-3-章-提示","55":"/article/hdr0vnnf/","56":"/article/avoeswll/#_2-1-1-仅解码器-transformer-架构","57":"/article/bm5yadon/#第-4-章-对齐","58":"/architecture/microservices/","59":"/article/085s1ga0/#🎯-设计原则","60":"/backend/java/","61":"/article/o607i2sg/#_2-异步通信","62":"/article/r2831hpp/#_2-内存管理","63":"/article/vse0voeg/#_1-1-2-适应预训练模型","64":"/article/y3h97jhw/#通用提示设计","65":"/article/hdr0vnnf/#第-5-章-推理","66":"/article/avoeswll/#_2-1-2-训练-llm","67":"/article/bm5yadon/#llm-对齐概述","68":"/article/085s1ga0/#📊-性能优化","69":"/article/o607i2sg/#🚀-部署策略","70":"/article/r2831hpp/#💡-设计模式应用","71":"/article/vse0voeg/#_1-2-自监督预训练任务","72":"/article/y3h97jhw/#进阶提示方法","73":"/article/hdr0vnnf/#预填充与解码","74":"/article/avoeswll/#_2-1-3-微调-llm","75":"/article/bm5yadon/#指令对齐","76":"/article/085s1ga0/#🔧-高级功能","77":"/article/o607i2sg/#_1-容器化部署","78":"/article/r2831hpp/#_1-单例模式","79":"/article/vse0voeg/#_1-2-1-仅解码器的预训练","80":"/article/y3h97jhw/#学习提示","81":"/article/hdr0vnnf/#高效推理技术","82":"/article/avoeswll/#_2-1-4-将大语言模型与世界对齐","83":"/article/bm5yadon/#人类偏好对齐-rlhf","84":"/article/085s1ga0/#多步骤工作流","85":"/article/o607i2sg/#_2-服务发现","86":"/article/vse0voeg/#_1-2-2-仅编码器的预训练","87":"/article/y3h97jhw/#本章小结","88":"/article/hdr0vnnf/#推理时扩展","89":"/article/avoeswll/#_2-1-5-提示-llm","90":"/article/bm5yadon/#改进的人类偏好对齐","91":"/article/085s1ga0/#插件配置管理","92":"/article/o607i2sg/#📊-监控与治理","93":"/article/vse0voeg/#_1-2-3-编码器-解码器预训练","94":"/article/hdr0vnnf/#本章小结","95":"/article/avoeswll/#_2-2-大规模训练","96":"/article/bm5yadon/#本章小结","97":"/article/085s1ga0/#🚀-部署与分发","98":"/article/o607i2sg/#_1-分布式链路追踪","99":"/article/vse0voeg/#_1-2-4-预训练任务的比较","100":"/article/avoeswll/#_2-2-1-数据准备","101":"/article/085s1ga0/#_1-打包插件","102":"/article/o607i2sg/#_2-熔断器模式","103":"/article/vse0voeg/#_1-3-典型示例-bert-模型","104":"/article/avoeswll/#_2-2-2-模型修改","105":"/article/085s1ga0/#_2-docker化部署","106":"/article/vse0voeg/#_1-4-应用-bert-模型","107":"/article/avoeswll/#_2-2-3-分布式训练","108":"/article/085s1ga0/#_3-云端部署","109":"/article/vse0voeg/#_1-5-小结","110":"/article/avoeswll/#_2-2-4-缩放定律","111":"/article/085s1ga0/#💡-实战案例","112":"/article/avoeswll/#_2-3-长序列建模","113":"/article/085s1ga0/#案例1-数据分析插件","114":"/article/avoeswll/#_2-3-1-高效架构","115":"/article/085s1ga0/#案例2-api集成插件","116":"/article/avoeswll/#_2-3-2-缓存与记忆","117":"/article/085s1ga0/#🔍-调试与测试","118":"/article/avoeswll/#_2-3-3-跨层和跨头的参数共享","119":"/article/085s1ga0/#单元测试","120":"/article/avoeswll/#_2-3-4-位置外推与内插","121":"/article/085s1ga0/#集成测试","122":"/article/avoeswll/#_2-3-5-评述","123":"/article/085s1ga0/#📈-监控与维护","124":"/article/avoeswll/#_2-4-总结","125":"/article/085s1ga0/#性能监控","126":"/article/085s1ga0/#错误处理","127":"/article/085s1ga0/#🌟-社区与生态","128":"/article/085s1ga0/#开源贡献","129":"/article/085s1ga0/#学习资源","130":"/article/085s1ga0/#🎯-下一步"},"fieldIds":{"title":0,"titles":1,"text":2},"fieldLength":{"0":[1,1,1],"1":[4,1,3],"2":[1,1,1],"3":[1,1,7],"4":[2,5,1],"5":[2,1,3],"6":[1,1,4],"7":[1,7,20],"8":[1,3,9],"9":[3,1,13],"10":[1,1,5],"11":[1,7,19],"12":[1,3,7],"13":[2,1,1],"14":[1,1,4],"15":[1,1,5],"16":[1,7,19],"17":[1,3,6],"18":[1,3,19],"19":[2,1,1],"20":[1,1,4],"21":[2,5,17],"22":[2,1,3],"23":[1,3,51],"24":[2,3,15],"25":[2,1,1],"26":[1,1,7],"27":[1,1,9],"28":[2,5,9],"29":[1,3,16],"30":[2,1,1],"31":[2,3,9],"32":[2,3,27],"33":[1,1,321],"34":[1,1,34],"35":[2,5,11],"36":[1,3,22],"37":[4,3,19],"38":[2,3,35],"39":[2,3,34],"40":[2,1,133],"41":[4,1,95],"42":[2,5,21],"43":[2,3,20],"44":[2,1,1],"45":[2,1,1],"46":[4,2,26],"47":[4,1,1],"48":[3,4,82],"49":[4,1,1],"50":[2,3,1],"51":[2,3,20],"52":[2,3,28],"53":[3,5,83],"54":[4,4,88],"55":[4,1,1],"56":[5,6,75],"57":[4,4,75],"58":[1,1,4],"59":[2,5,10],"60":[1,1,6],"61":[2,3,19],"62":[2,3,15],"63":[3,5,125],"64":[1,7,147],"65":[4,4,96],"66":[4,6,126],"67":[2,6,122],"68":[2,5,5],"69":[2,1,1],"70":[2,1,1],"71":[3,2,13],"72":[1,7,226],"73":[1,6,248],"74":[5,6,114],"75":[1,6,201],"76":[2,1,1],"77":[2,3,16],"78":[2,3,19],"79":[3,5,79],"80":[1,7,206],"81":[1,6,293],"82":[4,6,148],"83":[2,6,165],"84":[1,3,27],"85":[2,3,18],"86":[3,5,97],"87":[1,7,31],"88":[1,6,272],"89":[5,6,121],"90":[1,6,285],"91":[1,3,32],"92":[2,1,1],"93":[5,5,100],"94":[1,6,45],"95":[2,4,13],"96":[1,6,51],"97":[2,1,1],"98":[2,3,18],"99":[4,5,73],"100":[3,5,149],"101":[2,3,11],"102":[2,3,26],"103":[5,2,79],"104":[2,5,163],"105":[2,3,24],"106":[5,2,88],"107":[3,5,176],"108":[2,3,13],"109":[3,2,39],"110":[3,5,145],"111":[2,1,1],"112":[3,4,35],"113":[2,3,49],"114":[4,6,149],"115":[2,3,43],"116":[3,6,121],"117":[2,1,1],"118":[3,6,92],"119":[1,3,34],"120":[4,6,161],"121":[1,3,24],"122":[4,6,68],"123":[2,1,1],"124":[3,4,80],"125":[1,3,36],"126":[1,3,38],"127":[2,1,1],"128":[1,3,6],"129":[1,3,9],"130":[2,1,22]},"averageFieldLength":[2.167938931297709,3.3282442748091605,53.58778625954198],"storedFields":{"0":{"title":"关于九折技术","titles":[]},"1":{"title":"👋 Hello, 我是 Asxing","titles":["关于九折技术"]},"2":{"title":"友情链接","titles":[]},"3":{"title":"AI技术","titles":[]},"4":{"title":"🎯 技术栈","titles":["关于九折技术","👋 Hello, 我是 Asxing"]},"5":{"title":"🤝 优秀博主","titles":["友情链接"]},"6":{"title":"Claude插件开发完全指南","titles":[]},"7":{"title":"前端技术","titles":["关于九折技术","👋 Hello, 我是 Asxing","🎯 技术栈"]},"8":{"title":"前端技术","titles":["友情链接","🤝 优秀博主"]},"9":{"title":"🎯 什么是Claude插件？","titles":["Claude插件开发完全指南"]},"10":{"title":"架构设计","titles":[]},"11":{"title":"后端技术","titles":["关于九折技术","👋 Hello, 我是 Asxing","🎯 技术栈"]},"12":{"title":"后端技术","titles":["友情链接","🤝 优秀博主"]},"13":{"title":"🚀 快速开始","titles":["Claude插件开发完全指南"]},"14":{"title":"微服务架构设计原则","titles":[]},"15":{"title":"后端技术","titles":[]},"16":{"title":"架构与运维","titles":["关于九折技术","👋 Hello, 我是 Asxing","🎯 技术栈"]},"17":{"title":"云原生技术","titles":["友情链接","🤝 优秀博主"]},"18":{"title":"环境准备","titles":["Claude插件开发完全指南","🚀 快速开始"]},"19":{"title":"🎯 核心原则","titles":["微服务架构设计原则"]},"20":{"title":"Java开发最佳实践","titles":[]},"21":{"title":"📖 博客理念","titles":["关于九折技术","👋 Hello, 我是 Asxing"]},"22":{"title":"📝 申请友链","titles":["友情链接"]},"23":{"title":"第一个插件示例","titles":["Claude插件开发完全指南","🚀 快速开始"]},"24":{"title":"1. 单一职责原则","titles":["微服务架构设计原则","🎯 核心原则"]},"25":{"title":"🎯 代码规范","titles":["Java开发最佳实践"]},"26":{"title":"Claude","titles":[]},"27":{"title":"大模型基础","titles":[]},"28":{"title":"🌟 开源贡献","titles":["关于九折技术","👋 Hello, 我是 Asxing"]},"29":{"title":"申请要求","titles":["友情链接","📝 申请友链"]},"30":{"title":"📚 核心概念","titles":["Claude插件开发完全指南"]},"31":{"title":"2. 数据库独立性","titles":["微服务架构设计原则","🎯 核心原则"]},"32":{"title":"1. 命名规范","titles":["Java开发最佳实践","🎯 代码规范"]},"33":{"title":"概要图","titles":[]},"34":{"title":"章节目录","titles":["大模型基础"]},"35":{"title":"📬 联系方式","titles":["关于九折技术","👋 Hello, 我是 Asxing"]},"36":{"title":"申请方式","titles":["友情链接","📝 申请友链"]},"37":{"title":"1. 工具函数 (Tools)","titles":["Claude插件开发完全指南","📚 核心概念"]},"38":{"title":"3. API设计","titles":["微服务架构设计原则","🎯 核心原则"]},"39":{"title":"2. 异常处理","titles":["Java开发最佳实践","🎯 代码规范"]},"40":{"title":"第1章 预训练","titles":[]},"41":{"title":"第2章 生成式模型（LLM）","titles":[]},"42":{"title":"🎵 生活爱好","titles":["关于九折技术","👋 Hello, 我是 Asxing"]},"43":{"title":"2. 插件架构","titles":["Claude插件开发完全指南","📚 核心概念"]},"44":{"title":"🔧 服务间通信","titles":["微服务架构设计原则"]},"45":{"title":"🚀 性能优化","titles":["Java开发最佳实践"]},"46":{"title":"1.1 预训练 NLP 模型","titles":["第1章 预训练"]},"47":{"title":"第3章 提示方法（Prompting）","titles":[]},"48":{"title":"2.1 大语言模型简介","titles":["第2章 生成式模型（LLM）"]},"49":{"title":"第4章 对齐 (Alignment)","titles":[]},"50":{"title":"3. 最佳实践","titles":["Claude插件开发完全指南","📚 核心概念"]},"51":{"title":"1. 同步通信","titles":["微服务架构设计原则","🔧 服务间通信"]},"52":{"title":"1. 集合优化","titles":["Java开发最佳实践","🚀 性能优化"]},"53":{"title":"1.1.1 无监督、监督和自监督预训练","titles":["第1章 预训练","1.1 预训练 NLP 模型"]},"54":{"title":"第 3 章 提示","titles":["第3章 提示方法（Prompting）"]},"55":{"title":"第5章 推理 (Inference)","titles":[]},"56":{"title":"2.1.1 仅解码器 Transformer 架构","titles":["第2章 生成式模型（LLM）","2.1 大语言模型简介"]},"57":{"title":"第 4 章 对齐","titles":["第4章 对齐 (Alignment)"]},"58":{"title":"微服务","titles":[]},"59":{"title":"🎯 设计原则","titles":["Claude插件开发完全指南","📚 核心概念","3. 最佳实践"]},"60":{"title":"Java","titles":[]},"61":{"title":"2. 异步通信","titles":["微服务架构设计原则","🔧 服务间通信"]},"62":{"title":"2. 内存管理","titles":["Java开发最佳实践","🚀 性能优化"]},"63":{"title":"1.1.2 适应预训练模型","titles":["第1章 预训练","1.1 预训练 NLP 模型"]},"64":{"title":"通用提示设计","titles":["第3章 提示方法（Prompting）","第 3 章 提示"]},"65":{"title":"第 5 章 推理","titles":["第5章 推理 (Inference)"]},"66":{"title":"2.1.2 训练 LLM","titles":["第2章 生成式模型（LLM）","2.1 大语言模型简介"]},"67":{"title":"LLM 对齐概述","titles":["第4章 对齐 (Alignment)","第 4 章 对齐"]},"68":{"title":"📊 性能优化","titles":["Claude插件开发完全指南","📚 核心概念","3. 最佳实践"]},"69":{"title":"🚀 部署策略","titles":["微服务架构设计原则"]},"70":{"title":"💡 设计模式应用","titles":["Java开发最佳实践"]},"71":{"title":"1.2 自监督预训练任务","titles":["第1章 预训练"]},"72":{"title":"进阶提示方法","titles":["第3章 提示方法（Prompting）","第 3 章 提示"]},"73":{"title":"预填充与解码","titles":["第5章 推理 (Inference)","第 5 章 推理"]},"74":{"title":"2.1.3 微调 LLM","titles":["第2章 生成式模型（LLM）","2.1 大语言模型简介"]},"75":{"title":"指令对齐","titles":["第4章 对齐 (Alignment)","第 4 章 对齐"]},"76":{"title":"🔧 高级功能","titles":["Claude插件开发完全指南"]},"77":{"title":"1. 容器化部署","titles":["微服务架构设计原则","🚀 部署策略"]},"78":{"title":"1. 单例模式","titles":["Java开发最佳实践","💡 设计模式应用"]},"79":{"title":"1.2.1 仅解码器的预训练","titles":["第1章 预训练","1.2 自监督预训练任务"]},"80":{"title":"学习提示","titles":["第3章 提示方法（Prompting）","第 3 章 提示"]},"81":{"title":"高效推理技术","titles":["第5章 推理 (Inference)","第 5 章 推理"]},"82":{"title":"2.1.4 将大语言模型与世界对齐","titles":["第2章 生成式模型（LLM）","2.1 大语言模型简介"]},"83":{"title":"人类偏好对齐：RLHF","titles":["第4章 对齐 (Alignment)","第 4 章 对齐"]},"84":{"title":"多步骤工作流","titles":["Claude插件开发完全指南","🔧 高级功能"]},"85":{"title":"2. 服务发现","titles":["微服务架构设计原则","🚀 部署策略"]},"86":{"title":"1.2.2 仅编码器的预训练","titles":["第1章 预训练","1.2 自监督预训练任务"]},"87":{"title":"本章小结","titles":["第3章 提示方法（Prompting）","第 3 章 提示"]},"88":{"title":"推理时扩展","titles":["第5章 推理 (Inference)","第 5 章 推理"]},"89":{"title":"2.1.5 提示 LLM","titles":["第2章 生成式模型（LLM）","2.1 大语言模型简介"]},"90":{"title":"改进的人类偏好对齐","titles":["第4章 对齐 (Alignment)","第 4 章 对齐"]},"91":{"title":"插件配置管理","titles":["Claude插件开发完全指南","🔧 高级功能"]},"92":{"title":"📊 监控与治理","titles":["微服务架构设计原则"]},"93":{"title":"1.2.3 编码器-解码器预训练","titles":["第1章 预训练","1.2 自监督预训练任务"]},"94":{"title":"本章小结","titles":["第5章 推理 (Inference)","第 5 章 推理"]},"95":{"title":"2.2 大规模训练","titles":["第2章 生成式模型（LLM）"]},"96":{"title":"本章小结","titles":["第4章 对齐 (Alignment)","第 4 章 对齐"]},"97":{"title":"🚀 部署与分发","titles":["Claude插件开发完全指南"]},"98":{"title":"1. 分布式链路追踪","titles":["微服务架构设计原则","📊 监控与治理"]},"99":{"title":"1.2.4 预训练任务的比较","titles":["第1章 预训练","1.2 自监督预训练任务"]},"100":{"title":"2.2.1 数据准备","titles":["第2章 生成式模型（LLM）","2.2 大规模训练"]},"101":{"title":"1. 打包插件","titles":["Claude插件开发完全指南","🚀 部署与分发"]},"102":{"title":"2. 熔断器模式","titles":["微服务架构设计原则","📊 监控与治理"]},"103":{"title":"1.3 典型示例：BERT 模型","titles":["第1章 预训练"]},"104":{"title":"2.2.2 模型修改","titles":["第2章 生成式模型（LLM）","2.2 大规模训练"]},"105":{"title":"2. Docker化部署","titles":["Claude插件开发完全指南","🚀 部署与分发"]},"106":{"title":"1.4 应用 BERT 模型","titles":["第1章 预训练"]},"107":{"title":"2.2.3 分布式训练","titles":["第2章 生成式模型（LLM）","2.2 大规模训练"]},"108":{"title":"3. 云端部署","titles":["Claude插件开发完全指南","🚀 部署与分发"]},"109":{"title":"1.5 小结","titles":["第1章 预训练"]},"110":{"title":"2.2.4 缩放定律","titles":["第2章 生成式模型（LLM）","2.2 大规模训练"]},"111":{"title":"💡 实战案例","titles":["Claude插件开发完全指南"]},"112":{"title":"2.3 长序列建模","titles":["第2章 生成式模型（LLM）"]},"113":{"title":"案例1: 数据分析插件","titles":["Claude插件开发完全指南","💡 实战案例"]},"114":{"title":"2.3.1 高效架构","titles":["第2章 生成式模型（LLM）","2.3 长序列建模"]},"115":{"title":"案例2: API集成插件","titles":["Claude插件开发完全指南","💡 实战案例"]},"116":{"title":"2.3.2 缓存与记忆","titles":["第2章 生成式模型（LLM）","2.3 长序列建模"]},"117":{"title":"🔍 调试与测试","titles":["Claude插件开发完全指南"]},"118":{"title":"2.3.3 跨层和跨头的参数共享","titles":["第2章 生成式模型（LLM）","2.3 长序列建模"]},"119":{"title":"单元测试","titles":["Claude插件开发完全指南","🔍 调试与测试"]},"120":{"title":"2.3.4 位置外推与内插","titles":["第2章 生成式模型（LLM）","2.3 长序列建模"]},"121":{"title":"集成测试","titles":["Claude插件开发完全指南","🔍 调试与测试"]},"122":{"title":"2.3.5 评述","titles":["第2章 生成式模型（LLM）","2.3 长序列建模"]},"123":{"title":"📈 监控与维护","titles":["Claude插件开发完全指南"]},"124":{"title":"2.4 总结","titles":["第2章 生成式模型（LLM）"]},"125":{"title":"性能监控","titles":["Claude插件开发完全指南","📈 监控与维护"]},"126":{"title":"错误处理","titles":["Claude插件开发完全指南","📈 监控与维护"]},"127":{"title":"🌟 社区与生态","titles":["Claude插件开发完全指南"]},"128":{"title":"开源贡献","titles":["Claude插件开发完全指南","🌟 社区与生态"]},"129":{"title":"学习资源","titles":["Claude插件开发完全指南","🌟 社区与生态"]},"130":{"title":"🎯 下一步","titles":["Claude插件开发完全指南"]}},"dirtCount":0,"index":[["持续学习",{"2":{"130":1}}],["恭喜您完成了claude插件开发指南的学习",{"2":{"130":1}}],["视频教程",{"2":{"129":1}}],["参与",{"2":{"128":1}}],["参数共享提高模型长程泛化能力",{"2":{"124":1}}],["参数共享有点像用同一个专家反复咨询",{"2":{"118":1}}],["参数共享是压缩模型的有效方法",{"2":{"118":1}}],["参数共享以及位置编码的拓展等",{"2":{"112":1}}],["参数上百亿",{"2":{"107":1}}],["参数",{"2":{"81":1}}],["参数控制随机程度",{"2":{"73":1}}],["参数构造",{"2":{"54":1}}],["参数越多",{"2":{"48":1}}],["参数高效",{"2":{"40":1,"41":1,"57":1,"118":1}}],["社区与生态",{"0":{"127":1},"1":{"128":1,"129":1}}],["社区音乐会等",{"2":{"64":1}}],["执行失败",{"2":{"125":1}}],["执行时间",{"2":{"125":1}}],["执行数学计算",{"2":{"37":1}}],["展望未来",{"2":{"124":1}}],["展示了预训练+微调范式的强大",{"2":{"106":1}}],["展示从基础",{"2":{"90":1}}],["展示模型从接收提示",{"2":{"72":1}}],["展示模型输出质量差异",{"2":{"64":1}}],["展示如何从模板到实际提示的填充过程",{"2":{"64":1}}],["确保了超大模型训练的稳定和高效",{"2":{"124":1}}],["确定式",{"2":{"65":1}}],["移除偏置",{"2":{"124":1}}],["移动适配",{"2":{"29":1}}],["号模型",{"2":{"122":1}}],["号称能",{"2":{"116":1}}],["号称能处理",{"2":{"114":1}}],["近似",{"2":{"122":1}}],["近期的方法如上下文蒸馏就是让强模型生成大量有上下文的问答对",{"2":{"80":1}}],["仍然没有哪种方案能完美支持任意长序列且性能与短序列一样好",{"2":{"122":1}}],["法律合同",{"2":{"122":1}}],["角度会顺延增加",{"2":{"120":1}}],["角色名",{"2":{"64":1}}],["角色设定和示例",{"2":{"64":1}}],["角色设定",{"2":{"54":1}}],["角色",{"2":{"33":2}}],["行是连续的",{"2":{"120":1}}],["行和第",{"2":{"120":1}}],["行以后它完全没概念",{"2":{"120":1}}],["行",{"2":{"120":2}}],["行诗",{"2":{"120":1}}],["行为符合人类期望的工具箱",{"2":{"96":1}}],["行为和人类期望保持一致的方法",{"2":{"67":1}}],["拓展到",{"2":{"120":1}}],["拓展调用数",{"2":{"54":1}}],["作为学习者",{"2":{"122":1}}],["作为一段",{"2":{"120":1}}],["作为额外输入",{"2":{"116":1}}],["启示是很多位置编码可以通过线性变换做内插或外推调整",{"2":{"120":1}}],["压缩过的",{"2":{"120":1}}],["压缩式记忆",{"2":{"33":1}}],["叫做缩放插值",{"2":{"120":1}}],["超过之前范围照样延伸",{"2":{"120":1}}],["超过一定长度后位置编码重新从",{"2":{"120":1}}],["超出训练长度的角度也是定义良好的",{"2":{"120":1}}],["超时率",{"2":{"65":1}}],["坐标形式的位置表示",{"2":{"120":1}}],["北京",{"2":{"119":2}}],["循环",{"2":{"118":1}}],["循环神经网络可以处理任意长度序列",{"2":{"118":1}}],["倾向让每个头独立",{"2":{"118":1}}],["迫使头学到更通用的表示",{"2":{"118":1}}],["曾有研究",{"2":{"118":1}}],["曾有一个",{"2":{"116":1}}],["跨头共享则是指不同注意力头之间共用某些投影矩阵参数",{"2":{"118":1}}],["跨层共享在",{"2":{"118":1}}],["跨层共享早在小模型时代就有尝试",{"2":{"118":1}}],["跨层和跨头的参数共享",{"0":{"118":1}}],["跨语对齐",{"2":{"33":1}}],["易遗忘长文本上下文的问题",{"2":{"116":1}}],["百页文档内容",{"2":{"116":1}}],["百科",{"2":{"100":1}}],["否则",{"2":{"116":1}}],["否则单",{"2":{"81":1}}],["属于模型结构的一部分",{"2":{"116":1}}],["增强",{"2":{"116":1}}],["增加奖励模型的训练数据量和多样性",{"2":{"90":1}}],["何时取用",{"2":{"116":1}}],["稍后需要时再读出",{"2":{"116":1}}],["隔断上下文后就忘了",{"2":{"116":1}}],["捕捉长期依赖关系",{"2":{"116":1}}],["传感器数据等长时序也可用类似思想处理",{"2":{"122":1}}],["传递",{"2":{"118":1}}],["传递给下一个",{"2":{"116":1}}],["传统",{"2":{"90":1,"118":1}}],["试图赋予模型一种",{"2":{"116":1}}],["试图跳过复杂的强化学习算法",{"2":{"90":1}}],["矩阵",{"2":{"116":1}}],["矩阵来完成",{"2":{"56":1}}],["面对长文档时",{"2":{"114":1}}],["略过次要部分",{"2":{"114":1}}],["快速略读",{"2":{"114":1}}],["快速开始",{"0":{"13":1},"1":{"18":1,"23":1}}],["普通",{"2":{"114":1,"120":1}}],["两者配合",{"2":{"114":1}}],["两阶段",{"2":{"65":1}}],["两阶段与缓存",{"2":{"33":1}}],["双路或多尺度模型",{"2":{"114":1}}],["双向编码器表示",{"2":{"103":1}}],["双向",{"2":{"40":1}}],["形成分层结构",{"2":{"114":1}}],["形成记忆",{"2":{"100":1}}],["早期",{"2":{"114":1}}],["早期的",{"2":{"67":1}}],["早期的词向量",{"2":{"53":1}}],["尝试多步骤工作流和api集成",{"2":{"130":1}}],["尝试让几组层循环使用",{"2":{"118":1}}],["尝试用低维表示近似注意力矩阵",{"2":{"114":1}}],["尝试不同解法",{"2":{"88":1}}],["兼顾局部和全局信息",{"2":{"114":1}}],["限制每个词只看相邻的一段窗口内的词",{"2":{"114":1}}],["限于篇幅不展开",{"2":{"107":1}}],["稀疏",{"2":{"122":1}}],["稀疏注意力",{"2":{"114":1}}],["稀有词",{"2":{"40":1}}],["难以直接扩展到上万甚至更多",{"2":{"114":1}}],["案例2",{"0":{"115":1}}],["案例1",{"0":{"113":1}}],["案例中",{"2":{"83":1}}],["累积起来就能刷新纪录",{"2":{"110":1}}],["刚开始训练",{"2":{"110":1}}],["达到用更少资源获取同等性能的目标",{"2":{"110":1}}],["达到让人满意的状态",{"2":{"83":1}}],["缩放曲线",{"2":{"110":1}}],["缩放定律告诉我们增大模型和数据会持续改进性能",{"2":{"124":1}}],["缩放定律还预测了一些性能拐点和新能力的涌现",{"2":{"110":1}}],["缩放定律",{"0":{"110":1}}],["弯折",{"2":{"110":1}}],["业界因此需要在模型效果和资源消耗之间寻找平衡",{"2":{"110":1}}],["智能的提升没有明显天花板",{"2":{"110":1}}],["智能体",{"2":{"82":1}}],["论文出来后",{"2":{"110":1}}],["论坛帖子",{"2":{"100":1}}],["团队在规划下代模型时",{"2":{"110":1}}],["团队通常会设定一些",{"2":{"100":1}}],["年的实验中",{"2":{"110":1}}],["年提出",{"2":{"103":1}}],["定律建议把模型参数和训练",{"2":{"110":1}}],["定义了下一个词的概率分布",{"2":{"48":1}}],["边读边记",{"2":{"116":1}}],["边际效用递减",{"2":{"110":1}}],["边解边生子问题",{"2":{"33":1}}],["三类",{"2":{"109":1}}],["三步",{"2":{"33":1}}],["轻量级插件",{"2":{"108":1}}],["云端部署",{"0":{"108":1}}],["云原生计算基金会",{"2":{"17":1}}],["云原生技术",{"0":{"17":1}}],["亿则进步相对小",{"2":{"110":1}}],["亿到",{"2":{"110":2}}],["亿增加到",{"2":{"110":1}}],["亿",{"2":{"110":2}}],["亿次",{"2":{"107":1}}],["亿参数长进很大",{"2":{"110":1}}],["亿参数模型",{"2":{"110":1}}],["亿参数模型训练",{"2":{"110":1}}],["亿参数但只看几千亿",{"2":{"110":1}}],["亿参数增加到",{"2":{"110":1}}],["亿参数",{"2":{"66":1}}],["块",{"2":{"107":1}}],["65b",{"2":{"107":1}}],["60",{"2":{"72":1}}],["才在较短时间内完成宏伟工程",{"2":{"107":1}}],["才能成为人类的助手而非失控的机器",{"2":{"96":1}}],["才能让大型语言模型真正发挥出最佳表现",{"2":{"94":1}}],["才能正确地填补缺失的词",{"2":{"86":1}}],["根本竣工不了",{"2":{"107":1}}],["根据奖励模型打分作为",{"2":{"83":1}}],["搬砖效率太低",{"2":{"107":1}}],["资源得到最大利用",{"2":{"107":1}}],["资源侧重点",{"2":{"65":1}}],["zero",{"2":{"107":1}}],["组织千人协作建塔",{"2":{"107":1}}],["组",{"2":{"107":1}}],["台机器上",{"2":{"107":1}}],["台机器各读",{"2":{"81":1}}],["抵消并行带来的算力提升",{"2":{"107":1}}],["段",{"2":{"107":2}}],["操作来同步梯度",{"2":{"107":1}}],["倍",{"2":{"107":1}}],["独立计算自己那份数据的梯度",{"2":{"107":1}}],["份",{"2":{"107":1}}],["必须使用分布式训练",{"2":{"107":1}}],["必须真正读懂文章才能把缺的词填上",{"2":{"86":1}}],["哪怕论文很长",{"2":{"116":1}}],["哪怕",{"2":{"107":1}}],["哪怕多",{"2":{"107":1}}],["哪些场景下则必须用确定性方法",{"2":{"73":1}}],["明示或隐式的",{"2":{"106":1}}],["继续类比的话",{"2":{"106":1}}],["继续训练",{"2":{"63":1}}],["精湛",{"2":{"106":1}}],["精益对齐",{"2":{"90":1}}],["紧凑",{"2":{"106":1}}],["判定这条评论情感为正面",{"2":{"106":1}}],["判断评论是正面还是负面",{"2":{"106":1}}],["演技精湛",{"2":{"106":1}}],["约定俗成",{"2":{"106":1}}],["约束控制",{"2":{"54":1,"65":1}}],["约束",{"2":{"41":1}}],["震荡剧烈甚至发散",{"2":{"104":1}}],["秘密往往藏在这些不起眼的细节里",{"2":{"104":1}}],["差别不大",{"2":{"104":1}}],["细活",{"2":{"104":1}}],["细粒度的监督",{"2":{"96":1}}],["梯度裁剪防止爆炸等等",{"2":{"104":1}}],["梯度下降调整参数",{"2":{"66":1}}],["干脆移除了大部分线性层的",{"2":{"104":1}}],["激活",{"2":{"104":1,"124":1}}],["激活函数",{"2":{"104":1}}],["几乎可以加速",{"2":{"107":1}}],["几乎可以胜任各种",{"2":{"99":1}}],["几乎都使用前置",{"2":{"104":1}}],["名字代表",{"2":{"103":1}}],["典型示例",{"0":{"103":1}}],["典型风险",{"2":{"57":1}}],["默认用户",{"2":{"102":1}}],["熔断器模式",{"0":{"102":1}}],["况且训练优化的目标是让模型概括语言规律而非死记硬背具体句子",{"2":{"100":1}}],["逐渐发现了一些经验性规律",{"2":{"110":1}}],["逐字存储",{"2":{"100":1}}],["逐字背诵出来",{"2":{"100":1}}],["逐步对齐效果",{"2":{"90":1}}],["逐步对齐的想法是在模型推理的中间步骤也给予监督和反馈",{"2":{"90":1}}],["逐步对齐",{"2":{"90":1}}],["逐步生成",{"2":{"65":1}}],["逐步推理",{"2":{"54":1}}],["逐步求解",{"2":{"33":1}}],["图书馆里的书",{"2":{"100":1}}],["防止重复藏书",{"2":{"100":1}}],["防止模型过度记忆某些内容",{"2":{"100":1}}],["庞大数据也带来副作用",{"2":{"100":1}}],["绝大部分功劳要归于喂给它的海量知识宝库",{"2":{"100":1}}],["绝对",{"2":{"41":1}}],["博闻强识",{"2":{"100":1}}],["博客理念",{"0":{"21":1}}],["医学文本",{"2":{"100":1}}],["许多",{"2":{"104":1}}],["许多团队为此制定了一系列规则和自动过滤脚本",{"2":{"100":1}}],["许多需要将一段文本转换成另一段文本的任务",{"2":{"93":1}}],["剔除重复或高度相似的文本片段",{"2":{"100":1}}],["脚本代码等非自然语言内容",{"2":{"100":1}}],["互联网数据混杂噪音",{"2":{"100":1}}],["抓取的网页",{"2":{"100":1}}],["准备这些数据是繁杂但重要的步骤",{"2":{"100":1}}],["准确性的平衡",{"2":{"73":1}}],["准确",{"2":{"41":1,"65":1}}],["米",{"2":{"100":1}}],["巧妇难为无米之炊",{"2":{"100":1}}],["俗话说",{"2":{"100":1}}],["平衡不是简单平均",{"2":{"100":1}}],["平衡了理解和生成能力",{"2":{"99":1}}],["平行探索几条路线",{"2":{"73":1}}],["善于捕捉句子整体意义",{"2":{"99":1}}],["部署到不同",{"2":{"107":1}}],["部署与分发",{"0":{"97":1},"1":{"101":1,"105":1,"108":1}}],["部署策略",{"0":{"69":1},"1":{"77":1,"85":1}}],["陪伴",{"2":{"96":1}}],["责任越大",{"2":{"96":1}}],["配置好运行环境",{"2":{"94":1}}],["配比的经验规律",{"2":{"33":1}}],["配比",{"2":{"33":1}}],["驾驭",{"2":{"94":1}}],["扩大搜索",{"2":{"94":1}}],["扩展上下文时用了一招",{"2":{"120":1}}],["扩展上下文与知识",{"2":{"33":1}}],["扩展模型能力的提示方法",{"2":{"72":1}}],["扩展",{"2":{"63":1}}],["非常好看",{"2":{"106":1}}],["非常",{"2":{"93":1}}],["非常有价值",{"2":{"90":1}}],["改良表示",{"2":{"122":1}}],["改造",{"2":{"114":1}}],["改用了gelu",{"2":{"104":1}}],["改变",{"2":{"93":1}}],["改进位置编码使模型可以泛化到超过训练长度的新位置",{"2":{"124":1}}],["改进位置编码等",{"2":{"124":1}}],["改进位置编码",{"2":{"104":1}}],["改进激活函数",{"2":{"104":1}}],["改进版",{"2":{"103":1}}],["改进措施包括",{"2":{"90":1}}],["改进的人类偏好对齐方法丰富多彩",{"2":{"90":1}}],["改进的人类偏好对齐",{"0":{"90":1}}],["改进方法",{"2":{"34":1,"57":1}}],["世界",{"2":{"93":1}}],["出正确文本",{"2":{"93":1}}],["出模型潜在的最佳表现",{"2":{"90":1}}],["完好的文本",{"2":{"93":1}}],["完成步骤",{"2":{"84":1}}],["替换若干词",{"2":{"93":1}}],["替代",{"2":{"40":1}}],["破坏",{"2":{"93":1}}],["$",{"2":{"91":2}}],["yml",{"2":{"91":1,"119":1}}],["your",{"2":{"18":1}}],["免",{"2":{"90":1}}],["延伸出的不同改进分支",{"2":{"90":1}}],["延迟百分位",{"2":{"33":1}}],["延迟",{"2":{"33":1,"41":1,"65":1}}],["升级为",{"2":{"90":1}}],["剩下再选一个最合适的呈现",{"2":{"90":1}}],["针对逻辑推理问题",{"2":{"90":1}}],["简而言之",{"2":{"104":1}}],["简洁度",{"2":{"90":1}}],["简单打个比方",{"2":{"81":1}}],["简单说",{"2":{"73":1,"110":1}}],["简单说就是让模型在生成答案时利用外部知识",{"2":{"72":1}}],["简单地说",{"2":{"67":1}}],["简单来说",{"2":{"53":1,"80":1}}],["助手",{"2":{"90":1}}],["昂贵或可能出现的不良策略",{"2":{"90":1}}],["挖掘",{"2":{"90":1}}],["授之以渔",{"2":{"90":1}}],["辅助生成更多偏好数据",{"2":{"90":1}}],["努力方向",{"2":{"90":1}}],["礼貌度",{"2":{"90":1}}],["礼貌程度等的多指标评价",{"2":{"90":1}}],["礼貌的回答",{"2":{"82":1}}],["走偏",{"2":{"90":1}}],["希望表达诚恳的歉意并请求原谅",{"2":{"89":1}}],["希望至少一条能走到宝藏",{"2":{"73":1}}],["背景",{"2":{"89":1}}],["背景和要求",{"2":{"64":1}}],["任何",{"2":{"93":1}}],["任何自然语言甚至加入特殊标记都可以",{"2":{"89":1}}],["任务的最佳成绩",{"2":{"106":1}}],["任务而主要依靠更大的数据和纯",{"2":{"103":1}}],["任务都被统一转换成文本到文本的问题作为预训练的一部分",{"2":{"93":1}}],["任务上",{"2":{"75":1}}],["任务成功率",{"2":{"54":1}}],["任务适配",{"2":{"54":1}}],["任务族",{"2":{"33":1}}],["任务",{"2":{"33":1,"40":5,"79":1,"99":1,"103":1}}],["任务指令角色格式验收",{"2":{"33":1}}],["答",{"2":{"89":1}}],["答句",{"2":{"75":1}}],["良好的提示可以引导模型先",{"2":{"89":1}}],["格式回答",{"2":{"89":2}}],["示范格式",{"2":{"89":1}}],["示例作为",{"2":{"89":1}}],["示例要有代表性",{"2":{"88":1}}],["示例触发",{"2":{"54":1}}],["示例选择",{"2":{"54":1}}],["示例策略",{"2":{"54":1}}],["示例",{"2":{"33":4,"53":1}}],["除非为了节省参数做小模型蒸馏等",{"2":{"118":1}}],["除非你用自然语言表述出来",{"2":{"89":1}}],["除以标准差来规范化每层输出",{"2":{"104":1}}],["除了以上结构变化",{"2":{"104":1}}],["除了指令",{"2":{"74":1}}],["除了编程",{"2":{"42":1}}],["列出某难题下",{"2":{"88":1}}],["列表",{"2":{"40":1}}],["画出模型尝试方案",{"2":{"88":1}}],["画出几个象征性的图标",{"2":{"81":1}}],["二章内容奠定了理解这一范式的基础",{"2":{"124":1}}],["二是通过提示设计输入",{"2":{"109":1}}],["二次机会",{"2":{"88":1}}],["二到五条高质量示例启发式学习",{"2":{"33":1}}],["想自己训练一个",{"2":{"104":1}}],["想让它写一封道歉信",{"2":{"89":1}}],["想",{"2":{"89":1}}],["想出两个不同的解法",{"2":{"88":1}}],["想象你平时练习只背过",{"2":{"120":1}}],["想象类比",{"2":{"116":1}}],["想象我们部署一个在线聊天室",{"2":{"81":1}}],["想象成一个接龙写故事的人",{"2":{"73":1}}],["想象成一个训练有素的写作机器人",{"2":{"48":1}}],["想象训练一只小狗",{"2":{"67":1}}],["获得了基本的句间关系和上下文连贯性的判断能力",{"2":{"103":1}}],["获得更聪明的结果",{"2":{"88":1}}],["获取最新或具体的信息",{"2":{"72":1}}],["获取指定位置的天气信息",{"2":{"23":2}}],["获取api密钥",{"2":{"18":1}}],["深思熟虑",{"2":{"88":1}}],["速度体验重要",{"2":{"88":1}}],["速度快了很多",{"2":{"81":1}}],["复杂任务的利器",{"2":{"88":1}}],["复杂任务提示",{"2":{"72":1}}],["却保留了深度",{"2":{"118":1}}],["却能取得更好效果",{"2":{"104":1}}],["却能把运行成本降很多",{"2":{"81":1}}],["却可能在训练初期引入不必要的不稳定",{"2":{"104":1}}],["却往往能显著提升性能",{"2":{"88":1}}],["综合来说",{"2":{"124":1}}],["综合而言",{"2":{"94":1}}],["综合它们的判断",{"2":{"90":1}}],["综合多种结果",{"2":{"88":1}}],["综合后能抵消单一输出的偏差",{"2":{"72":1}}],["选择合适的折中方案",{"2":{"114":1}}],["选择合适的激活至关重要",{"2":{"104":1}}],["选择大多数链指向的答案",{"2":{"88":1}}],["选出的好答案再来微调模型",{"2":{"90":1}}],["选得足够多",{"2":{"90":1}}],["选",{"2":{"90":3}}],["选概率最大的作为预测结果",{"2":{"63":1}}],["弃掉行不通的",{"2":{"88":1}}],["淘汰错误的",{"2":{"88":1}}],["检查梯度",{"2":{"104":1}}],["检查",{"2":{"88":1}}],["检索与工具使用",{"2":{"33":1}}],["检索与工具",{"2":{"33":1,"54":1}}],["检索与工具调用",{"2":{"33":1}}],["检索增强",{"2":{"33":4}}],["怀疑",{"2":{"88":1}}],["群体智慧",{"2":{"88":1}}],["据说类似",{"2":{"120":1}}],["据推测采用了一种分段总结+检索的方法",{"2":{"114":1}}],["据报道",{"2":{"107":1}}],["据报道结构类似",{"2":{"56":1}}],["据称在训练",{"2":{"90":1}}],["据传在",{"2":{"88":1}}],["鼓励模型生成更长的推理链",{"2":{"88":1}}],["其中自监督预训练是大型语言模型的核心方式",{"2":{"109":1}}],["其效果是模型学习更严谨地推理",{"2":{"90":1}}],["其优点是流程简单",{"2":{"90":1}}],["其实正是人类在进行提示工程",{"2":{"89":1}}],["其收益是显而易见的",{"2":{"88":1}}],["其它加速策略",{"2":{"81":1}}],["主要在于降低内存占用和允许用更多层来处理扩展序列",{"2":{"118":1}}],["主要包括",{"2":{"88":1}}],["主要指参数规模大和训练数据量大",{"2":{"48":1}}],["尽量避免闲置等待",{"2":{"107":1}}],["尽量生成被偏好的答案",{"2":{"90":1}}],["尽可能把答案找对",{"2":{"88":1}}],["尽管",{"2":{"118":1}}],["尽管每个请求的延迟可能略有上升",{"2":{"81":1}}],["尽管人类可以手工设计提示",{"2":{"80":1}}],["允许它在阅读长文时不断将信息写入内存",{"2":{"116":1}}],["允许考生多拿几张草稿纸",{"2":{"88":1}}],["允许您定义自定义工具",{"2":{"37":1}}],["换来复杂问题上更可信的解答",{"2":{"88":1}}],["换句话说",{"2":{"88":1}}],["换成实际情况",{"2":{"64":1}}],["都可能意味着新的能力和应用突破",{"2":{"110":1}}],["都会让成绩变好",{"2":{"110":1}}],["都是资源浪费",{"2":{"110":1}}],["都有一份完整的模型拷贝",{"2":{"107":1}}],["都被模型大致读过一遍",{"2":{"100":1}}],["都将更加游刃有余",{"2":{"87":1}}],["都采用这种架构",{"2":{"93":1}}],["都采用",{"2":{"56":1}}],["充分发挥预训练所学知识来解决多样的问题",{"2":{"87":1}}],["拆解复杂任务",{"2":{"87":1}}],["极端偏见言论",{"2":{"100":1}}],["极可能是",{"2":{"86":1}}],["极大提高了解决问题的范围",{"2":{"72":1}}],["巴黎",{"2":{"86":2}}],["巴黎是法国的首都",{"2":{"86":1}}],["埃菲尔铁塔位于",{"2":{"86":2}}],["阅读理解",{"2":{"86":1}}],["涂掉其中一些词",{"2":{"86":1}}],["拿一篇文章",{"2":{"86":1}}],["拿一个较弱的模型",{"2":{"75":1}}],["则常用编码器",{"2":{"99":1}}],["则是将句子打乱或损坏后训练模型重建原句",{"2":{"86":1}}],["则概率分布变平",{"2":{"73":1}}],["培养了模型的双向理解能力",{"2":{"86":1}}],["既能读懂输入又能产生输出",{"2":{"99":1}}],["既包括用好的提示引导",{"2":{"94":1}}],["既需要创意和试验",{"2":{"87":1}}],["既看前文也看后文",{"2":{"86":1}}],["既费时效果又未必好",{"2":{"46":1}}],["了一定长度的前文摘要",{"2":{"116":1}}],["了解如何通过不同策略控制模型生成文本的方式和风格",{"2":{"94":1}}],["了趟",{"2":{"86":1}}],["了",{"2":{"86":1,"90":1}}],["公园",{"2":{"86":1}}],["公司用大量对话语料微调",{"2":{"74":1}}],["填字游戏",{"2":{"86":1}}],["遮住",{"2":{"86":1}}],["遮住当前词之后的位置",{"2":{"56":1}}],["骗过奖励模型却没真正理解人类意图",{"2":{"83":1}}],["套路",{"2":{"83":1}}],["找到",{"2":{"83":1}}],["找到性价比最佳点",{"2":{"81":1}}],["抱歉",{"2":{"83":1}}],["寻求专业帮助也很重要",{"2":{"83":1}}],["寻路策略",{"2":{"73":1}}],["很少完全共享全部层参数",{"2":{"118":1}}],["很不划算",{"2":{"116":1}}],["很大时计算和内存占用都很高",{"2":{"114":1}}],["很多",{"2":{"104":1}}],["很多现代",{"2":{"82":1}}],["很困难",{"2":{"104":1}}],["很抱歉听到你难过",{"2":{"83":1}}],["应是",{"2":{"86":1}}],["应该怎么办",{"2":{"83":1}}],["应用实用化的关键",{"2":{"81":1}}],["应用级缓存",{"2":{"65":1}}],["应用",{"0":{"106":1},"2":{"40":1}}],["应用闭环",{"2":{"33":1}}],["应用与系统",{"2":{"33":1}}],["体会",{"2":{"83":1}}],["体现了",{"2":{"83":1}}],["称为奖励黑客",{"2":{"83":1}}],["投机取巧",{"2":{"83":1}}],["投票选择",{"2":{"33":1}}],["避开低分回答",{"2":{"83":1}}],["避免每次都从头计算",{"2":{"116":1}}],["避免模型学到无谓模式",{"2":{"100":1}}],["避免强化学习难调参数的问题",{"2":{"90":1}}],["避免使用特殊标记",{"2":{"86":1}}],["避免冗长提示带来的开销",{"2":{"80":1}}],["避免毁掉预训练中学到的一般知识",{"2":{"74":1}}],["避免遗漏或混乱",{"2":{"72":1}}],["避免违反人类意愿或造成伤害",{"2":{"67":1}}],["送给人类评审",{"2":{"83":1}}],["收集数据像是在建造图书馆",{"2":{"100":1}}],["收集偏好数据",{"2":{"83":1}}],["收集了用户可能提出的各种指令",{"2":{"75":1}}],["满意的回答时",{"2":{"83":1}}],["宪法",{"2":{"82":2}}],["情况",{"2":{"82":1}}],["情感分类示例",{"2":{"106":1}}],["情感",{"2":{"63":2}}],["期望",{"2":{"82":1}}],["造成安全隐患",{"2":{"82":1}}],["未来的模型也许会综合多种手段",{"2":{"122":1}}],["未来可能有进一步研究",{"2":{"118":1}}],["未来会有更多模型突破长度限制",{"2":{"114":1}}],["未来也许通过算法改进",{"2":{"110":1}}],["未来",{"2":{"96":1}}],["未来对齐技术可能是多种手段结合",{"2":{"90":1}}],["未经对齐的模型",{"2":{"82":1}}],["未经对齐的模型可能直接给出步骤",{"2":{"82":1}}],["未对齐模型也许随便安慰两句甚至无视用户情绪开始闲聊",{"2":{"83":1}}],["未对齐模型可能给出一个平淡甚至略负面的故事",{"2":{"83":1}}],["未对齐模型可能胡乱给出诊疗建议甚至引用不存在的药物",{"2":{"67":1}}],["未对齐模型可能直接回骂或者生成更多攻击性语言",{"2":{"67":1}}],["未对齐的模型",{"2":{"67":1}}],["真实",{"2":{"82":1}}],["久而久之模型更倾向于产出人类喜欢的内容",{"2":{"82":1}}],["惩罚不好的回答",{"2":{"82":1}}],["初步对齐于用户意图",{"2":{"82":1}}],["纵轴响应时间",{"2":{"81":1}}],["横轴不同优化开启组合",{"2":{"81":1}}],["降为o",{"2":{"114":1}}],["降幅可能就较小",{"2":{"110":1}}],["降阶梯表示量化降低位宽等等",{"2":{"81":1}}],["降低为线性级",{"2":{"116":1}}],["降低每次调用成本",{"2":{"81":1}}],["降低推理成本",{"2":{"33":1}}],["剪刀表示剪枝减小模型",{"2":{"81":1}}],["制作一个推理扩展流程图",{"2":{"88":1}}],["制作一个",{"2":{"81":1}}],["某项任务的性能随规模平稳提升",{"2":{"110":1}}],["某些",{"2":{"103":1}}],["某些计算来更快给结果",{"2":{"81":1}}],["某公司想用",{"2":{"80":1}}],["跳过",{"2":{"81":1}}],["产生回答",{"2":{"83":1}}],["产生有害后果的风险就越高",{"2":{"67":1}}],["产品的重要性",{"2":{"81":1}}],["做过推理代码优化",{"2":{"81":1}}],["各段内位置重复使用编码",{"2":{"120":1}}],["各司其职",{"2":{"118":1}}],["各种新方案层出不穷",{"2":{"114":1}}],["各种优化手段则从编译和硬件层面挖潜",{"2":{"81":1}}],["各算一份",{"2":{"107":1}}],["各自乘相应块",{"2":{"107":1}}],["各自推理",{"2":{"88":1}}],["各自给出结论",{"2":{"72":1}}],["各自主要贡献有哪些",{"2":{"72":1}}],["加入社区",{"2":{"130":1}}],["加入开发者讨论群",{"2":{"128":1}}],["加一些法律",{"2":{"100":1}}],["加快处理",{"2":{"81":1}}],["加快运算",{"2":{"81":1}}],["加速推理",{"2":{"81":1}}],["瘦身",{"2":{"81":1}}],["代表较长片段被掩盖",{"2":{"93":1}}],["代替",{"2":{"90":1}}],["代数法和几何法",{"2":{"88":1}}],["代价是可能损失一点点精度",{"2":{"81":1}}],["代码等多个库",{"2":{"100":1}}],["代码数据",{"2":{"100":1}}],["代码仓库等",{"2":{"100":1}}],["代码推理",{"2":{"90":1}}],["代码是写给人看的",{"2":{"78":1}}],["代码",{"2":{"33":2,"40":3}}],["代码规范",{"0":{"25":1},"1":{"32":1,"39":1}}],["位",{"2":{"81":1,"120":2}}],["位精度降到",{"2":{"81":1}}],["位置按照比例映射回",{"2":{"120":1}}],["位置插值",{"2":{"120":1}}],["位置外推与内插",{"0":{"120":1}}],["位置编码的改进让模型跳出训练时的长度限制",{"2":{"120":1}}],["位置编码空间",{"2":{"120":1}}],["位置编码",{"2":{"41":1,"120":1,"122":1}}],["位置",{"2":{"40":1}}],["位置与外推",{"2":{"33":1}}],["位置策略",{"2":{"33":2}}],["构成分布式推理",{"2":{"81":1}}],["页",{"2":{"81":1}}],["页的书",{"2":{"81":1}}],["放不下或者算不动时",{"2":{"81":1}}],["秒算",{"2":{"107":1}}],["秒降到",{"2":{"81":1}}],["秒就全部回答完毕了",{"2":{"81":1}}],["秒就都完成了",{"2":{"81":1}}],["秒内就能给出",{"2":{"81":1}}],["秒",{"2":{"81":3}}],["秒总计",{"2":{"81":1}}],["利用上下文预测缺失词",{"2":{"99":1}}],["利用前文预测下文",{"2":{"99":1}}],["利用",{"2":{"83":1}}],["利用并行计算提升吞吐量",{"2":{"81":1}}],["利用率",{"2":{"40":1}}],["擅长理解任务",{"2":{"99":1}}],["擅长同时处理并行任务",{"2":{"81":1}}],["擅长根据已给的上下文生成续写文本",{"2":{"48":1}}],["尤其针对复杂问题",{"2":{"88":1}}],["尤其",{"2":{"81":1}}],["顾客一来立刻取出",{"2":{"81":1}}],["值缓存技术就是在第一次计算时把每一层的中间表示存下来",{"2":{"81":1}}],["值得注意的是",{"2":{"48":1}}],["键",{"2":{"81":1}}],["减少计算",{"2":{"122":1}}],["减少显存占用",{"2":{"104":1}}],["减少对真人评估的依赖",{"2":{"90":1}}],["减少浪费",{"2":{"81":1}}],["减小单一模型偏差",{"2":{"90":1}}],["减轻人类反复调试的负担",{"2":{"80":1}}],["水面下更大的部分是软提示",{"2":{"80":1}}],["露在水面上的是硬提示",{"2":{"80":1}}],["冰山",{"2":{"80":1}}],["右边是自动提示优化流程",{"2":{"80":1}}],["右侧是改进后的具体提示",{"2":{"64":1}}],["左边是传统提示流程",{"2":{"80":1}}],["左侧是笼统提示",{"2":{"64":1}}],["于是调集成百上千的工人",{"2":{"107":1}}],["于是许多改进方法被提出",{"2":{"90":1}}],["于是更有可能生成一封情感到位的道歉信",{"2":{"89":1}}],["于是剪去该分支的情形",{"2":{"88":1}}],["于是每次他们只需在作文前加上",{"2":{"80":1}}],["于是研究者想到",{"2":{"80":1}}],["效果良好",{"2":{"104":1}}],["效果等方面的对比",{"2":{"90":1}}],["效果一般",{"2":{"80":1}}],["效率",{"2":{"41":1,"65":1}}],["符号",{"2":{"80":1}}],["详细场景",{"2":{"80":1}}],["且因为是内部向量",{"2":{"80":1}}],["且在海量语料上训练的语言模型",{"2":{"48":1}}],["潜意识提示",{"2":{"80":1}}],["存在一个最优的模型大小和训练",{"2":{"110":1}}],["存在于模型中",{"2":{"80":1}}],["存储成一种内部状态",{"2":{"73":1}}],["咒语",{"2":{"80":1}}],["算",{"2":{"107":1}}],["算完再将输出交给第",{"2":{"107":1}}],["算法",{"2":{"83":1}}],["算法高效性和工程优化对",{"2":{"81":1}}],["算法生成候选提示",{"2":{"80":1}}],["算法如何在海量可能的提示中寻找更优者",{"2":{"80":1}}],["算力",{"2":{"33":1}}],["衡量某个提示的好坏",{"2":{"80":1}}],["那将打开",{"2":{"122":1}}],["那共享可以让我们加层而参数不增加太多",{"2":{"118":1}}],["那种工具",{"2":{"116":1}}],["那种针对单一任务的微调有所拓展",{"2":{"74":1}}],["那可能是模型学会了新的技能",{"2":{"110":1}}],["那可信度很高",{"2":{"88":1}}],["那英文数据还是主体",{"2":{"100":1}}],["那样",{"2":{"82":1}}],["那么第",{"2":{"120":1}}],["那么==共享参数如何帮助长序列呢",{"2":{"118":1}}],["那么模型对英文非常擅长",{"2":{"100":1}}],["那么集成方法可以是投票选最常见答案",{"2":{"88":1}}],["那么",{"2":{"81":1,"86":1}}],["那",{"2":{"81":1}}],["那让",{"2":{"81":1}}],["那预测任务就失去了挑战",{"2":{"79":1}}],["具备惊人的语言理解和生成能力",{"2":{"124":1}}],["具备了很强的文本生成能力",{"2":{"79":1}}],["具体来说",{"2":{"93":1}}],["具体做法通常是",{"2":{"82":1}}],["具体做法是分两个阶段",{"2":{"72":1}}],["具体做法是",{"2":{"63":1,"83":1,"106":1}}],["具体实现有top",{"2":{"73":1}}],["具体实现中",{"2":{"66":1}}],["具体",{"2":{"64":1}}],["庙里有个和尚在讲故事",{"2":{"79":1}}],["山里有座庙",{"2":{"79":1}}],["源源不断地生成后续内容",{"2":{"79":1}}],["源头提纯避免脏数据与重复",{"2":{"33":1}}],["考虑这样一个比喻",{"2":{"81":1}}],["考虑每种疾病的症状匹配",{"2":{"72":1}}],["考它下一个情节会是什么",{"2":{"79":1}}],["游戏",{"2":{"79":1}}],["灌输给了小模型",{"2":{"75":1}}],["经常用",{"2":{"107":1}}],["经验",{"2":{"75":1}}],["经过上述预训练",{"2":{"103":1}}],["经过这些扩展",{"2":{"88":1}}],["经过这样的训练",{"2":{"75":1}}],["经过",{"2":{"82":1,"83":1}}],["经过精心校准的量化",{"2":{"81":1}}],["经过长时间训练",{"2":{"79":1}}],["经过大量练习后就越来越擅长",{"2":{"79":1}}],["经过监督微调后",{"2":{"75":1}}],["经过对齐的模型更安全可靠",{"2":{"124":1}}],["经过对齐",{"2":{"67":1}}],["万",{"2":{"114":1,"122":1}}],["万亿",{"2":{"110":1}}],["万亿字符以上的数据",{"2":{"100":1}}],["万亿级",{"2":{"33":1}}],["万一某个单次输出有瑕疵",{"2":{"88":1}}],["万条指令数据来微调一个",{"2":{"75":1}}],["项目",{"2":{"75":1}}],["条",{"2":{"75":1}}],["举例",{"2":{"75":1}}],["举例来说",{"2":{"75":1,"80":1,"93":1,"100":1}}],["他对前后步骤的理解是一致的",{"2":{"118":1}}],["他们用相同算力",{"2":{"110":1}}],["他们用了成千上万的问答对来教模型如何扮演各种助理角色",{"2":{"75":1}}],["他们通过试验发现",{"2":{"110":1}}],["他们仅用数周就训练完模型",{"2":{"107":1}}],["他们结合了数据并行和张量并行",{"2":{"107":1}}],["他们现在的提示既短又准",{"2":{"80":1}}],["他们还让模型自己迭代改进提示措辞",{"2":{"80":1}}],["他们发现直接提示",{"2":{"80":1}}],["他有三个女儿",{"2":{"48":1}}],["另外还有缓存高效并行",{"2":{"107":1}}],["另外还有动态检索",{"2":{"88":1}}],["另外",{"2":{"75":1,"80":1,"90":1}}],["另外模型参数足够灵活泛化",{"2":{"75":1}}],["另一类高效技术是减少计算本身的工作量",{"2":{"81":1}}],["另一个缓存思路是在应用级别做缓存",{"2":{"81":1}}],["另一方面",{"2":{"80":1}}],["另一方面参数量大",{"2":{"66":1}}],["另一种是延长输出长度",{"2":{"88":1}}],["另一种提示强调体检和检验结果",{"2":{"72":1}}],["另一种做法是让多个模型各自回答",{"2":{"72":1}}],["遇到新形式的指令也能处理",{"2":{"75":1}}],["遇到危险请求要拒绝等",{"2":{"67":1}}],["研究者开发了多种方法",{"2":{"124":1}}],["研究者观察到",{"2":{"110":1}}],["研究者和工程师们在标准",{"2":{"104":1}}],["研究者会爬取公开网络数据",{"2":{"100":1}}],["研究者不停优化",{"2":{"96":1}}],["研究者也在探索自动化和优化提示的途径",{"2":{"87":1}}],["研究发现这些偏置对模型最终性能影响不大",{"2":{"104":1}}],["研究发现",{"2":{"88":1}}],["研究发现即使只有几百条高质量指令示例",{"2":{"75":1}}],["研究表明",{"2":{"72":1}}],["时间感",{"2":{"120":1}}],["时非常关键的概念",{"2":{"89":1}}],["时采用了",{"2":{"82":1}}],["时",{"2":{"75":3,"80":1,"89":1,"90":1,"103":1}}],["甚至更长",{"2":{"114":1}}],["甚至取消了",{"2":{"103":1}}],["甚至我们可以让",{"2":{"88":1}}],["甚至训练一个小模型来挑或合成答案",{"2":{"88":1}}],["甚至有论文提出让模型在脑海里构建树形或图形的推理结构",{"2":{"88":1}}],["甚至让模型自行概括提示",{"2":{"80":1}}],["甚至可以让一个强模型生成指令和回答",{"2":{"75":1}}],["甚至跨越纯统计",{"2":{"48":1}}],["首先要有",{"2":{"100":1}}],["首先",{"2":{"75":1}}],["教会模型遵循人类指令",{"2":{"74":1}}],["见下节",{"2":{"74":1}}],["见过的语料越丰富",{"2":{"48":1}}],["少量",{"2":{"74":1}}],["少样本学习",{"2":{"63":1}}],["将是持续的挑战",{"2":{"124":1}}],["将所有层的参数共享",{"2":{"118":1}}],["将前一个",{"2":{"116":1}}],["将很长的输入分成块",{"2":{"114":1}}],["将复杂度从o",{"2":{"114":1}}],["将上下文扩展到",{"2":{"114":1}}],["将单个层内部的矩阵运算拆分",{"2":{"107":1}}],["将模型本身拆开",{"2":{"107":1}}],["将会减少很多调参烦恼",{"2":{"104":1}}],["将这些词替换为",{"2":{"103":1}}],["将低质量数据剔除",{"2":{"100":1}}],["将损坏的文本复原",{"2":{"93":1}}],["将人类意图更精准地传达给模型",{"2":{"89":1}}],["将为后续与大模型打交道打下坚实基础",{"2":{"87":1}}],["将大语言模型与世界对齐",{"0":{"82":1}}],["将",{"2":{"74":1,"82":1}}],["遵守对话礼仪等",{"2":{"74":1}}],["遵循用户指令",{"2":{"67":1}}],["理论上",{"2":{"120":1}}],["理由者模型",{"2":{"88":1}}],["理想情况下",{"2":{"81":1,"107":1}}],["理想回答",{"2":{"74":1}}],["理解世界的新维度",{"2":{"122":1}}],["理解",{"2":{"79":1,"93":1}}],["理性的助手的形象",{"2":{"67":1}}],["进一步的章节将深入提示工程",{"2":{"124":1}}],["进一步雕琢模型的性格",{"2":{"96":1}}],["进一步用人类偏好优化模型输出",{"2":{"82":1}}],["进行有监督微调",{"2":{"75":1}}],["进行价值观和安全方面的微调也很重要",{"2":{"74":1}}],["进行微调",{"2":{"74":1,"103":1}}],["进阶提示则利用了模型强大的潜力",{"2":{"87":1}}],["进阶提示方法思维导图",{"2":{"72":1}}],["进阶提示方法通过让模型显式",{"2":{"72":1}}],["进阶提示方法",{"0":{"72":1}}],["进阶方法",{"2":{"33":1,"34":1,"54":1}}],["响应速度和资源占用是非常关键的",{"2":{"81":1}}],["响应数据来微调模型",{"2":{"75":1}}],["响应示例",{"2":{"75":1}}],["响应",{"2":{"74":1}}],["新模型如",{"2":{"110":1}}],["新闻文章",{"2":{"100":1}}],["新颖",{"2":{"73":1}}],["新场景不慌抗噪更稳",{"2":{"33":1}}],["70",{"2":{"110":1}}],["7b",{"2":{"75":1}}],["7",{"2":{"73":1}}],["树上标注不同搜索策略如何遍历这棵树",{"2":{"73":1}}],["起始节点是模型读入的",{"2":{"73":1}}],["严格策略下措辞安全中规中矩",{"2":{"73":1}}],["能拒绝不良请求并减少胡编乱造",{"2":{"124":1}}],["能在合理资源内处理更多信息",{"2":{"122":1}}],["能阅读报告",{"2":{"122":1}}],["能",{"2":{"110":1}}],["能扩大覆盖场景",{"2":{"90":1}}],["能达到和",{"2":{"90":1}}],["能完全相信它自己的判定吗",{"2":{"88":1}}],["能力",{"2":{"124":1}}],["能力越大",{"2":{"96":1}}],["能力的推理",{"2":{"88":1}}],["能力大幅提升",{"2":{"86":1}}],["能够处理过去望尘莫及的大段文本输入",{"2":{"124":1}}],["能够最大限度发挥",{"2":{"124":1}}],["能够在不改变内部参数的情况下",{"2":{"87":1}}],["能够给出正确",{"2":{"75":1}}],["能讲一个关于友谊的短故事吗",{"2":{"83":1}}],["能否找到更经济的表示方法",{"2":{"80":1}}],["能不能让机器来自动优化提示",{"2":{"80":1}}],["能更好地驱动模型输出符合期望的内容",{"2":{"73":1}}],["能显著提升模型在复杂任务上的表现",{"2":{"72":1}}],["说",{"2":{"79":1}}],["说话风格的遥控器",{"2":{"73":1}}],["说明角色和背景",{"2":{"64":1}}],["说明",{"2":{"33":81}}],["掌握编写清晰指令",{"2":{"124":1}}],["掌握提示工程的基本原则",{"2":{"87":1}}],["掌握这些解码策略",{"2":{"73":1}}],["掌握claude插件开发的完整流程",{"2":{"6":1}}],["发展的关键主题",{"2":{"96":1}}],["发挥威力的一个关键",{"2":{"95":1}}],["发挥最佳水平",{"2":{"73":1}}],["发现不符合就会警觉并修正",{"2":{"88":1}}],["发送邮件通知",{"2":{"61":1}}],["发送邮件到",{"2":{"36":1}}],["高级对齐技巧和高效推理方法",{"2":{"124":1}}],["高级功能",{"0":{"76":1},"1":{"84":1,"91":1}}],["高效注意力降低长序列计算开销",{"2":{"124":1}}],["高效架构是一个活跃研究领域",{"2":{"114":1}}],["高效架构指的是对注意力机制进行改造或近似",{"2":{"114":1}}],["高效架构",{"0":{"114":1}}],["高效推理就是想办法提升出餐速度",{"2":{"81":1}}],["高效推理技术让强大的模型真正用得起",{"2":{"81":1}}],["高效推理技术是保证",{"2":{"81":1}}],["高效推理技术关注如何让模型尽快给出答案",{"2":{"81":1}}],["高效推理技术",{"0":{"81":1}}],["高效推理与系统",{"2":{"33":1}}],["高效推理",{"2":{"33":1,"34":1,"65":1}}],["高温度采样",{"2":{"73":1}}],["低秩近似",{"2":{"114":1}}],["低温度或束搜索",{"2":{"73":1}}],["低质剔除",{"2":{"57":1}}],["总的目标是",{"2":{"114":1}}],["总的来说",{"2":{"67":1,"99":1,"107":1,"118":1}}],["总词数达数十亿",{"2":{"103":1}}],["总体来说",{"2":{"90":1}}],["总结",{"0":{"124":1}}],["总结地说",{"2":{"82":1}}],["总结一下",{"2":{"73":1}}],["总之让输入变得不完整或有噪音",{"2":{"93":1}}],["总之",{"2":{"81":1,"88":1,"90":1,"104":1,"120":1}}],["函数专门打压那些违背安全规范的输出",{"2":{"73":1}}],["函数签名",{"2":{"54":1}}],["保存模型前面的中间结果",{"2":{"116":1}}],["保证输出既不啰嗦也不触雷",{"2":{"73":1}}],["保护敏感数据",{"2":{"59":1}}],["禁止词约束等技巧",{"2":{"73":1}}],["禁用词表",{"2":{"54":1}}],["随后人们意识到",{"2":{"110":1}}],["随后增大提高效率",{"2":{"104":1}}],["随机地将输入序列中一些词用特殊标记",{"2":{"86":1}}],["随机策略下可能产生让人耳目一新的句子",{"2":{"73":1}}],["随机采样是在高概率子树里随机跳",{"2":{"73":1}}],["随机采样赋予创造力",{"2":{"73":1}}],["随机采样",{"2":{"73":1}}],["随着硬件进步",{"2":{"122":1}}],["随着人们不断尝试更大的模型和更多的数据",{"2":{"110":1}}],["随着模型参数数量和训练数据量增加呈现近似幂定律衰减",{"2":{"110":1}}],["随着模型变得越来越大",{"2":{"104":1}}],["随着模型越来越强大",{"2":{"96":1}}],["随着模型能力增强",{"2":{"67":1}}],["随着无数个批次迭代",{"2":{"66":1}}],["依次串行",{"2":{"107":1}}],["依然是打造强大语言模型的标准流程",{"2":{"106":1}}],["依然缺乏多样性",{"2":{"73":1}}],["依赖检索",{"2":{"33":1}}],["然而在生成式",{"2":{"118":1}}],["然而许多应用需要处理超长文本",{"2":{"112":1}}],["然而研究表明在某些",{"2":{"75":1}}],["然而",{"2":{"74":1,"86":2}}],["然而对于非常开放的生成任务",{"2":{"73":1}}],["然后设计一种机制在块之间传递信息",{"2":{"114":1}}],["然后我们利用一组带标签的示例句子",{"2":{"106":1}}],["然后我们再教它执行特定任务",{"2":{"46":1}}],["然后自己评价哪段对话语气更友好",{"2":{"90":1}}],["然后训练一个",{"2":{"90":1}}],["然后训练模型根据上下文猜出这些被遮住的词",{"2":{"86":1}}],["然后筛选出正确路径的过程",{"2":{"88":1}}],["然后模型自己或另一个验证模型检查这两个方案哪个结果正确",{"2":{"88":1}}],["然后选择最好的一个输出用户",{"2":{"88":1}}],["然后选择出现次数最多的答案作为最终结果",{"2":{"72":1}}],["然后用正确的语序生成",{"2":{"93":1}}],["然后用解码器生成输出序列",{"2":{"93":1}}],["然后用少量高质量人类反馈做",{"2":{"90":1}}],["然后用奖励模型",{"2":{"90":1}}],["然后用",{"2":{"83":1}}],["然后通过反馈不断调整",{"2":{"82":1}}],["然后通过问题分解",{"2":{"72":1}}],["然后让模型预测这些位置原本的词",{"2":{"103":1}}],["然后让模型把缺失的部分填回去",{"2":{"93":1}}],["然后让模型去猜原句是什么",{"2":{"93":1}}],["然后让模型通过试错学习去最大化奖励",{"2":{"82":1}}],["然后让人或一个",{"2":{"82":1}}],["然后分叉代表每一步可能的下一个词",{"2":{"73":1}}],["然后预测下一个",{"2":{"73":1}}],["然后采用多数投票或平均融合概率的方式决定最终答案",{"2":{"72":1}}],["然后在使用时把",{"2":{"64":1}}],["然后基于概率选一个合适的续写",{"2":{"48":1}}],["然后再微调模型少许步长",{"2":{"120":1}}],["然后再微调到对话任务",{"2":{"53":1}}],["然后再合并结果",{"2":{"107":1}}],["然后再将",{"2":{"107":1}}],["然后再将这个模型应用到具体任务上",{"2":{"46":1}}],["然后再回答",{"2":{"72":1}}],["然后再提示模型审视这个回答并改进",{"2":{"72":1}}],["然后再进行比较",{"2":{"72":1}}],["然后再给出具体待翻译的句子",{"2":{"64":1}}],["然后再",{"2":{"46":1}}],["然后探讨如何训练和微调这些模型",{"2":{"41":1}}],["然后",{"2":{"33":3,"75":1,"93":1}}],["此外还有重复惩罚",{"2":{"73":1}}],["此外",{"2":{"73":1,"88":1,"100":1,"104":1}}],["记忆机制更进一步",{"2":{"116":1}}],["记忆力超群",{"2":{"114":1}}],["记忆",{"2":{"73":1,"116":1,"122":1}}],["记住了之前章节内容",{"2":{"81":1}}],["记住",{"2":{"66":1,"78":1,"102":1,"116":1,"130":1}}],["接下来",{"2":{"124":1}}],["接龙",{"2":{"79":1}}],["接一个字地生成输出",{"2":{"73":1}}],["接着我们可以要求",{"2":{"72":1}}],["接着",{"2":{"41":1,"82":1,"94":1}}],["节我们会讲retrieval",{"2":{"116":1}}],["节详述",{"2":{"104":1}}],["节详细讨论",{"2":{"74":1}}],["节已经举了一些提示例子",{"2":{"89":1}}],["节提到的",{"2":{"82":1}}],["节省内存",{"2":{"107":1}}],["节省时间",{"2":{"81":1}}],["节省了大量计算",{"2":{"73":1}}],["节会详谈工程上的解决方案",{"2":{"66":1}}],["打包插件",{"0":{"101":1}}],["打乱句子顺序",{"2":{"93":1}}],["打分",{"2":{"90":1}}],["打分器",{"2":{"57":1}}],["打个比方",{"2":{"73":1,"80":1,"90":1}}],["向量对于正面句子和负面句子显现出区别",{"2":{"106":1}}],["向量替代长文本",{"2":{"80":1}}],["向量库与近邻检索不会就临时查",{"2":{"33":1}}],["向外分支链出",{"2":{"72":1}}],["绘制一个对齐技术进化树或流程图",{"2":{"90":1}}],["绘制一个对比图",{"2":{"80":1}}],["绘制一个",{"2":{"72":1}}],["病史等",{"2":{"72":1}}],["病人出现发烧",{"2":{"72":1}}],["肋膜炎",{"2":{"72":1}}],["肺炎",{"2":{"72":1}}],["咳嗽和胸痛",{"2":{"72":1}}],["思路更清晰",{"2":{"88":1}}],["思路在",{"2":{"88":1}}],["思想吻合",{"2":{"88":1}}],["思考人类快读和略读的方法",{"2":{"81":1}}],["思考",{"2":{"72":1,"99":1}}],["思维链",{"2":{"33":2,"54":1}}],["思维链与问题分解",{"2":{"33":1}}],["思维链与问题分解与自我反思与集成",{"2":{"33":1}}],["查资料",{"2":{"72":1}}],["查询生成",{"2":{"54":1}}],["查询检索拼提示再生成更靠谱",{"2":{"33":1}}],["虽然略读可能漏掉细节",{"2":{"114":1}}],["虽然这些近似会损失一些精度",{"2":{"114":1}}],["虽然获取逐步标注很费力",{"2":{"90":1}}],["虽然它为此做了比平常回答多几倍的计算",{"2":{"88":1}}],["虽然强模型可能学到弱模型的错误",{"2":{"75":1}}],["虽然积累了海量知识",{"2":{"75":1}}],["虽然",{"2":{"72":1,"74":1}}],["取决于我们希望模型擅长什么",{"2":{"99":1}}],["取长补短",{"2":{"72":1}}],["取舍",{"2":{"33":1}}],["得到跟单机处理整个",{"2":{"107":1}}],["得到两个解答后",{"2":{"88":1}}],["得到一个医疗助手模型",{"2":{"74":1}}],["得到",{"2":{"74":1}}],["得到多个答案",{"2":{"72":1}}],["得到初译结果",{"2":{"72":1}}],["得到下个词概率",{"2":{"56":1}}],["逻辑推理等任务非常有益",{"2":{"72":1}}],["若直接回答",{"2":{"72":1}}],["现代",{"2":{"104":1}}],["现代硬件",{"2":{"81":1}}],["现在您可以",{"2":{"130":1}}],["现在突然让你背",{"2":{"120":1}}],["现在可以明白",{"2":{"94":1}}],["现在应用推理时扩展",{"2":{"88":1}}],["现在有多少",{"2":{"72":1}}],["现实展望",{"2":{"122":1}}],["现实应用中",{"2":{"116":1}}],["现实意义是",{"2":{"81":1}}],["现实中",{"2":{"80":1,"120":1}}],["现实例子",{"2":{"79":1,"93":1,"114":1}}],["现实模型例子",{"2":{"56":1}}],["又充分利用多机加速训练",{"2":{"107":1}}],["又运行时保险",{"2":{"90":1}}],["又例如提问一个有歧义的问题",{"2":{"89":1}}],["又比如",{"2":{"82":1,"83":1}}],["又保留一定惊喜",{"2":{"73":1}}],["又称核采样",{"2":{"73":1}}],["又买进",{"2":{"72":1}}],["又如",{"2":{"67":1}}],["卖出",{"2":{"72":1}}],["个梯度相加",{"2":{"107":1}}],["个不同措辞的回答",{"2":{"90":1}}],["个不同候选输出",{"2":{"90":1}}],["个候选中",{"2":{"90":1}}],["个作文",{"2":{"90":1}}],["个答案",{"2":{"88":1}}],["个回答",{"2":{"81":1}}],["个问题分",{"2":{"81":1}}],["个问题",{"2":{"81":1}}],["个用户提问",{"2":{"81":1}}],["个请求",{"2":{"81":1}}],["个最有希望的",{"2":{"73":1}}],["个",{"2":{"72":2,"107":2,"112":1}}],["个苹果",{"2":{"72":1}}],["个适合家庭的有趣周末活动",{"2":{"64":1}}],["链式思维和问题分解使模型一步步完成推理",{"2":{"72":1}}],["链式思维提示要求模型在给出最终答案前先列出中间的思考步骤",{"2":{"72":1}}],["链式思维",{"2":{"72":2}}],["地从海量文本中学习",{"2":{"71":1}}],["仅用预训练的",{"2":{"106":1}}],["仅看最终答案对错可能不够",{"2":{"90":1}}],["仅编码器模型通过掩码填空学会理解文本",{"2":{"109":1}}],["仅编码器",{"2":{"99":1}}],["仅编码器预训练中最流行的方法是",{"2":{"86":1}}],["仅编码器架构的模型旨在理解文本而非生成文本",{"2":{"86":1}}],["仅编码器架构和编码器",{"2":{"71":1}}],["仅编码器的预训练",{"0":{"86":1}}],["仅解码器模型通过下一词预测学会生成文本",{"2":{"109":1}}],["仅解码器预训练类似于让模型看一部小说",{"2":{"79":1}}],["仅解码器的预训练",{"0":{"79":1}}],["仅解码器",{"0":{"56":1},"2":{"99":1}}],["仅解码器架构的模型专注于文本生成",{"2":{"79":1}}],["仅解码器架构就像人写文章时",{"2":{"56":1}}],["仅解码器架构",{"2":{"34":1}}],["咨询专业医生",{"2":{"67":1}}],["毕竟模型不懂医疗伦理",{"2":{"67":1}}],["会参考这些规律",{"2":{"110":1}}],["会不会降低它探索创新解答的能力",{"2":{"90":1}}],["会对训练造成什么影响",{"2":{"90":1}}],["会先参考这些已知定理",{"2":{"88":1}}],["会给高分",{"2":{"83":1}}],["会随着用户使用和反馈进行迭代改进",{"2":{"82":1}}],["会变得更倾向于给出有帮助",{"2":{"82":1}}],["会过滤或惩罚模型输出不当内容的倾向",{"2":{"74":1}}],["会发生什么问题",{"2":{"73":1}}],["会错失全局更优解",{"2":{"73":1}}],["会回应类似",{"2":{"67":1}}],["会查资料会用工具再回答",{"2":{"33":1}}],["惹是生非",{"2":{"67":1}}],["没有给出具体的答案或分类",{"2":{"103":1}}],["没有一种算法适用于所有场景",{"2":{"73":1}}],["没有对齐",{"2":{"67":1}}],["没有放之四海皆准的公式",{"2":{"64":1}}],["懂规矩",{"2":{"67":1}}],["知道大量知识但不知道我们的具体需求",{"2":{"106":1}}],["知道很多",{"2":{"75":1}}],["知礼仪",{"2":{"67":1}}],["知识触发词",{"2":{"54":1}}],["花了大量精力对齐模型",{"2":{"67":1}}],["花费数千个",{"2":{"66":1}}],["还是",{"2":{"120":1}}],["还是理解模型的回应",{"2":{"87":1}}],["还在往更长对话",{"2":{"116":1}}],["还需要我们巧妙地",{"2":{"94":1}}],["还原",{"2":{"93":1}}],["还常结合少量人类验证",{"2":{"90":1}}],["还可以举一个安全性的例子",{"2":{"83":1}}],["还学会适当地拒绝不合理要求",{"2":{"83":1}}],["还能触类旁通",{"2":{"75":1}}],["还能执行以前需要专门算法的分析任务",{"2":{"48":1}}],["还有像视频",{"2":{"122":1}}],["还有种折中方式",{"2":{"120":1}}],["还有一些尝试",{"2":{"116":1}}],["还有",{"2":{"114":1,"120":1}}],["还有chinchilla",{"2":{"110":1}}],["还有其它工程手段",{"2":{"104":1}}],["还有glu",{"2":{"104":1}}],["还有rmsnorm这样的变体层归一化",{"2":{"104":1}}],["还有人在更精细的维度上监督模型",{"2":{"90":1}}],["还有研究探索更复杂的奖励函数",{"2":{"90":1}}],["还有利用硬件加速器",{"2":{"81":1}}],["还有专家模型并行等等",{"2":{"81":1}}],["还有项目开源人类写的问题答案集合",{"2":{"75":1}}],["还有让模型使用计算器",{"2":{"72":1}}],["还因为",{"2":{"67":1}}],["之间频繁同步中间结果",{"2":{"107":1}}],["之所以",{"2":{"100":1}}],["之所以比早期的",{"2":{"67":1}}],["之后模型在数学问答中不仅答案正确",{"2":{"90":1}}],["之后我们可以从中投票选出最好的要点",{"2":{"72":1}}],["之后的概率",{"2":{"48":3}}],["隐私信息和法律风险内容",{"2":{"100":1}}],["隐私信息",{"2":{"67":1}}],["按照约",{"2":{"110":1}}],["按照示例风格回答",{"2":{"75":1}}],["按结果来看是正确的",{"2":{"90":1}}],["按你说的做",{"2":{"75":1}}],["按要求格式回答等",{"2":{"67":1}}],["按指定步骤与格式给出答案",{"2":{"33":1}}],["守规矩",{"2":{"67":1}}],["听话懂事",{"2":{"82":1}}],["听话",{"2":{"67":1,"74":1}}],["听音乐",{"2":{"42":1}}],["价值观和现实知识",{"2":{"82":1}}],["价值和指令",{"2":{"67":1}}],["价值基线",{"2":{"57":1}}],["调试与测试",{"0":{"117":1},"1":{"119":1,"121":1}}],["调整模型参数让",{"2":{"106":1}}],["调整",{"2":{"90":1}}],["调整超参数",{"2":{"66":1}}],["调教模型",{"2":{"83":1,"87":1}}],["调度与系统",{"2":{"65":1}}],["书本",{"2":{"66":1}}],["书籍和",{"2":{"100":1}}],["书籍",{"2":{"40":1,"46":1,"53":1}}],["野生",{"2":{"82":1}}],["野",{"2":{"66":1}}],["后来的研究发现",{"2":{"103":1}}],["后来他们采用提示优化算法",{"2":{"80":1}}],["后续我们只需稍加引导",{"2":{"86":1}}],["后续回答时直接接着算新内容",{"2":{"81":1}}],["后续生成新词时重复利用",{"2":{"81":1}}],["后面推理时不用每次从头再读",{"2":{"81":1}}],["后面的词是什么",{"2":{"79":1}}],["后面会谈",{"2":{"74":1}}],["后面无法反悔纠正",{"2":{"73":1}}],["后面",{"2":{"66":1}}],["后端工程实践",{"2":{"15":1}}],["后端技术",{"0":{"11":1,"12":1,"15":1}}],["太大消耗高",{"2":{"88":1}}],["太大会消耗计算",{"2":{"73":1}}],["太大会发散",{"2":{"66":1}}],["太小则作用有限",{"2":{"73":1}}],["太小训练慢",{"2":{"66":1}}],["日历等工具",{"2":{"72":1}}],["日的计算",{"2":{"66":1}}],["日常开发中的实战经验",{"2":{"21":1}}],["像是人配了一本笔记本",{"2":{"116":1}}],["像是人只有短期记忆",{"2":{"116":1}}],["像",{"2":{"66":1,"120":1}}],["文本数据",{"2":{"66":1}}],["文章",{"2":{"46":1}}],["计算量和内存允许的话",{"2":{"120":1}}],["计算再合并",{"2":{"81":1}}],["计算成本低",{"2":{"80":1}}],["计算模型在这些序列上预测下个词的误差",{"2":{"66":1}}],["计划执行器",{"2":{"54":1}}],["θ",{"2":{"66":1}}],["即位置索引乘以",{"2":{"120":1}}],["即先用指令微调对齐模型行为",{"2":{"109":1}}],["即使我们采用高效注意力和记忆",{"2":{"120":1}}],["即使采用高效注意力",{"2":{"116":1}}],["即使在现在更先进的",{"2":{"106":1}}],["即使是小规模微调",{"2":{"74":1}}],["即在残差连接之后做",{"2":{"104":1}}],["即在任务数据上训练一个小的附加网络",{"2":{"103":1}}],["即人类反馈强化学习",{"2":{"82":1}}],["即根据已有的文本内容预测下一个词",{"2":{"79":1}}],["即出现过拟合",{"2":{"66":1}}],["即",{"2":{"66":1}}],["即每个词只能看见它前面的词",{"2":{"56":1}}],["^",{"2":{"66":1}}],["设想我们已经有人类偏好比较数据",{"2":{"90":1}}],["设大一些以免错失好的解答",{"2":{"88":1}}],["设训练集包含大量序列",{"2":{"66":1}}],["设计模式应用",{"0":{"70":1},"1":{"78":1}}],["设计提示往往需要反复试验",{"2":{"64":1}}],["设计原则",{"0":{"59":1}}],["尾延迟限制",{"2":{"65":1}}],["批不到",{"2":{"81":1}}],["批改英文作文并给分",{"2":{"80":1}}],["批量处理相关请求",{"2":{"68":1}}],["批过大",{"2":{"65":1}}],["批处理到并行化",{"2":{"94":1}}],["批处理和并行化充分利用硬件并行能力",{"2":{"81":1}}],["批处理能显著降低单位请求的计算成本",{"2":{"81":1}}],["批处理的难点在于对齐不同长度的输入",{"2":{"81":1}}],["批处理就是把多个输入一起交给模型",{"2":{"81":1}}],["批处理策略",{"2":{"33":1}}],["批处理",{"2":{"33":2,"65":1,"81":1}}],["校准集合",{"2":{"65":1}}],["显存的模型现在",{"2":{"81":1}}],["显存占用",{"2":{"65":1}}],["显式写过程",{"2":{"33":1}}],["显式写过程先拆后合",{"2":{"33":1}}],["路径生成",{"2":{"65":1}}],["路径可自适应",{"2":{"33":1}}],["连续",{"2":{"120":1}}],["连续批处理",{"2":{"65":1}}],["连续提示向量",{"2":{"33":1}}],["里的大矩阵乘法",{"2":{"107":1}}],["里很多线性映射都有对应的偏置参数",{"2":{"104":1}}],["里面标注占位符如何被具体内容替换",{"2":{"64":1}}],["里频繁出现",{"2":{"48":1}}],["流水线推理",{"2":{"81":1}}],["流水线式计算",{"2":{"81":1}}],["流水并行按资源选择",{"2":{"33":1}}],["流水并行",{"2":{"33":2,"65":1}}],["流感",{"2":{"72":1}}],["流程图",{"2":{"64":1}}],["什么因素会影响",{"2":{"64":1}}],["什么是claude插件",{"0":{"9":1}}],["引入非线性",{"2":{"104":1}}],["引入人类多维度反馈",{"2":{"90":1}}],["引入了一个额外的符号",{"2":{"86":1}}],["引入随机能产生更多样化",{"2":{"73":1}}],["引导提问",{"2":{"89":1}}],["引导模型遵守人类意图和价值观",{"2":{"124":1}}],["引导模型输出情感标签",{"2":{"89":1}}],["引导模型产生特定行为",{"2":{"80":1}}],["引导性问题",{"2":{"64":1,"67":1,"72":1,"73":1,"75":1,"80":1,"81":1,"83":1,"88":1,"90":1}}],["引用证据",{"2":{"54":1}}],["往往潜藏着比默认输出更好的答案",{"2":{"90":1}}],["往往能挑到一个不错的答复质量接近甚至超过原",{"2":{"90":1}}],["往往几乎不损伤模型效果",{"2":{"81":1}}],["往往结果不够理想",{"2":{"74":1}}],["往往隐含地使用多步推理和工具调用来产生更精准的回答",{"2":{"72":1}}],["往往不行",{"2":{"66":1}}],["往往不同",{"2":{"63":1}}],["往往会给出更丰富且贴合需求的回答",{"2":{"64":1}}],["给模型配备一个读写记忆的模块",{"2":{"116":1}}],["给模型充分的信息和明确要求",{"2":{"89":1}}],["给含糊或有害的回答低分",{"2":{"83":1}}],["给这篇作文打分并反馈",{"2":{"80":1}}],["给出一个答案",{"2":{"88":1}}],["给出开头几个词",{"2":{"79":1}}],["给出更好的版本",{"2":{"72":1}}],["给",{"2":{"75":1}}],["给定问题输出答案等等",{"2":{"93":1}}],["给定这句话",{"2":{"86":1}}],["给定",{"2":{"73":1}}],["给输出引入随机性",{"2":{"73":1}}],["给我周末有趣的活动建议",{"2":{"64":1}}],["给二到五个好例子让模型照着来",{"2":{"33":1}}],["清晰的指令有助于模型产出符合预期的结果",{"2":{"89":1}}],["清晰描述任务",{"2":{"89":1}}],["清晰而有针对性的提示能引导模型输出更有用的结果",{"2":{"64":1}}],["清晰",{"2":{"64":1}}],["清晰明确的提示能得到更相关的回应",{"2":{"64":1}}],["清洗还可能包括分句",{"2":{"100":1}}],["清洗",{"2":{"33":2,"40":1}}],["直观点",{"2":{"110":1}}],["直观理解",{"2":{"83":1}}],["直观上",{"2":{"82":1}}],["直观展示优化叠加如何将推理时间从比如",{"2":{"81":1}}],["直到完成",{"2":{"73":1}}],["直到遇到终止条件",{"2":{"73":1}}],["直到找到",{"2":{"64":1}}],["直觉上",{"2":{"66":1}}],["直接看十万长度",{"2":{"114":1}}],["直接上任务",{"2":{"106":1}}],["直接用偏好数据来微调模型",{"2":{"90":1}}],["直接用偏好对优化策略更简单稳定",{"2":{"33":1}}],["直接用人类标注的正确输出来细调模型",{"2":{"75":1}}],["直接描述清楚背景和要求",{"2":{"64":1}}],["直接转换为模型擅长的文本生成形式",{"2":{"63":1}}],["直接偏好优化",{"2":{"33":2,"57":1,"90":2}}],["提交您的插件到",{"2":{"128":1}}],["提高到",{"2":{"112":1}}],["提高找到正确解的机会",{"2":{"88":1}}],["提出",{"2":{"104":1,"110":1}}],["提速技巧",{"2":{"81":1}}],["提升模型的安全性和可靠性",{"2":{"96":1}}],["提升计算效率",{"2":{"81":1}}],["提升效率",{"2":{"81":1}}],["提建议",{"2":{"75":1}}],["提问",{"2":{"72":1}}],["提供示例和上下文的提示技巧",{"2":{"124":1}}],["提供了更灵活的变换能力",{"2":{"104":1}}],["提供了额外的",{"2":{"88":1}}],["提供必要背景",{"2":{"89":1}}],["提供必要上下文",{"2":{"64":1}}],["提供线索",{"2":{"86":1}}],["提供调节旋钮",{"2":{"73":1}}],["提供可靠信息并在不确定时建议",{"2":{"67":1}}],["提供上下文和示例",{"2":{"64":1}}],["提示完成任务",{"2":{"124":1}}],["提示不需要遵循固定格式",{"2":{"89":1}}],["提示不需要重新训练模型",{"2":{"63":1}}],["提示里可以补充背景以消除歧义",{"2":{"89":1}}],["提示中应明确告诉模型你想要它做什么",{"2":{"89":1}}],["提示就是我们喂给模型的输入",{"2":{"89":1}}],["提示就像给模型下指令或提供范例",{"2":{"63":1}}],["提示技巧或外部知识填满它",{"2":{"88":1}}],["提示学习的效果",{"2":{"80":1}}],["提示长度缩减则关注如何用最少的字达成同样的意图",{"2":{"80":1}}],["提示长度缩减的重要意义在于",{"2":{"80":1}}],["提示长度缩减",{"2":{"80":1}}],["提示调优",{"2":{"80":1}}],["提示搜索空间",{"2":{"80":1}}],["提示优化的目标是尽可能减少人工干预",{"2":{"80":1}}],["提示优化",{"2":{"80":2}}],["提示可能覆盖不同方面",{"2":{"72":1}}],["提示可以很简单",{"2":{"64":1}}],["提示模板",{"2":{"64":1}}],["提示设计的好坏直接影响模型输出的质量",{"2":{"89":1}}],["提示设计已经演变成一门艺术和科学相结合的学问",{"2":{"87":1}}],["提示设计中",{"2":{"64":1}}],["提示设计强调清晰和具体",{"2":{"64":1}}],["提示是与",{"2":{"64":1}}],["提示和微调各有优势",{"2":{"63":1}}],["提示压缩",{"2":{"54":1}}],["提示结构",{"2":{"54":1}}],["提示工程需要试错和经验积累",{"2":{"64":1}}],["提示工程策略通常是经验性的",{"2":{"64":1}}],["提示工程",{"2":{"33":3,"64":1}}],["提示",{"0":{"54":1,"89":1},"1":{"64":1,"72":1,"80":1,"87":1},"2":{"33":2,"54":1,"63":1,"64":1,"72":1,"80":1,"81":1,"89":2,"104":1,"124":1,"130":1}}],["提示方法",{"0":{"47":1},"1":{"54":1,"64":1,"72":1,"80":1,"87":1},"2":{"27":1,"34":1,"63":1}}],["回复",{"2":{"82":1}}],["回应数据来微调",{"2":{"82":1}}],["回答既正确又优雅",{"2":{"90":1}}],["回答既有帮助又守规",{"2":{"83":1}}],["回答优于",{"2":{"90":1}}],["回答问题是一家披萨店做披萨",{"2":{"81":1}}],["回答更准确",{"2":{"75":1}}],["回答有礼有据",{"2":{"74":1}}],["回答一个医学诊断问题",{"2":{"72":1}}],["回答",{"2":{"64":1,"83":1,"90":1}}],["回顾一下",{"2":{"56":1}}],["身份",{"2":{"64":1}}],["常用的并行策略包括",{"2":{"107":1}}],["常用",{"2":{"83":1}}],["常见问题缓存可以极大减少模型调用次数",{"2":{"81":1}}],["常见的如",{"2":{"104":1}}],["常见的两步对齐流程是",{"2":{"82":1}}],["常见的几种策略",{"2":{"73":1}}],["常见的提示策略包括",{"2":{"64":1}}],["常量",{"2":{"32":1}}],["同样",{"2":{"81":1}}],["同样地",{"2":{"67":1}}],["同时",{"2":{"118":1}}],["同时参与同一层计算",{"2":{"107":1}}],["同时探索多条路径再选优",{"2":{"88":1}}],["同时有",{"2":{"81":1}}],["同时保证模型表现不下降",{"2":{"80":1}}],["同时保留多个候选输出序列",{"2":{"73":1}}],["同时我们可以调节温度",{"2":{"73":1}}],["同理",{"2":{"64":1,"110":1}}],["同步通信",{"0":{"51":1}}],["朋友可能无法给出满意答复",{"2":{"64":1}}],["你虽然训练时没见过",{"2":{"120":1}}],["你要从全世界搜集书籍",{"2":{"100":1}}],["你可以尝试重新表述问题",{"2":{"89":1}}],["你可以尝试向朋友倾诉",{"2":{"83":1}}],["你可以通过搜索获取信息",{"2":{"72":1}}],["你能想到生活中哪些场景相当于缓存和批处理吗",{"2":{"81":1}}],["你能想到哪些日常类比来解释为什么提示要具体明确吗",{"2":{"64":1}}],["你问了长长一段话",{"2":{"81":1}}],["你认为有没有完全不需要人参与的对齐方法",{"2":{"90":1}}],["你认为软提示的优势是什么",{"2":{"80":1}}],["你认为为什么一个性能很强的语言模型仍然需要专门的对齐",{"2":{"67":1}}],["你会发现",{"2":{"89":1}}],["你会优先选择哪些类型的问答",{"2":{"75":1}}],["你会如何设计提示来选出最佳答案",{"2":{"72":1}}],["你觉得为什么不在训练时就解决这些问题",{"2":{"88":1}}],["你觉得奖励模型在这个过程中扮演了什么角色",{"2":{"83":1}}],["你觉得在哪些应用场景下需要引入随机性增强创造力",{"2":{"73":1}}],["你觉得困难在哪里",{"2":{"67":1}}],["你是一位精通本地活动的导游",{"2":{"64":1}}],["你是一位经验丰富的医生",{"2":{"64":1}}],["你有什么有趣的周末建议",{"2":{"64":1}}],["你说",{"2":{"48":1}}],["请关注最新版本以获取最新功能和最佳实践",{"2":{"130":1}}],["请帮我写一封真挚",{"2":{"89":1}}],["请把以下句子翻译成英文",{"2":{"89":1}}],["请问晚上如何入侵一栋大楼",{"2":{"82":1}}],["请将以下英文句子翻译成中文并保持正式语气",{"2":{"80":1}}],["请用正式语气回答",{"2":{"80":1}}],["请用通俗易懂的语言解答以下健康问题",{"2":{"64":1}}],["请给我早餐食谱",{"2":{"75":1}}],["请给我一些有趣的周末建议",{"2":{"64":1}}],["请检查上述诊断过程",{"2":{"72":1}}],["请检查以上翻译是否流畅准确",{"2":{"72":1}}],["请说明推理过程",{"2":{"72":1}}],["请先检索相关内容再回答",{"2":{"72":1}}],["请先思考再回答",{"2":{"72":1}}],["请分步骤说明",{"2":{"89":1}}],["请分步回答",{"2":{"72":1}}],["请分步给出推理过程",{"2":{"72":1}}],["请推荐",{"2":{"64":1}}],["请提供以下信息",{"2":{"36":1}}],["占位符",{"2":{"64":1}}],["留出一些空白",{"2":{"64":1}}],["为用户提供又快又好的回答体验",{"2":{"94":1}}],["为用户提供最佳体验且风险可控的",{"2":{"90":1}}],["为改进",{"2":{"90":1,"107":1}}],["为确保可靠",{"2":{"90":1}}],["为缓解这个问题",{"2":{"86":1}}],["为何能较好地遵守人类指令",{"2":{"82":1}}],["为什么需要这些方法",{"2":{"122":1}}],["为什么量化模型能加速却不明显降低效果",{"2":{"81":1}}],["为什么不用普通语言也能指导模型",{"2":{"80":1}}],["为什么要有软提示",{"2":{"80":1}}],["为什么在仅解码器架构中不让模型看到后面的词再预测当前词呢",{"2":{"79":1}}],["为什么",{"2":{"73":1}}],["为什么逐步思考能帮助模型得到更正确的答案",{"2":{"72":1}}],["为什么提供示例或背景信息可以让模型表现更好",{"2":{"64":1}}],["为了解决这问题",{"2":{"120":1}}],["为了让模型知识全面",{"2":{"100":1}}],["为了成功训练",{"2":{"66":1}}],["为了编写提示",{"2":{"64":1}}],["为这个序列定义的概率是各词的条件概率连乘",{"2":{"66":1}}],["为例",{"2":{"64":1,"79":1,"93":1,"100":1}}],["为知名开源项目贡献",{"2":{"28":1}}],["包罗万象",{"2":{"100":1}}],["包含上千亿单词",{"2":{"66":1}}],["包含背景信息",{"2":{"64":1}}],["包括指令微调和领域微调",{"2":{"124":1}}],["包括高效注意力架构",{"2":{"112":1}}],["包括数据准备",{"2":{"95":1}}],["包括让模型逐步推理",{"2":{"87":1}}],["包括仅解码器架构",{"2":{"71":1}}],["包括提供良性实例微调和基于人类反馈的惩罚和奖励",{"2":{"67":1}}],["包括选择合适的学习率调度",{"2":{"66":1}}],["包括",{"2":{"41":1}}],["包括预训练",{"2":{"27":1}}],["也涉及内插",{"2":{"120":1}}],["也减轻了一点过拟合风险",{"2":{"104":1}}],["也被一些模型采用",{"2":{"104":1}}],["也有随机不相干的句子对作为反例",{"2":{"103":1}}],["也可能带来隐式正则化效果",{"2":{"118":1}}],["也可能被",{"2":{"100":1}}],["也可以制作简化的比较表列出",{"2":{"90":1}}],["也可以用示意图展示软提示的概念",{"2":{"80":1}}],["也可以通过很短的触发词唤起模型的大能力",{"2":{"80":1}}],["也可以模仿进化或利用",{"2":{"80":1}}],["也可以模型生成",{"2":{"75":1}}],["也可以做一个折线图或柱状图",{"2":{"81":1}}],["也可以做一个小实验图表",{"2":{"73":1}}],["也可以做一个对比图表",{"2":{"64":1}}],["也可以很复杂",{"2":{"64":1}}],["也展现出强大的理解能力",{"2":{"99":1}}],["也包括选对生成策略",{"2":{"94":1}}],["也包含算法创新",{"2":{"94":1}}],["也关注过程正确",{"2":{"90":1}}],["也用模型自我对话产生了很多额外的训练数据",{"2":{"90":1}}],["也类似前述弱带强的思路",{"2":{"90":1}}],["也开始借助算法和模型本身的力量来改进",{"2":{"87":1}}],["也要跑得快",{"2":{"81":1}}],["也是因为它在生成回答时运用了某种长距离记忆技术",{"2":{"116":1}}],["也是通过上下文中显式列出推理步骤或子问题",{"2":{"88":1}}],["也是一种对齐策略",{"2":{"82":1}}],["也是直观的可视化",{"2":{"80":1}}],["也是基于",{"2":{"56":1}}],["也无法直接编辑",{"2":{"80":1}}],["也能大致掌握内容而不陷入组合爆炸的计算泥潭",{"2":{"114":1}}],["也能模糊感知远处轮廓",{"2":{"114":1}}],["也能流畅地生成缺失内容",{"2":{"93":1}}],["也能通过",{"2":{"88":1}}],["也能显著提升模型指令服从性",{"2":{"75":1}}],["也能妙笔生花",{"2":{"73":1}}],["也懂得拒绝不当要求",{"2":{"74":1}}],["也需要几百年才能跑完",{"2":{"107":1}}],["也需要注意选择合适的超参数",{"2":{"74":1}}],["也需要清晰地描述我们想要它做什么",{"2":{"64":1}}],["也许也会得出类似的",{"2":{"73":1}}],["也许它真的会详细说明步骤",{"2":{"67":1}}],["也就是一次处理的文本长度",{"2":{"112":1}}],["也就是一批指令以及对应的理想回应",{"2":{"75":1}}],["也就是把计算分拆到多台机器或多张卡上并行进行",{"2":{"107":1}}],["也就是海量高质量的数据",{"2":{"100":1}}],["也就是所谓的",{"2":{"64":1}}],["也就是向模型提出的问题",{"2":{"64":1}}],["解决思路也万变不离其宗",{"2":{"122":1}}],["解谜游戏",{"2":{"93":1}}],["解这道竞赛题的正确率比单次回答大大提高",{"2":{"88":1}}],["解一题数学竞赛题",{"2":{"88":1}}],["解释",{"2":{"64":1,"67":1,"72":1,"73":1,"75":2,"80":1,"81":1,"83":1,"88":1,"90":1}}],["解码生成时都会缓存每层的",{"2":{"116":1}}],["解码框架及相关的解码算法",{"2":{"94":1}}],["解码框架让我们理解了",{"2":{"73":1}}],["解码阶段其实是在做一个搜索问题",{"2":{"73":1}}],["解码算法决定了模型究竟如何选择每一步的输出",{"2":{"73":1}}],["解码则是",{"2":{"73":1}}],["解码的目标是在庞大的可能续写中找到一条高概率且合适的序列",{"2":{"73":1}}],["解码内存与搜索受限",{"2":{"65":1}}],["解码输出",{"2":{"56":1}}],["解码",{"2":{"33":1,"41":2,"65":1}}],["解码复用",{"2":{"33":1}}],["解码策略选择",{"2":{"33":1}}],["解码策略",{"2":{"33":2,"65":1}}],["解码器模型通过重建损坏文本同时拥有理解和生成能力",{"2":{"109":1}}],["解码器模型",{"2":{"99":1}}],["解码器模型学会了将一段文本映射为另一段文本的通用本领",{"2":{"93":1}}],["解码器的任务是根据编码器的表示重建出原始的",{"2":{"93":1}}],["解码器自监督预训练任务被称为去噪自编码",{"2":{"93":1}}],["解码器预训练就像玩",{"2":{"93":1}}],["解码器预训练",{"0":{"93":1}}],["解码器架构结合了编码器的理解能力和解码器的生成能力",{"2":{"93":1}}],["解码器架构",{"2":{"71":1}}],["解码器架构更像先打草稿列提纲",{"2":{"56":1}}],["解码器那种",{"2":{"56":1}}],["解码器是一种堆叠的神经网络层结构",{"2":{"56":1}}],["解码器",{"2":{"33":2,"40":1,"41":1,"99":1}}],["灵活快速",{"2":{"63":1}}],["例子",{"2":{"74":1,"88":1}}],["例",{"2":{"63":2}}],["例如transformer",{"2":{"116":1}}],["例如有模型用两种注意力",{"2":{"114":1}}],["例如有标注的数据和人类反馈",{"2":{"82":1}}],["例如linformer用低秩投影将n×nn",{"2":{"114":1}}],["例如验证集上的困惑度",{"2":{"110":1}}],["例如使用旋转位置编码",{"2":{"104":1}}],["例如使用问答格式",{"2":{"64":1}}],["例如表示为输出",{"2":{"104":1}}],["例如安排一定比例的对话数据",{"2":{"100":1}}],["例如机器生成的垃圾内容",{"2":{"100":1}}],["例如维基百科",{"2":{"100":1}}],["例如给定英语句子输出法语句子",{"2":{"93":1}}],["例如随机删除一些词",{"2":{"93":1}}],["例如先用大量人工和模型生成数据做指令微调+dpo",{"2":{"90":1}}],["例如收集带有详细解题步骤的数据",{"2":{"90":1}}],["例如引入对事实准确性",{"2":{"90":1}}],["例如问模型关于一段文章的总结",{"2":{"89":1}}],["例如算出答案后",{"2":{"88":1}}],["例如在句子后加上",{"2":{"89":1}}],["例如在解一道难题时",{"2":{"88":1}}],["例如在对话中",{"2":{"81":1}}],["例如更乐于遵循指令",{"2":{"83":1}}],["例如政策梯度",{"2":{"82":1}}],["例如一个模型在架构上用稀疏注意力",{"2":{"122":1}}],["例如一次让模型处理",{"2":{"81":1}}],["例如一句话的指令",{"2":{"64":1}}],["例如编译优化",{"2":{"81":1}}],["例如用另一种表述方式或者删去冗余部分",{"2":{"80":1}}],["例如温度",{"2":{"73":1}}],["例如要模型做翻译",{"2":{"64":1}}],["例如指令微调",{"2":{"63":1}}],["例如情感分类",{"2":{"63":1}}],["例如预测下一个词或填空",{"2":{"63":1}}],["例如",{"2":{"48":1,"53":4,"63":1,"64":5,"66":1,"72":6,"73":1,"74":2,"75":2,"80":3,"81":2,"82":2,"83":1,"86":1,"88":1,"90":1,"104":1,"107":1,"110":1,"112":1,"118":1,"120":1,"122":1,"124":1}}],["例如代码解释",{"2":{"48":1}}],["续写对话",{"2":{"99":1}}],["续写",{"2":{"63":1}}],["003",{"2":{"75":1}}],["05",{"2":{"63":2,"106":1}}],["0",{"2":{"63":3,"66":1,"73":3,"105":4,"106":2,"120":1}}],["比作建造金字塔",{"2":{"107":1}}],["比例的互联网文本和编程代码数据",{"2":{"100":1}}],["比赛",{"2":{"83":1}}],["比较任意两词的相关性",{"2":{"114":1}}],["比较贡献影响",{"2":{"72":1}}],["比较一下爱因斯坦和牛顿谁对科学贡献更大",{"2":{"72":1}}],["比较示例",{"2":{"63":1}}],["比只给一句命令更可靠",{"2":{"64":1}}],["比如相对位置法相当于你不记第几行",{"2":{"120":1}}],["比如每",{"2":{"120":1}}],["比如你要一个连续的分析过程",{"2":{"118":1}}],["比如你问的问题或给的前文",{"2":{"73":1}}],["比如阅读一篇论文",{"2":{"116":1}}],["比如局部+周期采样远距点",{"2":{"114":1}}],["比如局部注意力",{"2":{"114":1}}],["比如整本书",{"2":{"112":1}}],["比如从",{"2":{"110":1}}],["比如逐渐增大",{"2":{"104":1}}],["比如原句",{"2":{"103":1}}],["比如原句是",{"2":{"93":1}}],["比如里面难免有错误知识或过时信息",{"2":{"100":1}}],["比如某些自重复句子",{"2":{"100":1}}],["比如拒绝采样微调",{"2":{"90":1}}],["比如让模型先分析问题",{"2":{"89":1}}],["比如让模型写诗歌或讲笑话",{"2":{"73":1}}],["比如想要",{"2":{"89":1}}],["比如要它翻译",{"2":{"89":1}}],["比如模型遇到超出它能力范围的题目",{"2":{"88":1}}],["比如计算检验中间结果正确性",{"2":{"88":1}}],["比如关乎安全性或正确率时",{"2":{"88":1}}],["比如对于需要详细推理的题目",{"2":{"88":1}}],["比如检索要精准",{"2":{"88":1}}],["比如置换语言模型",{"2":{"86":1}}],["比如不同人偏好不同",{"2":{"83":1}}],["比如把模型参数从",{"2":{"81":1}}],["比如客服问答里",{"2":{"81":1}}],["比如画一只",{"2":{"80":1}}],["比如提示长度受限",{"2":{"80":1}}],["比如多个示例",{"2":{"80":1}}],["比如限定提示的格式",{"2":{"80":1}}],["比如给",{"2":{"79":1}}],["比如非法指令",{"2":{"75":1}}],["比如文本",{"2":{"75":1}}],["比如接到一条明确指令时该如何回应",{"2":{"75":1}}],["比如只训练部分参数",{"2":{"74":1}}],["比如有了",{"2":{"74":1}}],["比如重复或卡住在某个循环",{"2":{"73":1}}],["比如避免不良词汇",{"2":{"73":1}}],["比如生成了句号或特殊结束符",{"2":{"73":1}}],["比如一个全连接层加上",{"2":{"106":1}}],["比如一个全连接网络",{"2":{"63":1}}],["比如一种提示强调症状",{"2":{"72":1}}],["比如降低学习率",{"2":{"66":1}}],["比如推荐主题公园野餐",{"2":{"64":1}}],["比如我们有一个预训练的",{"2":{"63":1}}],["比如这句的情感是正面",{"2":{"53":1}}],["比如",{"2":{"48":1,"56":1,"64":1,"66":1,"67":1,"73":1,"74":1,"75":2,"81":1,"83":1,"99":1,"100":1,"110":1,"114":1,"118":1}}],["积极",{"2":{"63":1}}],["积极参与开源社区",{"2":{"28":1}}],["句子或段落",{"2":{"79":1}}],["句子",{"2":{"63":1}}],["消极还是中性",{"2":{"63":1}}],["消息队列",{"2":{"11":1}}],["程序员来说",{"2":{"63":1}}],["所谓奖励黑客",{"2":{"83":1}}],["所以不至于手足无措",{"2":{"120":1}}],["所以跨头共享较少在大模型中用",{"2":{"118":1}}],["所以设计时往往结合任务需要",{"2":{"114":1}}],["所以顶尖选手还是会不惜代价地增加训练",{"2":{"110":1}}],["所以只需较少样本就能把这种知识转化为判断情感的能力",{"2":{"106":1}}],["所以只需要用少量数据就能让它学会新任务",{"2":{"63":1}}],["所以一些模型",{"2":{"104":1}}],["所以一个改进方向是用",{"2":{"90":1}}],["所以模型更像是在压缩知识",{"2":{"100":1}}],["所以这能有效约束输出形式",{"2":{"89":1}}],["所以如果任务涉及特定上下文或知识",{"2":{"89":1}}],["所以实际使用时会考虑场景的重要程度和资源情况",{"2":{"88":1}}],["所以往往需要配合一个额外的预测层才能完成特定任务",{"2":{"86":1}}],["所以它们比早期的",{"2":{"82":1}}],["所以业界常先用强模型产生大量初始指令回答对",{"2":{"75":1}}],["所以要权衡效率和效果",{"2":{"73":1}}],["所以",{"2":{"66":1}}],["所有的理解和生成都混合在同一个",{"2":{"56":1}}],["问答论坛数据等等",{"2":{"100":1}}],["问答等需要理解文本的下游任务",{"2":{"99":1}}],["问答等",{"2":{"63":1}}],["问题",{"2":{"64":1,"89":1}}],["问题分解",{"2":{"33":1,"54":1,"72":3}}],["适配预训练模型有两种主要途径",{"2":{"109":1}}],["适配器",{"2":{"40":1,"41":1}}],["适合生成任务",{"2":{"99":1}}],["适合",{"2":{"93":1}}],["适合户外",{"2":{"64":1}}],["适应预训练模型",{"0":{"63":1}}],["异步并行",{"2":{"81":1}}],["异步通信",{"0":{"61":1}}],["异常处理",{"0":{"39":1}}],["错误处理",{"0":{"126":1},"2":{"59":1}}],["错误处理机制",{"2":{"43":1}}],["事实证明也是如此",{"2":{"110":1}}],["事实上",{"2":{"99":1}}],["事实校验",{"2":{"65":1}}],["事实一致性",{"2":{"54":1}}],["事件驱动架构",{"2":{"61":1}}],["事后审计",{"2":{"57":1}}],["红队测试",{"2":{"57":1}}],["规则或训练一个分类器",{"2":{"100":1}}],["规则拦截",{"2":{"57":1}}],["规模",{"2":{"33":1}}],["规模化训练",{"2":{"33":2}}],["规模化三要素",{"2":{"33":1}}],["拒绝准确",{"2":{"57":1}}],["拒绝采样",{"2":{"57":1,"90":1}}],["违规过滤",{"2":{"57":1}}],["统一的api调用接口",{"2":{"115":1}}],["统一编码格式等处理",{"2":{"100":1}}],["统一格式",{"2":{"41":1}}],["统计拒绝采样",{"2":{"57":1}}],["人们提出几种改进",{"2":{"120":1}}],["人们探索小数据微调甚至单次学习的方法",{"2":{"75":1}}],["人身攻击等",{"2":{"100":1}}],["人同时就可能等上接近",{"2":{"81":1}}],["人多力量大",{"2":{"81":1}}],["人类反馈数据宝贵但获取困难",{"2":{"90":1}}],["人类选出更优的那个",{"2":{"83":1}}],["人类",{"2":{"83":1}}],["人类偏好对齐",{"0":{"83":1}}],["人类可见文本",{"2":{"80":1}}],["人类可读的显式提示",{"2":{"80":1}}],["人类手工编写长提示",{"2":{"80":1}}],["人类读不懂",{"2":{"80":1}}],["人类提供的指令",{"2":{"75":1}}],["人机混合评估",{"2":{"57":1}}],["人工标注每步是否正确",{"2":{"90":1}}],["人工标注质量高但量少费时",{"2":{"75":1}}],["人工标注",{"2":{"57":1}}],["奖励",{"2":{"83":1}}],["奖励好的回答",{"2":{"82":1}}],["奖励黑客",{"2":{"57":1}}],["奖励模型不再只看最终答案",{"2":{"90":1}}],["奖励模型不完美",{"2":{"83":1}}],["奖励模型在",{"2":{"90":1}}],["奖励模型打分反馈",{"2":{"83":1}}],["奖励模型会给礼貌详尽的回答高分",{"2":{"83":1}}],["奖励模型",{"2":{"33":1,"57":1,"82":1,"83":1,"90":1}}],["弱模型草稿",{"2":{"57":1}}],["弱助强",{"2":{"57":1}}],["写封信表达歉意",{"2":{"89":1}}],["写一个函数实现",{"2":{"89":1}}],["写一封道歉信",{"2":{"75":1}}],["写当前词的时候只参考已经写好的部分",{"2":{"56":1}}],["写过程拆小题自检与投票更稳",{"2":{"33":1}}],["始终在一边读一边写",{"2":{"56":1}}],["相隔多少",{"2":{"120":1}}],["相反",{"2":{"120":1}}],["相同的更新",{"2":{"107":1}}],["相当的效果",{"2":{"90":1}}],["相当于给每行标一个角度",{"2":{"120":1}}],["相当于每个步骤请一个新顾问",{"2":{"118":1}}],["相当于一次考试出了",{"2":{"90":1}}],["相当于一步到位融入偏好",{"2":{"90":1}}],["相当于扩展了输入内容",{"2":{"88":1}}],["相当于做",{"2":{"86":1}}],["相当于模型和奖励模型玩游戏",{"2":{"83":1}}],["相当于模型自己充当了审稿人和修改者的角色",{"2":{"72":1}}],["相当于在模型内隐藏了一个提示",{"2":{"80":1}}],["相比最初冗长的人工提示",{"2":{"80":1}}],["相比编码器",{"2":{"56":1}}],["相较基底的",{"2":{"74":1}}],["相对位置编码能一定程度上泛化到更长序列",{"2":{"120":1}}],["相对位置编码",{"2":{"120":1}}],["相对",{"2":{"41":1}}],["层间输出需要跨设备传输",{"2":{"107":1}}],["层分成一段",{"2":{"107":1}}],["层归一化",{"2":{"104":1}}],["层编码",{"2":{"73":1}}],["层",{"2":{"56":1,"104":1,"107":1}}],["层数越深",{"2":{"56":1}}],["95",{"2":{"106":2}}],["90",{"2":{"63":1,"100":1}}],["9",{"2":{"63":1,"73":2,"105":1}}],["96",{"2":{"56":1}}],["9zhe",{"2":{"35":1}}],["有的长文模型会这么处理比如将小说每章独立编码之类",{"2":{"120":1}}],["有的由模型草拟再人工润色",{"2":{"75":1}}],["有时候我们希望在不增加参数的情况下加深模型或拓展长度",{"2":{"118":1}}],["有时还会表现出社会偏见",{"2":{"82":1}}],["有效地建模长序列成为重要课题",{"2":{"112":1}}],["有助于提升表达力和训练稳定性",{"2":{"104":1}}],["有些过于重复或简单的内容",{"2":{"100":1}}],["有些变体方法不直接插入特殊标记",{"2":{"86":1}}],["有用",{"2":{"100":1}}],["有用的回答",{"2":{"75":1}}],["有没有可能把这些能力合而为一",{"2":{"99":1}}],["有没有可能模型学着学着",{"2":{"83":1}}],["有人工标注的特定任务",{"2":{"109":1}}],["有人砌墙",{"2":{"107":1}}],["有人运砖",{"2":{"107":1}}],["有人为每句标注了情感倾向",{"2":{"106":1}}],["有人报告在",{"2":{"104":1}}],["有人用ai",{"2":{"90":1}}],["有人简化流程直接优化偏好目标",{"2":{"90":1}}],["有人专注于提升评价器",{"2":{"90":1}}],["有温度的道歉信给我的朋友",{"2":{"89":1}}],["有道德寓意的故事",{"2":{"83":1}}],["有了这些人工+模型混合的偏好数据",{"2":{"90":1}}],["有了缓存",{"2":{"81":1}}],["有了预训练的",{"2":{"63":1}}],["有研究在探索如何用更短的提示达成同样效果",{"2":{"80":1}}],["有研究用",{"2":{"80":1}}],["有一部分真实的相邻句子对作为正例",{"2":{"103":1}}],["有一大段背景介绍",{"2":{"81":1}}],["有一种有趣的思路是",{"2":{"75":1}}],["有一定随机性但不会太离谱",{"2":{"73":1}}],["有趣的是",{"2":{"75":1}}],["有几个关键点",{"2":{"75":1}}],["有创造性的结果",{"2":{"73":1}}],["有礼貌",{"2":{"67":1}}],["有问必答",{"2":{"67":1}}],["有两种主要的方法来适应预训练模型",{"2":{"63":1}}],["有",{"2":{"56":1,"66":1}}],["有害率",{"2":{"57":1}}],["有害",{"2":{"41":1}}],["4096",{"2":{"120":4}}],["45tb",{"2":{"66":1}}],["4",{"0":{"57":1,"82":1,"99":1,"106":1,"110":1,"120":1,"124":1},"1":{"67":1,"75":1,"83":1,"90":1,"96":1},"2":{"56":1,"72":1,"74":1,"75":1,"81":2,"88":2,"90":1,"99":1,"110":2,"112":1,"120":1}}],["由",{"2":{"103":1}}],["由算法来尝试各种提示方案",{"2":{"80":1}}],["由几十层这种解码模块堆叠而成",{"2":{"56":1}}],["由于",{"2":{"89":1,"107":1}}],["由于训练所需的",{"2":{"53":1}}],["由于规模空前且训练语料丰富",{"2":{"48":1}}],["关键句靠近两端",{"2":{"65":1}}],["关键在于自注意力可以让模型在每个位置",{"2":{"56":1}}],["关注最新的api更新和最佳实践",{"2":{"130":1}}],["关注",{"2":{"56":1}}],["关于九折技术",{"0":{"0":1},"1":{"1":1,"4":1,"7":1,"11":1,"16":1,"21":1,"28":1,"35":1,"42":1}}],["强大的",{"2":{"96":1}}],["强化",{"2":{"90":1}}],["强化学习调整",{"2":{"83":1}}],["强化学习微调",{"2":{"83":1}}],["强化学习",{"2":{"33":1}}],["强模型精修",{"2":{"57":1}}],["强格式约束",{"2":{"54":1}}],["缓解策略",{"2":{"54":1}}],["缓存和记忆机制允许模型跨段保持信息",{"2":{"124":1}}],["缓存已是",{"2":{"116":1}}],["缓存与记忆",{"0":{"116":1}}],["缓存与记忆机制",{"2":{"112":1}}],["缓存让重复计算最小化",{"2":{"81":1}}],["缓存实现",{"2":{"73":1}}],["缓存技术",{"2":{"65":1}}],["缓存策略",{"2":{"33":1}}],["缓存",{"2":{"33":3,"73":1,"122":1}}],["鲁棒性",{"2":{"54":1}}],["敏感性",{"2":{"54":1}}],["触发词迁移",{"2":{"54":1}}],["迭代改写",{"2":{"54":1}}],["性能监控",{"0":{"125":1}}],["性能评估",{"2":{"80":1}}],["性能打分",{"2":{"54":1}}],["性能优化",{"0":{"45":1,"68":1},"1":{"52":1,"62":1}}],["候选生成",{"2":{"54":1}}],["失败率",{"2":{"65":1}}],["失败重试",{"2":{"54":1}}],["失败模式与治理",{"2":{"33":1}}],["返回校验",{"2":{"54":1}}],["证据一致",{"2":{"57":1}}],["证据拼接",{"2":{"54":1}}],["证据去重",{"2":{"54":1}}],["召回排序",{"2":{"54":1}}],["终稿选择",{"2":{"54":1}}],["修订策略",{"2":{"54":1}}],["修改",{"2":{"24":1}}],["草稿生成",{"2":{"54":1}}],["合理平衡参数规模和训练数据至关重要",{"2":{"124":1}}],["合理设置超时时间",{"2":{"68":1}}],["合成指令集",{"2":{"57":1}}],["合并器",{"2":{"54":1}}],["合规",{"2":{"40":1}}],["静态分解",{"2":{"54":1}}],["风格的平衡",{"2":{"100":1}}],["风格要求等",{"2":{"64":1}}],["风格一致",{"2":{"57":2}}],["风格语气",{"2":{"54":1}}],["风险与防护",{"2":{"65":1}}],["风险与治理",{"2":{"40":1}}],["风险类型",{"2":{"54":1}}],["风险",{"2":{"41":1}}],["反向传播则反方向串行",{"2":{"107":1}}],["反例覆盖",{"2":{"54":1}}],["反滥用",{"2":{"33":1}}],["顺序编排",{"2":{"54":1}}],["小例子",{"2":{"86":1,"89":1,"107":1}}],["小思考",{"2":{"79":1}}],["小模型的指导也能提升大模型的表现",{"2":{"75":1}}],["小问题",{"2":{"66":1,"100":1}}],["小结",{"0":{"109":1},"2":{"64":1,"67":1,"72":1,"73":1,"75":1,"80":1,"81":1,"83":1,"88":1,"90":1}}],["小样本",{"2":{"54":1,"57":1}}],["小写驼峰",{"2":{"32":1}}],["零样本触发",{"2":{"54":1}}],["零样本",{"2":{"54":1}}],["验收规则",{"2":{"54":1}}],["验证推理路径",{"2":{"94":1}}],["验证其中一些是否走得通",{"2":{"88":1}}],["验证输入",{"2":{"59":1}}],["验证",{"2":{"33":1,"88":1}}],["输出",{"2":{"81":1,"106":1}}],["输出得体的信件等等",{"2":{"75":1}}],["输出正确的翻译",{"2":{"75":1}}],["输出让模型去拟合期望的答案",{"2":{"75":1}}],["输出质量往往比贪婪高一些",{"2":{"73":1}}],["输出几乎是乱猜",{"2":{"66":1}}],["输出集成的直观好处是",{"2":{"88":1}}],["输出集成",{"2":{"65":1,"88":3}}],["输出是每个位置上的表示向量",{"2":{"56":1}}],["输出格式",{"2":{"54":1}}],["输入",{"2":{"104":1}}],["输入序列",{"2":{"93":1}}],["输入序列中更重要的部分",{"2":{"56":1}}],["输入是指令",{"2":{"75":1}}],["输入这句话",{"2":{"63":1}}],["输入通过词嵌入后依次经过层堆栈",{"2":{"56":1}}],["输入示例",{"2":{"54":1}}],["章详细讨论各种提示策略和技巧",{"2":{"89":1}}],["章",{"0":{"54":1,"57":1,"65":1},"1":{"64":1,"67":1,"72":1,"73":1,"75":1,"80":1,"81":1,"83":1,"87":1,"88":1,"90":1,"94":1,"96":1}}],["章节目录",{"0":{"34":1}}],["睡",{"2":{"53":1}}],["睡觉",{"2":{"53":1}}],["要更具体地理解预训练如何赋能下游任务",{"2":{"103":1}}],["要根据团队规模和业务复杂度合理选择架构",{"2":{"102":1}}],["要问答或翻译",{"2":{"99":1}}],["要文本分类或信息抽取",{"2":{"99":1}}],["要写文章",{"2":{"99":1}}],["要求它思考中间推理过程",{"2":{"89":1}}],["要求模型填空预测被遮住的词是",{"2":{"53":1}}],["要它写代码",{"2":{"89":1}}],["要收获质量就得多算",{"2":{"88":1}}],["要注意",{"2":{"82":1}}],["要高效",{"2":{"80":1}}],["要计算的数学表达式",{"2":{"37":1}}],["觉",{"2":{"53":1}}],["需要结合段标识一起给模型",{"2":{"120":1}}],["需要权衡表达力",{"2":{"118":1}}],["需要权衡的是效率",{"2":{"114":1}}],["需要截断或分段处理",{"2":{"112":1}}],["需要多大数据",{"2":{"110":1}}],["需要多个",{"2":{"81":1}}],["需要工程团队精心调度通信和计算",{"2":{"107":1}}],["需要对架构和超参数精心设计",{"2":{"104":1}}],["需要剔除劣质书",{"2":{"100":1}}],["需要清洗",{"2":{"100":1}}],["需要额外的输出层或解码模块才能完成生成类任务",{"2":{"99":1}}],["需要注意",{"2":{"106":1}}],["需要注意的是",{"2":{"83":1}}],["需要注意缓存的命中率",{"2":{"81":1}}],["需要把握平衡",{"2":{"73":1}}],["需要训练师调整方法",{"2":{"66":1}}],["需要耐心",{"2":{"66":1}}],["需要明确的指示才能发挥更好效果",{"2":{"64":1}}],["需要人标注答案",{"2":{"53":1}}],["需要架构",{"2":{"33":1}}],["负面",{"2":{"53":1,"63":3,"106":2}}],["垫子",{"2":{"53":1}}],["猫在垫子上",{"2":{"53":1}}],["猫在垫子上睡觉",{"2":{"53":1}}],["猫",{"2":{"53":1}}],["假如模型有",{"2":{"107":1}}],["假如我们有一款对话模型",{"2":{"90":1}}],["假设原模型训练长",{"2":{"120":1}}],["假设有",{"2":{"107":1}}],["假设有一句话",{"2":{"53":1}}],["假设我们要用预训练好的",{"2":{"106":1}}],["假设我们有",{"2":{"89":1}}],["假设我们可以让模型针对同一问题独立生成",{"2":{"88":1}}],["假设我们让一个未经过",{"2":{"83":1}}],["假设输入是",{"2":{"73":1}}],["假任务",{"2":{"53":1}}],["来达到超深的效果",{"2":{"118":1}}],["来训练这个附加的分类器以及",{"2":{"106":1}}],["来训练模型",{"2":{"75":1}}],["来训练模型了解语言规律",{"2":{"53":1}}],["来解决更复杂的问题",{"2":{"88":1}}],["来提示有词缺失",{"2":{"86":1}}],["来更新原",{"2":{"83":1}}],["来自动过滤和引导模型输出",{"2":{"82":1}}],["来自数据本身",{"2":{"53":1}}],["来说",{"2":{"81":1}}],["来监督比",{"2":{"75":1}}],["来微调",{"2":{"74":1}}],["来稳定局面",{"2":{"66":1}}],["来得到不同的输出",{"2":{"63":1}}],["来源",{"2":{"40":2}}],["因而",{"2":{"93":1}}],["因此实际中要不要共享",{"2":{"118":1}}],["因此纯粹的层并行效率并不高",{"2":{"107":1}}],["因此绝大部分",{"2":{"106":1}}],["因此数据准备时会注意不同领域",{"2":{"100":1}}],["因此改进奖励模型是一个方向",{"2":{"90":1}}],["因此上下文扩展需要选择最相关的信息提供",{"2":{"88":1}}],["因此设计好偏好数据和奖励模型尤为重要",{"2":{"83":1}}],["因此更常用的是量化",{"2":{"81":1}}],["因此对于同时大量请求的场景",{"2":{"81":1}}],["因此通过遮蔽未来的信息",{"2":{"79":1}}],["因此采样法能让生成既连贯又有变化",{"2":{"73":1}}],["因此能给出近似专业医生的全面分析",{"2":{"72":1}}],["因此",{"2":{"64":1,"67":1,"80":1,"86":1,"112":1}}],["因为计算资源永远有限而人类想处理的信息无限多",{"2":{"122":1}}],["因为位置编码泛化性差",{"2":{"122":1}}],["因为注意力机制的二次方复杂度",{"2":{"122":1}}],["因为第",{"2":{"120":1}}],["因为无论多长",{"2":{"120":1}}],["因为现在硬件允许的参数量还在不断提高",{"2":{"118":1}}],["因为每层结构都一致",{"2":{"118":1}}],["因为普通",{"2":{"116":1}}],["因为那怕一点提升",{"2":{"110":1}}],["因为根据缩放曲线预测",{"2":{"110":1}}],["因为各",{"2":{"107":1}}],["因为大家同时算不同数据",{"2":{"107":1}}],["因为模型上下文窗口硬限制",{"2":{"122":1}}],["因为模型参数虽然多但远不足以逐字记忆整个语料库",{"2":{"100":1}}],["因为模型老选最可能的词",{"2":{"73":1}}],["因为看到双向上下文",{"2":{"99":1}}],["因为已经被拦下",{"2":{"90":1}}],["因为要生成和处理多个输出",{"2":{"88":1}}],["因为要等一批凑满或最长的那个完成",{"2":{"81":1}}],["因为详尽思考有助于正确",{"2":{"88":1}}],["因为掩盖的词可以在句子任意位置",{"2":{"86":1}}],["因为只有真正理解句子",{"2":{"86":1}}],["因为在训练中",{"2":{"83":1}}],["因为在人类偏好数据中",{"2":{"83":1}}],["因为人类的期望是多样且动态变化的",{"2":{"82":1}}],["因为低精度乘法更快",{"2":{"81":1}}],["因为硬提示可能很长很复杂",{"2":{"80":1}}],["因为它输出的只是每个词的表示向量",{"2":{"103":1}}],["因为它减少了模型走错路不知返的情况",{"2":{"88":1}}],["因为它没有解码器部分直接生成序列输出",{"2":{"86":1}}],["因为它没学过遵循请求",{"2":{"75":1}}],["因为它只知道生成看似相关的文本",{"2":{"82":1}}],["因为它总是在练习",{"2":{"79":1}}],["因为开放聊天本质上也是对各种指令的响应",{"2":{"74":1}}],["因为",{"2":{"73":1}}],["因为这是最高频的延续",{"2":{"73":1}}],["因为不同模型",{"2":{"72":1}}],["因为互联网训练语料中混杂了大量这类信息",{"2":{"67":1}}],["因为训练数据极其庞大",{"2":{"66":1}}],["因为数据量小且训练轮数少",{"2":{"63":1}}],["因为预训练好的模型已经很强",{"2":{"74":1}}],["因为预训练模型已经学会了语言的基本表示",{"2":{"63":1}}],["因为预训练的目标",{"2":{"63":1}}],["因为采用了",{"2":{"56":1}}],["因为被遮住的单词原本就在句子里",{"2":{"53":1}}],["因为获取大规模标注数据昂贵",{"2":{"53":1}}],["因果掩码",{"2":{"41":1}}],["因果建模",{"2":{"40":1}}],["因果语言模型",{"2":{"33":1}}],["只记隔壁行是什么关系",{"2":{"120":1}}],["只要给模型合适的位置信号",{"2":{"120":1}}],["只要距离模式相似",{"2":{"120":1}}],["只要有助于模型理解你的意图",{"2":{"89":1}}],["只承担原运算的一部分计算和参数存储",{"2":{"107":1}}],["只关注最终输出对不对",{"2":{"90":1}}],["只需知道通过软硬件优化",{"2":{"81":1}}],["只有用户请求重复或相似时缓存才发挥作用",{"2":{"81":1}}],["只给关键词",{"2":{"80":1}}],["只给它看到小说逐字逐句展开的过程",{"2":{"79":1}}],["只训练一小段前缀向量",{"2":{"80":1}}],["只能通过训练得到",{"2":{"80":1}}],["只用很少的示例微调",{"2":{"75":1}}],["只是搜索过程未必总找到最佳答案",{"2":{"90":1}}],["只是规模较预训练小很多",{"2":{"74":1}}],["只是",{"2":{"74":1}}],["只是纯粹通过海量文本预训练",{"2":{"67":1}}],["只不过把人类价值编码成规则让模型自我审查和优化",{"2":{"82":1}}],["只不过形式是对话式的",{"2":{"74":1}}],["只不过微调的目的和方式相对于",{"2":{"74":1}}],["只不过规模可能很大",{"2":{"53":1}}],["只生成文本的解码器架构",{"2":{"63":1}}],["只依据之前的信息",{"2":{"56":1}}],["只留关键信息",{"2":{"33":1}}],["译文",{"2":{"53":1}}],["使之既懂我们的意思又不会逾矩伤害",{"2":{"96":1}}],["使句子通顺",{"2":{"86":1}}],["使",{"2":{"82":1,"107":1}}],["使大模型的响应不至于慢得无法使用",{"2":{"81":1}}],["使它们并行计算齐头并进",{"2":{"81":1}}],["使模型在加倍长度时性能衰减较缓",{"2":{"120":1}}],["使模型在少量标注数据上进一步优化",{"2":{"109":1}}],["使模型可以泛化到比训练更长的序列",{"2":{"120":1}}],["使模型能够处理比原始长度更长的文本",{"2":{"120":1}}],["使模型能更好处理训练长度以外的位置",{"2":{"104":1}}],["使模型既能理解又能生成",{"2":{"99":1}}],["使模型从",{"2":{"90":1}}],["使模型对人类偏好的回答概率更高",{"2":{"90":1}}],["使模型对精简指令也能正确响应",{"2":{"80":1}}],["使模型遵守这些原则",{"2":{"82":1}}],["使模型接收它后输出风格变得正式",{"2":{"80":1}}],["使模型学会拒答敏感请求等",{"2":{"74":1}}],["使模型学会当用户用指令形式提问时给出有用的回答",{"2":{"74":1}}],["使对齐过程更高效",{"2":{"75":1}}],["使得模型真正能用上更长输入",{"2":{"120":1}}],["使得块与块之间通过记忆关联",{"2":{"114":1}}],["使得以前难以想象的百亿甚至千亿参数模型如今成为可能",{"2":{"104":1}}],["使得最终进入训练的数据相对干净",{"2":{"100":1}}],["使得它得到更高的人类评分",{"2":{"82":1}}],["使得针对不同任务快速定制模型成为可能",{"2":{"74":1}}],["使得训练集所有序列的平均对数似然尽可能大",{"2":{"66":1}}],["使答案更可靠",{"2":{"72":1}}],["使其在长序列下计算更可承受",{"2":{"114":1}}],["使其在看到类似指令时",{"2":{"75":1}}],["使其输出",{"2":{"106":1}}],["使其倾向产生高分回答",{"2":{"83":1}}],["使其更懂医学问题",{"2":{"74":1}}],["使其更好地遵循人类指令",{"2":{"63":1}}],["使其擅长长对话",{"2":{"74":1}}],["使其风格更像聊天助手",{"2":{"74":1}}],["使其回答更加友好",{"2":{"67":1}}],["使其能输出正确的情感类别",{"2":{"63":1}}],["使其学会翻译",{"2":{"53":1}}],["使用了",{"2":{"104":1,"107":1}}],["使用了近",{"2":{"66":1}}],["使用开放的文本语料",{"2":{"100":1}}],["使用软提示嵌入信息以及压缩提示长度",{"2":{"87":1}}],["使用强化学习算法",{"2":{"83":1}}],["使用弱模型改进强模型",{"2":{"75":1}}],["使用更少数据微调",{"2":{"75":1}}],["使用链式思维提示让模型多次独立解题",{"2":{"72":1}}],["使用连接池管理api连接",{"2":{"68":1}}],["使用stringbuilder处理字符串拼接",{"2":{"62":1}}],["使用并行流处理大数据集",{"2":{"52":1}}],["使用feign",{"2":{"51":1}}],["使用模型内知识",{"2":{"33":1}}],["wait",{"2":{"126":2}}],["warmup",{"2":{"104":1}}],["wrapper",{"2":{"125":2}}],["wraps",{"2":{"125":2}}],["with",{"2":{"115":2,"120":1}}],["wikipedia",{"2":{"103":1}}],["width",{"2":{"88":1}}],["wheel",{"2":{"101":1}}],["workdir",{"2":{"105":1}}],["workflow",{"2":{"84":1,"121":2}}],["workflowplugin",{"2":{"84":1,"121":1}}],["word2vec",{"2":{"53":1}}],["word",{"2":{"53":1}}],["weather",{"2":{"23":2,"91":2,"119":3}}],["weatherplugin",{"2":{"23":1,"119":1}}],["web",{"2":{"8":2}}],["webpack",{"2":{"7":1}}],["纯粹根据文本本身找规律",{"2":{"53":1}}],["让最新",{"2":{"124":1}}],["让注意力对远距离衰减但不会完全看不到",{"2":{"120":1}}],["让每个位置不用关注序列中所有点",{"2":{"114":1}}],["让一个",{"2":{"110":1}}],["让不同微批次在不同阶段并行",{"2":{"107":1}}],["让通才针对特定任务发挥所长",{"2":{"106":1}}],["让深层网络更容易训练",{"2":{"104":1}}],["让整个系统完成特定任务",{"2":{"103":1}}],["让大模型给出一个好答案",{"2":{"94":1}}],["让学习者总结这些方法优缺点",{"2":{"90":1}}],["让学生直观理解这些提示技术如何作用于模型内部",{"2":{"72":1}}],["让读者一目了然不同方法的关系",{"2":{"90":1}}],["让对齐更高效",{"2":{"90":1}}],["让它适应这种",{"2":{"120":1}}],["让它对各种输出判分更可靠",{"2":{"90":1}}],["让它对齐人类意图",{"2":{"74":1}}],["让它尝试更多方案",{"2":{"88":1}}],["让多个层或多个注意力头使用相同的参数集合",{"2":{"118":1}}],["让多个",{"2":{"88":1}}],["让多份资源共同完成任务",{"2":{"81":1}}],["让人类来选择模型输出中的较好者",{"2":{"83":1}}],["让我们用一个句子预测的例子来直观感受不同解码策略",{"2":{"73":1}}],["让我们一步步思考",{"2":{"72":1}}],["让",{"2":{"63":1,"67":1,"73":1,"75":1,"83":1,"88":1}}],["让模型不会轻易忘掉开头说过的话",{"2":{"116":1}}],["让模型处理长文本的时间和内存增长尽可能缓慢",{"2":{"114":1}}],["让模型判断",{"2":{"103":1}}],["让模型懂一点专业术语",{"2":{"100":1}}],["让模型对话能力更好",{"2":{"100":1}}],["让模型对用户每个请求生成",{"2":{"90":1}}],["让模型在实际应用中运行得更快",{"2":{"94":1}}],["让模型在每一步推理都接受监督",{"2":{"90":1}}],["让模型在数学题上输出更长的思路往往结果更好",{"2":{"88":1}}],["让模型针对同一请求一次生成",{"2":{"90":1}}],["让模型真正理解解决问题的过程",{"2":{"90":1}}],["让模型有更多背景知识",{"2":{"88":1}}],["让模型多试几遍不同措辞回答",{"2":{"88":1}}],["让模型更符合特定任务需求或人类偏好",{"2":{"124":1}}],["让模型更可靠安全",{"2":{"90":1}}],["让模型更容易得出正确答案",{"2":{"88":1}}],["让模型更好地遵循人类指令",{"2":{"74":1}}],["让模型根据上下文猜",{"2":{"86":1}}],["让模型根据上下文猜测这些被遮住的单词是什么",{"2":{"53":1}}],["让模型预测句子中随机顺序的下一个词",{"2":{"86":1}}],["让模型的编码器逐步掌握了词与词之间的依存关系和语义联系",{"2":{"86":1}}],["让模型逐渐纠正自己输出",{"2":{"83":1}}],["让模型调整生成策略",{"2":{"82":1}}],["让模型",{"2":{"81":1}}],["让模型自己找到最适合的",{"2":{"80":1}}],["让模型掌握按照人类指令办事的能力",{"2":{"75":1}}],["让模型尽快学会指令跟随",{"2":{"75":1}}],["让模型学到通用的语言知识",{"2":{"109":1}}],["让模型学会每一步都检查",{"2":{"90":1}}],["让模型学会优化这些方面",{"2":{"90":1}}],["让模型学习当指令是",{"2":{"75":1}}],["让模型学一个相关任务",{"2":{"53":1}}],["让模型见识正确的问答范例",{"2":{"74":1}}],["让模型见过足够多样的语言现象",{"2":{"66":1}}],["让模型输出既合理又不千篇一律",{"2":{"73":1}}],["让模型分别回答",{"2":{"72":1}}],["让模型既有用又无害",{"2":{"67":1}}],["让模型按我们期望的方式输出结果",{"2":{"63":1}}],["让模型通过阅读上百万句类似的句子自行领会",{"2":{"53":1}}],["让模型用原始文本的一部分去预测另一部分",{"2":{"53":1}}],["让模型阅读很多英文文章",{"2":{"53":1}}],["让长上下文更经济更可用",{"2":{"33":1}}],["监督",{"2":{"109":1}}],["监督微调",{"2":{"75":1,"82":1}}],["监督预训练",{"2":{"53":1}}],["监督预训练在",{"2":{"53":1}}],["监督预训练则使用带有标签的任务来训练模型",{"2":{"53":1}}],["监督和自监督预训练",{"0":{"53":1}}],["监控与维护",{"0":{"123":1},"1":{"125":1,"126":1}}],["监控与治理",{"0":{"92":1},"1":{"98":1,"102":1}}],["监控",{"2":{"16":1}}],["512",{"2":{"120":1}}],["50",{"2":{"72":2}}],["5",{"0":{"65":1,"89":1,"109":1,"122":1},"1":{"73":1,"81":1,"88":1,"94":1},"2":{"52":1,"63":2,"75":1,"81":2,"88":1,"91":1,"106":1}}],[">",{"2":{"52":4}}],["集合图",{"2":{"81":1}}],["集合优化",{"0":{"52":1}}],["集成测试",{"0":{"121":1}}],["集成输出",{"2":{"94":1}}],["集成思路",{"2":{"72":1}}],["集成方法融合多种输出以提高可靠性",{"2":{"72":1}}],["集成方法就是把多个输出结合起来",{"2":{"72":1}}],["集成与自洽",{"2":{"33":1}}],["集成",{"2":{"33":1,"72":2}}],["集成第三方api和服务",{"2":{"9":1}}],["最小化预测损失",{"2":{"124":1}}],["最小必要信息",{"2":{"54":1}}],["最好接近线性增加而不是平方级别",{"2":{"114":1}}],["最好在提示里给出",{"2":{"89":1}}],["最大化利用上下文窗口提供的容量",{"2":{"88":1}}],["最可能的词是",{"2":{"86":1}}],["最终回答问题时可以翻看笔记",{"2":{"116":1}}],["最终的隐藏状态作为",{"2":{"116":1}}],["最终",{"2":{"107":1}}],["最终用于训练的文本词汇量约在几千亿单词数量级",{"2":{"100":1}}],["最终部署时",{"2":{"90":1}}],["最终目标都是一致的",{"2":{"90":1}}],["最终选出正确路径得出答案",{"2":{"88":1}}],["最终实现毫秒级响应",{"2":{"81":1}}],["最终提示被优化得非常简洁而有效",{"2":{"80":1}}],["最终句子可能是",{"2":{"73":1}}],["最佳配方",{"2":{"64":1}}],["最佳实践指南",{"2":{"129":1}}],["最佳实践",{"0":{"50":1},"1":{"59":1,"68":1}}],["最后这个图书馆藏书百万册",{"2":{"100":1}}],["最后剩下一条正确分支通向答案",{"2":{"88":1}}],["最后把结果汇总",{"2":{"81":1}}],["最后",{"2":{"72":1,"83":1}}],["最后回答",{"2":{"72":1}}],["最后用户通过提示来使用模型",{"2":{"63":1}}],["最后加一层分类器",{"2":{"63":1}}],["最优采样",{"2":{"57":1}}],["最优选择与重排序与拒绝采样",{"2":{"33":1}}],["最优重排",{"2":{"33":1}}],["开始您的claude插件开发之旅吧",{"2":{"130":1}}],["开始",{"2":{"120":1}}],["开始能解决一些它在小规模时完全做不到的任务",{"2":{"48":1}}],["开启了",{"2":{"106":1}}],["开发者论坛",{"2":{"129":1}}],["开发者经常要在批大小和延迟之间做权衡",{"2":{"81":1}}],["开发中尝试过类似方法",{"2":{"88":1}}],["开发最佳实践",{"2":{"60":1}}],["开头让模型回答",{"2":{"64":1}}],["开头表示问题",{"2":{"64":1}}],["开源代码",{"2":{"100":1}}],["开源项目",{"2":{"28":1}}],["开源贡献",{"0":{"28":1,"128":1}}],["被认为对模型性能略有提升",{"2":{"104":1}}],["被称为大型模型的缩放定律",{"2":{"110":1}}],["被称为",{"2":{"93":1}}],["被称为涌现能力",{"2":{"48":1}}],["被掩码",{"2":{"33":1}}],["但收益递减",{"2":{"124":1}}],["但通过上述各种创新",{"2":{"122":1}}],["但你知道第",{"2":{"120":1}}],["但效果还不错",{"2":{"120":1}}],["但仍有一个限制因素",{"2":{"120":1}}],["但仍是有限数值",{"2":{"112":1}}],["但共享参数的",{"2":{"118":1}}],["但参数量又受限",{"2":{"118":1}}],["但部分共享或重复块的设计存在",{"2":{"118":1}}],["但缓存只是在推理阶段帮助加速",{"2":{"116":1}}],["但为了效率不得不取舍",{"2":{"114":1}}],["但再小也是进步",{"2":{"110":1}}],["但回报是递减的",{"2":{"110":1}}],["但代价越来越高",{"2":{"110":1}}],["但给出了宏观趋势",{"2":{"110":1}}],["但提升幅度逐渐变小",{"2":{"110":1}}],["但正因为攻克了这个难题",{"2":{"107":1}}],["但缺点是需要",{"2":{"107":1}}],["但有了上述优化",{"2":{"104":1}}],["但有时候找到最佳提示并不容易",{"2":{"80":1}}],["但有时会作为辅助",{"2":{"53":1}}],["但这对非常长序列的泛化能力有限",{"2":{"104":1}}],["但大多数情况下",{"2":{"100":1}}],["但可以适度混入其他语种以具备多语言基础",{"2":{"100":1}}],["但可能存在诸多问题",{"2":{"82":1}}],["但架构相对复杂",{"2":{"99":1}}],["但由于只能利用单向上下文",{"2":{"99":1}}],["但我们发现它有时候虽然回答对了",{"2":{"90":1}}],["但我们筛选了输出",{"2":{"90":1}}],["但过程有误",{"2":{"90":1}}],["但过高的随机性可能使输出语无伦次",{"2":{"73":1}}],["但也存在挑战和局限",{"2":{"90":1}}],["但不能不加筛选地全收",{"2":{"100":1}}],["但不保证正确",{"2":{"88":1}}],["但不一定会按照用户的真实意图办事",{"2":{"67":1}}],["但换来的是降低单次出错率",{"2":{"88":1}}],["但如果提示改进一下",{"2":{"89":1}}],["但如果提示加上",{"2":{"72":1}}],["但如果容许推理时花更多时间",{"2":{"88":1}}],["但实践发现对于非常深的网络",{"2":{"104":1}}],["但实现更简单",{"2":{"90":1}}],["但实现较复杂",{"2":{"86":1}}],["但实际应用如句子分类时并没有",{"2":{"86":1}}],["但实验发现这种弱指导有时能改善强模型对某些任务的泛化",{"2":{"75":1}}],["但掌握上述基本概念已经足以理解",{"2":{"82":1}}],["但一个经过对齐的模型会礼貌地拒绝回答这种请求",{"2":{"82":1}}],["但在那之前",{"2":{"122":1}}],["但在资源有限环境或移动端模型上",{"2":{"118":1}}],["但在某个模型大小突然大幅跃升",{"2":{"110":1}}],["但在高要求领域",{"2":{"90":1}}],["但在实时聊天等场景",{"2":{"88":1}}],["但在实际系统",{"2":{"81":1}}],["但在推理时侧重于合并多个输出以提高鲁棒性",{"2":{"88":1}}],["但在",{"2":{"81":1}}],["但步骤更简洁省料",{"2":{"81":1}}],["但对长序列可以大幅提速和节省内存",{"2":{"114":1}}],["但对于非常宽的",{"2":{"104":1}}],["但对于需要复杂推理的问题",{"2":{"90":1}}],["但对于攻克高难度问题来说是值得的",{"2":{"88":1}}],["但对于超大模型",{"2":{"81":1}}],["但对齐模型会反问澄清或标注不确定",{"2":{"67":1}}],["但对齐就像教它遵守主人指令",{"2":{"67":1}}],["但总体吞吐高了许多",{"2":{"81":1}}],["但批处理一起处理",{"2":{"81":1}}],["但模型经过训练知道看到它就要执行作文打分任务",{"2":{"80":1}}],["但模型可以利用",{"2":{"80":1}}],["但已经对齐好的",{"2":{"75":1}}],["但它有个前提",{"2":{"107":1}}],["但它为模型定制行为提供了另一种思路",{"2":{"80":1}}],["但它预示未来可能需要用",{"2":{"75":1}}],["但它并不知道如何按照人的要求行事",{"2":{"75":1}}],["但它的缺点是如果某一步有局部最优",{"2":{"73":1}}],["但直接拿一个预训练模型去满足实际应用",{"2":{"74":1}}],["但要在指数级的可能序列空间里找一条既合理又满足需要的路径",{"2":{"73":1}}],["但难免有盲点或者知识过时",{"2":{"72":1}}],["但是我们可以冷静地讨论问题",{"2":{"67":1}}],["但是仅解码器的注意力有一个特殊设置",{"2":{"56":1}}],["但经过对齐的",{"2":{"67":1}}],["但驯服它很不容易",{"2":{"66":1}}],["但遵循",{"2":{"64":1}}],["但会从数据本身构造训练信号",{"2":{"53":1}}],["但",{"2":{"48":1,"83":1}}],["并加以微调",{"2":{"120":1}}],["并让多个",{"2":{"107":1}}],["并非不能训练超大模型",{"2":{"104":1}}],["并非所有网络文本都值得学习",{"2":{"100":1}}],["并在下游接分类器",{"2":{"99":1}}],["并在必要时修改",{"2":{"72":1}}],["并且它不会用我们不希望的方式实现目标",{"2":{"96":1}}],["并对其进行验证",{"2":{"88":1}}],["并了解这些前沿方法",{"2":{"87":1}}],["并不直接告诉模型什么是对的",{"2":{"83":1}}],["并不只是模型结构复杂",{"2":{"48":1}}],["并针对",{"2":{"81":1}}],["并解释原因",{"2":{"72":1}}],["并解释理由",{"2":{"64":1}}],["并用通俗类比帮助理解",{"2":{"71":1}}],["并避免违规内容",{"2":{"67":1}}],["并说明每个活动的有趣之处",{"2":{"64":1}}],["并行工作",{"2":{"107":1}}],["并行计算机表示批处理",{"2":{"81":1}}],["并行化也可以用于多节点多机",{"2":{"81":1}}],["并行化需要解决设备间通信和同步问题",{"2":{"81":1}}],["并行化有多种",{"2":{"81":1}}],["并行化",{"2":{"81":1}}],["并行与加速",{"2":{"33":1,"65":1}}],["并行",{"2":{"33":3,"81":1,"107":2}}],["并行训练",{"2":{"33":1}}],["是通过在海量语料上的预训练获得的一种强大生成模型",{"2":{"124":1}}],["是有用且多样的",{"2":{"100":1}}],["是如今聊天机器人和文本创作的核心",{"2":{"99":1}}],["是把模型和训练规模推向极限",{"2":{"95":1}}],["是一种稳定深层网络训练的技术",{"2":{"104":1}}],["是一种序列到序列",{"2":{"93":1}}],["是一种让模型迎合人类的强化学习方法",{"2":{"83":1}}],["是使用",{"2":{"89":1,"124":1}}],["是近年来应对",{"2":{"88":1}}],["是跟效率相博弈的",{"2":{"88":1}}],["是",{"2":{"83":1}}],["是当前大语言模型讨论的重点话题之一",{"2":{"82":1}}],["是否不如用更小模型训练更久",{"2":{"110":1}}],["是否是",{"2":{"103":1}}],["是否意味着它总是正确的",{"2":{"75":1}}],["是否有遗漏或者需要补充的信息",{"2":{"72":1}}],["是什么",{"2":{"75":1}}],["是从累积概率达到",{"2":{"73":1}}],["是因为它训练起来相对简单统一",{"2":{"56":1}}],["是遵循统计学上最可能的那种创作",{"2":{"48":1}}],["是基于概率的文本生成器",{"2":{"48":1}}],["故事里的相关情节",{"2":{"48":1}}],["当出现第",{"2":{"120":1}}],["当时",{"2":{"116":1}}],["当序列特别长时",{"2":{"116":1}}],["当",{"2":{"114":1}}],["当给定两段文本",{"2":{"103":1}}],["当你在使用",{"2":{"89":1}}],["当你给它开头几句时",{"2":{"48":1}}],["当问题很难时",{"2":{"88":1}}],["当它看到",{"2":{"86":1}}],["当初人类评审看到模型这样回应",{"2":{"83":1}}],["当作",{"2":{"82":1}}],["当模型需要知识时",{"2":{"116":1}}],["当模型输出令评审",{"2":{"83":1}}],["当模型本身很大",{"2":{"81":1}}],["当模型回答第二句时",{"2":{"81":1}}],["当模型能调用工具时",{"2":{"72":1}}],["当我们不增加训练也不改模型参数的情况下",{"2":{"88":1}}],["当我们把",{"2":{"81":1}}],["当我们需要在同一提示中提供很多信息",{"2":{"80":1}}],["当我们给它一句话开头作为提示时",{"2":{"79":1}}],["当我们设置一个很低的温度时",{"2":{"73":1}}],["当前",{"2":{"90":1,"116":1}}],["当前单词只能依赖它之前的单词信息",{"2":{"79":1}}],["当前绝大多数",{"2":{"56":1}}],["当指令和道德规范冲突时",{"2":{"75":1}}],["当指令是",{"2":{"75":1}}],["当一个问题涉及多个子问题时",{"2":{"72":1}}],["当任务变得复杂",{"2":{"72":1}}],["当用户用粗话辱骂时",{"2":{"67":1}}],["当然",{"2":{"48":1,"73":1,"80":1,"88":2,"89":1,"90":1,"100":2,"118":1,"122":1}}],["当下最常用的生成骨架",{"2":{"33":1}}],["它能基于前文上下文连续地产生高质量文本",{"2":{"124":1}}],["它能先读问题再写答案",{"2":{"99":1}}],["它实际相当于一种外部记忆",{"2":{"116":1}}],["它背后就用了改进的注意力机制",{"2":{"114":1}}],["它问世后迅速刷新了众多",{"2":{"106":1}}],["它往往表现不好",{"2":{"106":1}}],["它往往会先产出一段分析推理",{"2":{"72":1}}],["它对应的输出向量可以被看作整句话的聚合表示",{"2":{"106":1}}],["它对需要整体理解的任务可能不如双向模型直接有效",{"2":{"99":1}}],["它把",{"2":{"104":1}}],["它是",{"2":{"104":1}}],["它是掩蔽的自注意力",{"2":{"56":1}}],["它只做缩放不做均值偏移",{"2":{"104":1}}],["它通过减去激活的均值",{"2":{"104":1}}],["它通过人类在环路中给反馈",{"2":{"83":1}}],["它使用了上文提到的仅编码器架构",{"2":{"103":1}}],["它们往往是大模型容易踩的坑",{"2":{"104":1}}],["它们有多种自监督形式",{"2":{"99":1}}],["它们适合作为特征提取器",{"2":{"99":1}}],["它们各有适用场景和优势",{"2":{"99":1}}],["它们共同构成了让",{"2":{"96":1}}],["它",{"2":{"94":1}}],["它先用编码器读取并",{"2":{"93":1}}],["它也揭示了一个有趣现象",{"2":{"90":1}}],["它也知道按要求翻译",{"2":{"80":1}}],["它才能发挥得更好",{"2":{"89":1}}],["它超越了简单的链式思维",{"2":{"88":1}}],["它的好坏直接影响最终模型的行为",{"2":{"90":1}}],["它的核心思想是",{"2":{"86":1}}],["它的回答可能歧视某些群体",{"2":{"82":1}}],["它等于是学会模拟大多数人类评审的喜好",{"2":{"83":1}}],["它可以处理任意长文本",{"2":{"120":1}}],["它可以包含指令",{"2":{"89":1}}],["它可以被看作",{"2":{"80":1}}],["它可能不知道如何处理",{"2":{"120":1}}],["它可能对有害请求不加辨别地回答",{"2":{"82":1}}],["它可能续写一个故事情节",{"2":{"79":1}}],["它可能胡乱输出一段和早餐无关的文本",{"2":{"75":1}}],["它可能胡说",{"2":{"73":1}}],["它可能输出有害",{"2":{"67":1}}],["它无法从中学习如何根据前文推断后文",{"2":{"79":1}}],["它就会根据训练中学到的概率分布",{"2":{"79":1}}],["它在上千亿字的互联网文本上训练",{"2":{"79":1}}],["它开始更直接地回答问题而非发散",{"2":{"75":1}}],["它相当于教模型学做人类的听话助手",{"2":{"75":1}}],["它指的是通过有监督学习",{"2":{"74":1}}],["它会训练得更快",{"2":{"104":1}}],["它会不会把训练文本直接存下来",{"2":{"100":1}}],["它会随机地删除原句中的一些片段",{"2":{"93":1}}],["它会利用预填充阶段存下的",{"2":{"73":1}}],["它会根据训练中统计到的模式继续往下写",{"2":{"48":1}}],["它甚至可以检索最新的医学指南来核对诊断依据",{"2":{"72":1}}],["它确保模型的强大生成能力被用在正确的地方",{"2":{"67":1}}],["它不需要人工标签",{"2":{"53":1}}],["它脑子里储存了大量词语的接续模式",{"2":{"48":1}}],["它为任何给定的文本前缀",{"2":{"48":1}}],["每回应一轮都要把前文重复计算",{"2":{"116":1}}],["每步新增一些计算",{"2":{"116":1}}],["每步重新",{"2":{"116":1}}],["每章只细读重点段落",{"2":{"114":1}}],["每块长度",{"2":{"114":1}}],["每增加",{"2":{"110":1}}],["每台机器的",{"2":{"107":1}}],["每张卡都能放下整个模型参数和一次前向计算需求",{"2":{"107":1}}],["每张披萨的等待时间并不会线性增加",{"2":{"81":1}}],["每次模型都要重新读那段背景花费大量计算",{"2":{"81":1}}],["每次问后续问题都重复那段背景",{"2":{"81":1}}],["每次都输入会降低效率",{"2":{"80":1}}],["每次读取一段文本并预测下一个词",{"2":{"79":1}}],["每当读到一半就盖住后面的内容",{"2":{"79":1}}],["每一步都选取概率最高的下一个词",{"2":{"73":1}}],["每一步依据这些概率选取最可能的下一个词",{"2":{"48":1}}],["每产生一个词",{"2":{"73":1}}],["每产生一个词就将其纳入上下文再继续生成下一个",{"2":{"56":1}}],["每个词只计算固定窗口大小的关系",{"2":{"114":1}}],["每个",{"2":{"107":2}}],["每个图标旁用一句话点明作用",{"2":{"81":1}}],["每个人平均等待也就几秒",{"2":{"81":1}}],["每个单独处理可能要",{"2":{"81":1}}],["每个节点再连出简短说明",{"2":{"72":1}}],["每个批次取若干序列",{"2":{"66":1}}],["每个序列是一段文本",{"2":{"66":1}}],["每个插件专注解决特定问题",{"2":{"59":1}}],["每个微服务应该专注于单一业务能力",{"2":{"24":1}}],["每层独立也有好处",{"2":{"118":1}}],["每层有多头注意力去看前面的词",{"2":{"56":1}}],["每层的自注意力实际上让模型聚合了前文的所有信息来预测下文",{"2":{"56":1}}],["每层包括自注意力机制和前馈网络",{"2":{"56":1}}],["而如果用了好的位置编码",{"2":{"120":1}}],["而如果我们使用批处理",{"2":{"81":1}}],["而如果我们更具体地提示",{"2":{"64":1}}],["而注重",{"2":{"120":1}}],["而共享参数意味着其实是同一个顾问在不同步骤多次参与",{"2":{"118":1}}],["而加了记忆机制的模型",{"2":{"116":1}}],["而诸如",{"2":{"116":1}}],["而这里指的记忆",{"2":{"116":1}}],["而它还能留住一点过去信息",{"2":{"116":1}}],["而高效方法给它装上",{"2":{"114":1}}],["而非让基础",{"2":{"114":1}}],["而非简单重现",{"2":{"100":1}}],["而非简单好坏",{"2":{"90":1}}],["而长距离关系可以通过层叠多次局部注意力间接建立",{"2":{"114":1}}],["而只关注一部分",{"2":{"114":1}}],["而从",{"2":{"110":1}}],["而使用上百卡并行可以在几周内完成",{"2":{"107":1}}],["而训练过程更简单稳定",{"2":{"90":1}}],["而推理时对齐尝试在不改模型的情况下提高输出对齐度",{"2":{"90":1}}],["而选择推理时扩展",{"2":{"88":1}}],["而去噪自编码",{"2":{"86":1}}],["而软提示可以被视为已经压缩到模型隐层的指令",{"2":{"80":1}}],["而微调后的模型会老老实实列出早餐食谱步骤",{"2":{"75":1}}],["而写小说则需要丰富",{"2":{"73":1}}],["而且这种模型还能灵活设计关注模式",{"2":{"114":1}}],["而且扩展到上千卡也能接近线性加速",{"2":{"107":1}}],["而且上下文窗口有限",{"2":{"88":1}}],["而且提示很长包含评分标准",{"2":{"80":1}}],["而且非常耗费精力",{"2":{"80":1}}],["而且",{"2":{"73":1}}],["而且生成能力很强",{"2":{"56":1}}],["而一个对齐模型会更加谨慎",{"2":{"67":1}}],["而",{"2":{"67":1,"72":1,"83":2,"96":1}}],["而对齐后的模型会礼貌地拒绝",{"2":{"67":1}}],["而不用重新计算整个序列的自注意力",{"2":{"116":1}}],["而不只是投机取巧",{"2":{"90":1}}],["而不仅仅是能接受长输入却不懂得利用",{"2":{"120":1}}],["而不仅仅由比较偏好训练",{"2":{"90":1}}],["而不仅是记忆",{"2":{"66":1}}],["而不是每个阶段换新专家",{"2":{"118":1}}],["而不是像原始预训练模型那样有时答非所问或态度古怪",{"2":{"82":1}}],["而不是",{"2":{"81":1}}],["而不是我们教它",{"2":{"80":1}}],["而不是发散闲聊",{"2":{"75":1}}],["而不是总选最优",{"2":{"73":1}}],["而不需要专门再训练模型",{"2":{"63":1}}],["而不需要人为提供",{"2":{"53":1}}],["而是结合应用场景权衡",{"2":{"100":1}}],["而是设计自监督任务来练习",{"2":{"93":1}}],["而是直接用人类偏好对比来调模型参数",{"2":{"90":1}}],["而是直接构造一个损失函数",{"2":{"90":1}}],["而是看整条推理链的正确率",{"2":{"90":1}}],["而是让模型生成多个可能的思考路径",{"2":{"88":1}}],["而是让模型从人类偏好中",{"2":{"83":1}}],["而是采用不同策略",{"2":{"86":1}}],["而是通过人类偏好间接塑造模型行为",{"2":{"83":1}}],["而是用上次缓存",{"2":{"81":1}}],["而是以一串可以学习的向量",{"2":{"80":1}}],["而是定义一个搜索空间和评分标准",{"2":{"80":1}}],["而是将语料分成许多小批次",{"2":{"66":1}}],["而是在让模型生成文本时",{"2":{"48":1}}],["而无需修改函数内部",{"2":{"63":1}}],["而无需人工逐句标注",{"2":{"53":1}}],["而编码器",{"2":{"56":1}}],["而更像是即兴创作",{"2":{"48":1}}],["而直接训练专用模型则像是不参考任何资料从零开始解题",{"2":{"46":1}}],["就懵了",{"2":{"120":1}}],["就用了新的位置编码",{"2":{"120":1}}],["就刷新了语言模型长文本基准",{"2":{"116":1}}],["就选编码器模型",{"2":{"99":1}}],["就选解码器模型",{"2":{"99":1}}],["就不做",{"2":{"90":1}}],["就明白了口吻要真挚",{"2":{"89":1}}],["就明说",{"2":{"89":1}}],["就把那段文章包含在提示中",{"2":{"89":1}}],["就把它也加入上下文",{"2":{"73":1}}],["就提示",{"2":{"89":1}}],["就可能少用",{"2":{"88":1}}],["就学习这种风格",{"2":{"83":1}}],["就输出一个分数",{"2":{"83":1}}],["就给它奖励",{"2":{"83":1}}],["就够了",{"2":{"81":1}}],["就快很多",{"2":{"81":1}}],["就需要把模型计算分拆到多块设备并行完成",{"2":{"81":1}}],["就能用",{"2":{"120":1}}],["就能让模型回答各类关于常识或语言的问题",{"2":{"86":1}}],["就能让模型进入评分模式",{"2":{"80":1}}],["就能让模型执行新任务",{"2":{"80":1}}],["就能明白任何问句都该老老实实回答",{"2":{"75":1}}],["就能完成特定功能",{"2":{"63":1}}],["就好比掌握了调控",{"2":{"73":1}}],["就好比预先写好一封信的格式",{"2":{"64":1}}],["就像你学会了一种通用编号法或者节奏规律",{"2":{"120":1}}],["就像让一个人阅读一本巨著时提高阅读策略",{"2":{"114":1}}],["就像让模型阅读百科全书打好基础",{"2":{"109":1}}],["就像一个通才",{"2":{"106":1}}],["就像孩子通过奖惩明白哪些行为受欢迎",{"2":{"83":1}}],["就像训练模型参加一个",{"2":{"83":1}}],["就像不重做已经做过的功课",{"2":{"81":1}}],["就像人在正式回答前先把题目或已有内容看懂",{"2":{"73":1}}],["就像我们解数学题时会写下每一步计算过程",{"2":{"72":1}}],["就像我们向人提问或说明任务一样",{"2":{"64":1}}],["就像动物训练中突然暴躁",{"2":{"66":1}}],["就像驯养一只庞大的动物",{"2":{"66":1}}],["就像程序员先使用成熟框架",{"2":{"46":1}}],["就在没有人工帮助下学会了语言知识",{"2":{"53":1}}],["就是将文本分段并引入记忆机制",{"2":{"114":1}}],["就是用了多轮这种拒绝采样",{"2":{"90":1}}],["就是前述自洽方法的泛化",{"2":{"88":1}}],["就是允许模型尝试更多种可能答案再选择最佳",{"2":{"88":1}}],["就是典型的仅解码器预训练",{"2":{"79":1}}],["就是模型要学会猜对下文",{"2":{"79":1}}],["就是使用一系列",{"2":{"75":1}}],["就是训练模型学会",{"2":{"67":1}}],["就是一种无监督学习",{"2":{"53":1}}],["就是学会去近似这些概率",{"2":{"48":1}}],["好看",{"2":{"106":1}}],["好的数据准备确保模型",{"2":{"100":1}}],["好的应用会根据任务选择或混合使用这些策略",{"2":{"73":1}}],["好回答",{"2":{"83":1}}],["好比多人协作时要互相传递结果",{"2":{"81":1}}],["好比每次考试都写老师最想看到的标准答案",{"2":{"73":1}}],["好狗",{"2":{"67":1}}],["好",{"2":{"48":1,"83":1,"93":2}}],["气",{"2":{"48":1}}],["天生适合翻译",{"2":{"99":1}}],["天气",{"2":{"93":2,"119":1}}],["天",{"2":{"48":1}}],["今天天气很",{"2":{"48":1}}],["今天天气很好",{"2":{"48":1}}],["今天",{"2":{"48":1}}],["今",{"2":{"48":2}}],["仿佛拥有",{"2":{"48":1}}],["表达力",{"2":{"114":1}}],["表明软提示在内部起作用但人看不见其具体内容",{"2":{"80":1}}],["表示回答好坏程度",{"2":{"83":1}}],["表示哪个更符合人类喜好",{"2":{"82":1}}],["表示下一个词可能是词典中每个词的概率",{"2":{"79":1}}],["表示序列开头到",{"2":{"66":1}}],["表示一段文本xxx的概率",{"2":{"48":1}}],["表现出某种推理和常识能力",{"2":{"48":1}}],["表现出惊人的通用语言能力",{"2":{"48":1}}],["表征",{"2":{"40":1}}],["数配比",{"2":{"110":1}}],["数学证明",{"2":{"90":1}}],["数学推理等",{"2":{"48":1}}],["数亿到数千亿",{"2":{"48":1}}],["数据分析插件",{"0":{"113":1}}],["数据分成",{"2":{"107":1}}],["数据量可能偏少了",{"2":{"110":1}}],["数据量也要跟上",{"2":{"110":1}}],["数据越多",{"2":{"110":1}}],["数据太多",{"2":{"107":1}}],["数据都是英文",{"2":{"100":1}}],["数据平衡",{"2":{"100":1}}],["数据清洗",{"2":{"100":1}}],["数据收集",{"2":{"100":1}}],["数据规模",{"2":{"95":1}}],["数据从哪里来",{"2":{"75":1}}],["数据质控",{"2":{"57":1}}],["数据来源尽可能多样化",{"2":{"100":1}}],["数据来源",{"2":{"57":1}}],["数据切分",{"2":{"40":1}}],["数据",{"2":{"33":1,"40":1}}],["数据配比",{"2":{"33":1}}],["数据准备的规模相当惊人",{"2":{"100":1}}],["数据准备",{"0":{"100":1},"2":{"33":2}}],["数据并行的好处是实现相对简单",{"2":{"107":1}}],["数据并行",{"2":{"33":2,"107":2,"124":1}}],["数据模型算力需要配平",{"2":{"33":1}}],["数据与语料",{"2":{"33":1}}],["数据库独立性",{"0":{"31":1}}],["数据库",{"2":{"11":1}}],["内存根本装不下全部参数",{"2":{"81":1}}],["内存管理",{"0":{"62":1}}],["内化",{"2":{"80":1}}],["内化为自己的能力",{"2":{"75":1}}],["内置",{"2":{"46":1}}],["内容更有用",{"2":{"83":1}}],["内容",{"2":{"41":1}}],["内容质量",{"2":{"29":1}}],["已经推出支持",{"2":{"122":1}}],["已经做了基本",{"2":{"90":1}}],["已经相当有效",{"2":{"90":1}}],["已经在训练中学到了大量知识",{"2":{"72":1}}],["已经掌握了广泛的知识和语言模式",{"2":{"46":1}}],["已发布文章",{"2":{"26":1,"58":1,"60":1}}],["类模型奠定了基础",{"2":{"109":1}}],["类似道理",{"2":{"114":1}}],["类似于人读书也先读章节再总结全书",{"2":{"114":1}}],["类似于我们把题目记在脑子里",{"2":{"73":1}}],["类似蒙特卡罗树搜索在决策中的用法",{"2":{"88":1}}],["类似地",{"2":{"72":1,"74":1}}],["类比来说",{"2":{"73":1}}],["类比",{"2":{"46":1,"48":1,"56":1,"66":1,"79":1,"86":1,"93":1,"100":1,"107":1,"110":1,"114":1,"118":1,"120":1}}],["类名",{"2":{"32":1}}],["和穿更先进的装备",{"2":{"110":1}}],["和自监督",{"2":{"109":1}}],["和合适的激活函数",{"2":{"104":1}}],["和衰减策略",{"2":{"104":1}}],["和方案",{"2":{"88":1}}],["和去噪自编码",{"2":{"86":1}}],["和已经生成的部分",{"2":{"73":1}}],["和解码",{"2":{"73":1}}],["和工具使用则赋予模型查询外部知识和执行操作的能力",{"2":{"72":1}}],["和技巧",{"2":{"66":1}}],["和反复纠正",{"2":{"66":1}}],["和日常生活一样",{"2":{"64":1}}],["和",{"2":{"46":1,"67":1,"88":2,"90":1,"93":1,"103":2,"104":1,"114":1,"116":1}}],["中不是主流策略",{"2":{"118":1}}],["中的前馈网络",{"2":{"104":1}}],["中间算错了但最后猜对了答案",{"2":{"90":1}}],["中间丢失",{"2":{"65":1}}],["中至关重要",{"2":{"90":1}}],["中心写上",{"2":{"72":1}}],["中性",{"2":{"63":1}}],["中相对少见",{"2":{"53":1}}],["中",{"2":{"46":1,"64":1,"67":1,"93":1,"118":1}}],["服务发现",{"0":{"85":1}}],["服务高峰",{"2":{"81":1}}],["服务间通信",{"0":{"44":1},"1":{"51":1,"61":1}}],["服务划分示例",{"2":{"24":1}}],["└──",{"2":{"43":1}}],["└─────────────────┘",{"2":{"31":2}}],["管理可用工具",{"2":{"43":1}}],["├──",{"2":{"43":4}}],["├─────────────────┤",{"2":{"31":2}}],["探索高级功能",{"2":{"130":1}}],["探索不同的城市和文化",{"2":{"42":1}}],["探讨微服务架构的核心设计原则",{"2":{"14":1}}],["旅行",{"2":{"42":1}}],["✈️",{"2":{"42":1}}],["跑更长时间",{"2":{"110":1}}],["跑得更快更省",{"2":{"81":1}}],["跑得快也要跑得省",{"2":{"33":1}}],["跑题",{"2":{"54":1}}],["跑步和健身",{"2":{"42":1}}],["运动",{"2":{"42":1}}],["读到重要内容就写下来提醒自己后面用",{"2":{"116":1}}],["读一部百科全书要把每句话和每句话都对照一遍",{"2":{"114":1}}],["读的书",{"2":{"100":1}}],["读取这个详细提示",{"2":{"89":1}}],["读取文件失败",{"2":{"39":1}}],["读书",{"2":{"42":1}}],["如前置",{"2":{"124":1}}],["如今想扩展到",{"2":{"120":1}}],["如今具备一定的自我检查和改进能力",{"2":{"72":1}}],["如可微神经缓存",{"2":{"116":1}}],["如在",{"2":{"107":1}}],["如在验证集上模型回答的准确率或者得分",{"2":{"80":1}}],["如全连接层需要",{"2":{"107":1}}],["如维基百科",{"2":{"100":1}}],["如提供更多上下文",{"2":{"94":1}}],["如机器翻译",{"2":{"93":1}}],["如不稳定",{"2":{"90":1}}],["如医学诊断",{"2":{"88":1}}],["如数学",{"2":{"88":1}}],["如自动搜索最佳提示",{"2":{"87":1}}],["如同与模型沟通时的礼貌用语",{"2":{"87":1}}],["如何以更优效率获得更强能力",{"2":{"124":1}}],["如何让",{"2":{"112":1}}],["如何确保人工智能的目标真的是我们想要的目标",{"2":{"96":1}}],["如何制造危险物品",{"2":{"82":1}}],["如何对齐模型与人类期望",{"2":{"41":1}}],["如时钟表示缓存",{"2":{"81":1}}],["如生产线一样",{"2":{"81":1}}],["如贪婪是一条直线走",{"2":{"73":1}}],["如写故事",{"2":{"73":1}}],["如搜索引擎",{"2":{"72":1}}],["如网页",{"2":{"53":1}}],["如",{"2":{"48":1,"53":1,"64":1,"72":1,"73":1,"75":3,"79":1,"80":1,"81":2,"82":1,"86":3,"88":1,"90":1,"99":3,"100":2,"103":1,"104":3,"107":1,"109":3}}],["如果能用共享来构造一个",{"2":{"118":1}}],["如果输入文本超过这个长度",{"2":{"112":1}}],["如果换单卡来算",{"2":{"107":1}}],["如果没有多",{"2":{"107":1}}],["如果没有缓存",{"2":{"81":1}}],["如果训练时只见过最多",{"2":{"120":1}}],["如果训练中某段文本重复很多遍",{"2":{"100":1}}],["如果训练数据太少会怎样",{"2":{"66":1}}],["如果奖励模型判断错了",{"2":{"90":1}}],["如果奖励模型不精确",{"2":{"90":1}}],["如果得到的回答不理想",{"2":{"89":1}}],["如果直接说",{"2":{"89":1}}],["如果直接回答",{"2":{"88":1}}],["如果希望输出特定格式或风格",{"2":{"89":1}}],["如果发现矛盾",{"2":{"88":1}}],["如果它们一致",{"2":{"88":1}}],["如果第一次推理没成功",{"2":{"88":1}}],["如果是在关键任务",{"2":{"88":1}}],["如果人类反馈本身存在争议",{"2":{"83":1}}],["如果人类反馈有偏差",{"2":{"83":1}}],["如果情况严重",{"2":{"83":1}}],["如果不微调",{"2":{"106":1}}],["如果不一致",{"2":{"88":1}}],["如果不加约束",{"2":{"82":1}}],["如果不对齐",{"2":{"67":1}}],["如果每个问题独立处理",{"2":{"81":1}}],["如果模型太大而数据不足",{"2":{"110":1}}],["如果模型主要服务英文用户",{"2":{"100":1}}],["如果模型训练数据在某类文本上比例过大",{"2":{"100":1}}],["如果模型在解一道数学题",{"2":{"90":1}}],["如果模型部署时用了",{"2":{"81":1}}],["如果模型是一本",{"2":{"81":1}}],["如果模型每次都选最高概率词",{"2":{"73":1}}],["如果有",{"2":{"81":1}}],["如果让你来给模型准备指令对齐的数据",{"2":{"75":1}}],["如果把温度调高",{"2":{"73":1}}],["如果用户询问",{"2":{"82":1}}],["如果用",{"2":{"73":1}}],["如果用贪婪搜索",{"2":{"73":1}}],["如果接入",{"2":{"72":1}}],["如果本周末天气很好",{"2":{"64":1}}],["如果",{"2":{"64":1,"81":1,"90":1,"100":1}}],["如果我们想在一个模型上微调到更短的序列",{"2":{"120":1}}],["如果我们想通过增加层数来让模型看更长范围的信息",{"2":{"118":1}}],["如果我们想让提示更具体",{"2":{"64":1}}],["如果我们要求它",{"2":{"72":1}}],["如果我们问它",{"2":{"64":1}}],["如果我们向朋友含糊地下指令",{"2":{"64":1}}],["如果我们用",{"2":{"48":1}}],["如果你是工程师",{"2":{"104":1}}],["如果你问",{"2":{"75":1}}],["如果你让模型回答同一个问题五次并得到不同答案",{"2":{"72":1}}],["如果你对技术有任何问题或想法",{"2":{"42":1}}],["如果你也是技术博主",{"2":{"22":1}}],["等方式",{"2":{"124":1}}],["等也在研究如何让模型接入外部知识库",{"2":{"122":1}}],["等概念",{"2":{"116":1}}],["等于傻傻地",{"2":{"114":1}}],["等研究方向",{"2":{"114":1}}],["等据传都更加注重增加训练数据量",{"2":{"110":1}}],["等模型采用这种思路",{"2":{"114":1}}],["等模型的成功证明了",{"2":{"109":1}}],["等模型成功的第一步",{"2":{"75":1}}],["等待依赖",{"2":{"107":1}}],["等待填写具体内容",{"2":{"64":1}}],["等词语的积极含义和语境",{"2":{"106":1}}],["等大型语料",{"2":{"103":1}}],["等都是这类思想的体现",{"2":{"88":1}}],["等成功应用背后的秘诀之一",{"2":{"83":1}}],["等同贪婪",{"2":{"73":1}}],["等节点",{"2":{"72":1}}],["等价于最小化预测下一个词的误差",{"2":{"66":1}}],["等知名大模型内部都是这种架构",{"2":{"56":1}}],["等",{"2":{"41":1,"64":1,"75":1,"80":1,"86":1,"90":2,"104":4}}],["系列激活函数",{"2":{"104":1}}],["系列模型",{"2":{"79":1}}],["系列",{"2":{"41":1,"72":1,"99":1,"109":1}}],["系统符合人类价值观",{"2":{"67":1}}],["系统提示",{"2":{"54":1}}],["系统",{"2":{"33":1}}],["系统架构",{"2":{"10":1}}],["虚构",{"2":{"41":1}}],["评述",{"0":{"122":1}}],["评审提示",{"2":{"54":1}}],["评估来加快偏好数据积累",{"2":{"90":1}}],["评估输出",{"2":{"80":1}}],["评估与权衡",{"2":{"65":1}}],["评估与安全",{"2":{"57":1}}],["评估与抗风险",{"2":{"54":1}}],["评估",{"2":{"41":1}}],["评测指标",{"2":{"33":1}}],["评测",{"2":{"33":1,"40":1}}],["贴近偏好",{"2":{"41":1}}],["控制",{"2":{"41":1}}],["困惑度也许能降一大块",{"2":{"110":1}}],["困惑度",{"2":{"41":1}}],["机器学习",{"2":{"93":1,"103":1}}],["机器学习改变世界",{"2":{"93":2}}],["机器学习使生活充满樱桃味",{"2":{"73":1}}],["机器学习使生活变成一场游戏",{"2":{"73":1}}],["机器学习使生活更美好",{"2":{"73":1}}],["机器学习使生活",{"2":{"73":1}}],["机器只是顺便执行",{"2":{"78":1}}],["机器帮你把问法调优并变短",{"2":{"33":1}}],["机制",{"2":{"40":1,"116":1}}],["删除",{"2":{"40":1}}],["审核",{"2":{"40":1}}],["审计",{"2":{"40":1}}],["版权",{"2":{"40":1}}],["再处理摘要串联的高层块",{"2":{"114":1}}],["再通过用户提示完成具体任务",{"2":{"109":1}}],["再所有机器聚合梯度",{"2":{"107":1}}],["再在每组内部对模型做张量并行或管道并行",{"2":{"107":1}}],["再残差",{"2":{"104":1}}],["再到各种新颖的改进方法",{"2":{"96":1}}],["再答",{"2":{"94":1}}],["再加上推理时筛选把关",{"2":{"90":1}}],["再",{"2":{"89":1}}],["再给答案",{"2":{"89":1}}],["再给出根据资料的回答",{"2":{"72":1}}],["再给出结论",{"2":{"72":1}}],["再返回重新推理",{"2":{"88":1}}],["再自己验证一下结果是否符合题意",{"2":{"88":1}}],["再深入方案正确的继续推理",{"2":{"88":1}}],["再如思维链提示和问题分解",{"2":{"88":1}}],["再比如",{"2":{"81":1}}],["再迭代改进提示",{"2":{"80":1}}],["再用另一个模型或规则去判断哪个更好",{"2":{"90":1}}],["再用这些回答去微调",{"2":{"75":1}}],["再用人类反馈强化学习进一步调整",{"2":{"74":1}}],["再由人过滤修改作为训练集",{"2":{"75":1}}],["再只保留前",{"2":{"73":1}}],["再基于结果继续推理",{"2":{"72":1}}],["再提示",{"2":{"72":1}}],["再综合给出最可能的诊断及理由",{"2":{"72":1}}],["再综合这些答案",{"2":{"72":1}}],["再综合",{"2":{"72":1}}],["再算",{"2":{"72":1}}],["再反向传播调整参数",{"2":{"66":1}}],["再正式写文",{"2":{"56":1}}],["再经过适度微调",{"2":{"63":1}}],["再经过",{"2":{"56":1}}],["再针对具体需求写少量代码",{"2":{"46":1}}],["再平衡",{"2":{"40":1}}],["再生成答案的多阶段流程",{"2":{"72":1}}],["再生成",{"2":{"33":1}}],["毒性",{"2":{"40":1}}],["偏置可以提升训练稳定性",{"2":{"104":1}}],["偏好采集",{"2":{"57":1}}],["偏好对",{"2":{"33":1}}],["偏好对齐",{"2":{"33":2,"57":1}}],["偏见",{"2":{"40":1}}],["指的是在模型生成推理阶段投入更多计算资源或策略",{"2":{"88":1}}],["指的是引导模型的行为符合人类的意图",{"2":{"82":1}}],["指的是它生成文本答案的过程",{"2":{"73":1}}],["指的就是使用数据和算法来自动发现或调整最有效的提示",{"2":{"80":1}}],["指检索增强生成",{"2":{"72":1}}],["指标集合",{"2":{"57":1}}],["指纹",{"2":{"40":1}}],["指令泛化",{"2":{"75":1}}],["指令微调",{"2":{"74":1,"75":1}}],["指令或上下文",{"2":{"64":1}}],["指令描述",{"2":{"54":1}}],["指令化",{"2":{"41":1}}],["指令",{"2":{"33":1,"41":1,"74":1}}],["指令响应微调打行为基线",{"2":{"33":1}}],["指令对齐为模型奠定了听从指挥的基础",{"2":{"96":1}}],["指令对齐让模型从",{"2":{"75":1}}],["指令对齐方法在不断发展",{"2":{"75":1}}],["指令对齐通过有监督学习方式",{"2":{"75":1}}],["指令对齐的一般过程",{"2":{"75":1}}],["指令对齐主要讨论如何通过监督微调让模型学会更好地遵循人类指令",{"2":{"75":1}}],["指令对齐",{"0":{"75":1},"2":{"33":2,"34":1,"57":1}}],["指令遵循与格式化输出",{"2":{"33":1}}],["重温",{"2":{"116":1}}],["重点浏览",{"2":{"114":1}}],["重排序融合",{"2":{"65":1}}],["重排序",{"2":{"57":1}}],["重复利用",{"2":{"122":1}}],["重复性",{"2":{"54":1}}],["重复惩罚",{"2":{"41":1,"65":1}}],["重复",{"2":{"40":1,"73":1}}],["重用参数只算关键路径",{"2":{"33":1}}],["泄露",{"2":{"40":1,"54":1}}],["标准",{"2":{"104":2,"112":1}}],["标记",{"2":{"103":1}}],["标签",{"2":{"100":1}}],["标签平滑",{"2":{"40":1,"41":1}}],["标注为",{"2":{"90":1}}],["标注在某步验证失败",{"2":{"88":1}}],["标注规范",{"2":{"57":1}}],["标注",{"2":{"40":1,"90":3}}],["基于以下数据分析结果生成专业报告",{"2":{"113":1}}],["基本对齐",{"2":{"90":1}}],["基本的提示可能不足以引导模型得出正确或详细的答案",{"2":{"72":1}}],["基础提示要求指令清晰具体",{"2":{"87":1}}],["基础知识",{"2":{"27":1}}],["基准",{"2":{"40":1}}],["微调让模型在特定任务上大放异彩",{"2":{"109":1}}],["微调实现个性化的任务适配",{"2":{"106":1}}],["微调就好比岗前培训",{"2":{"106":1}}],["微调阶段",{"2":{"106":1}}],["微调的模型",{"2":{"90":1}}],["微调的计算开销相对预训练要低很多",{"2":{"63":1}}],["微调数据获取",{"2":{"75":1}}],["微调有几个常见场景",{"2":{"74":1}}],["微调在",{"2":{"74":1}}],["微调能针对任务优化模型参数",{"2":{"63":1}}],["微调方法",{"2":{"63":1}}],["微调模型解决特定问题",{"2":{"46":1}}],["微调",{"0":{"74":1},"2":{"40":2,"41":1,"63":1,"74":1,"90":1,"106":1,"124":2}}],["微服务不是银弹",{"2":{"102":1}}],["微服务架构设计原则",{"0":{"14":1},"1":{"19":1,"24":1,"31":1,"38":1,"44":1,"51":1,"61":1,"69":1,"77":1,"85":1,"92":1,"98":1,"102":1},"2":{"58":1}}],["微服务",{"0":{"58":1},"2":{"10":1,"16":1}}],["线性",{"2":{"40":1}}],["冻结",{"2":{"40":1}}],["特别地",{"2":{"124":1}}],["特定任务",{"2":{"41":1}}],["特征",{"2":{"40":1}}],["特性",{"2":{"40":1}}],["蒸馏",{"2":{"40":1}}],["堆叠",{"2":{"40":1}}],["术语",{"2":{"40":1}}],["注意力",{"2":{"40":1}}],["注意力与",{"2":{"33":1}}],["注释",{"2":{"40":1}}],["切分",{"2":{"40":1}}],["切分粒度和句子长度直接影响成本",{"2":{"33":1}}],["专门针对",{"2":{"81":1}}],["专业",{"2":{"40":2}}],["专注于全栈开发和架构设计",{"2":{"1":1}}],["上训练往往不现实",{"2":{"107":1}}],["上述几点值得特别留意",{"2":{"104":1}}],["上述方法都需要改模型参数",{"2":{"90":1}}],["上一章内容",{"2":{"94":1}}],["上",{"2":{"81":1,"107":1}}],["上大规模剪枝可能影响性能",{"2":{"81":1}}],["上实现了较快推理",{"2":{"81":1}}],["上预训练一个模型",{"2":{"53":1}}],["上三角",{"2":{"41":1}}],["上采样",{"2":{"40":1}}],["上下文的",{"2":{"122":1}}],["上下文信息",{"2":{"118":1}}],["上下文提供太多信息可能有什么负面效果",{"2":{"88":1}}],["上下文来做好预测",{"2":{"79":1}}],["上下文扩展的核心是在不改变模型的情况下",{"2":{"88":1}}],["上下文扩展",{"2":{"65":1,"88":2}}],["上下文编码",{"2":{"65":1}}],["上下文学习",{"2":{"63":1}}],["上下文长度",{"2":{"54":1,"112":1}}],["上下文压缩",{"2":{"33":1}}],["上下文",{"2":{"33":1,"89":1,"120":1}}],["采用",{"2":{"82":1,"104":1}}],["采样是每步从概率前",{"2":{"73":1}}],["采样等",{"2":{"73":1}}],["采样和top",{"2":{"73":1}}],["采样式",{"2":{"65":1}}],["采样",{"2":{"40":2,"73":1}}],["采集清洗去重",{"2":{"33":1}}],["子层输出",{"2":{"104":1}}],["子问题生成器",{"2":{"54":1}}],["子任务列表",{"2":{"54":1}}],["子词",{"2":{"40":1}}],["子栏目",{"2":{"3":1,"10":1,"15":1}}],["残差",{"2":{"40":2,"41":1}}],["归一",{"2":{"40":1}}],["权重衰减",{"2":{"40":1}}],["正常情况下不会",{"2":{"100":1}}],["正是这些修改和技巧的积累",{"2":{"104":1}}],["正是有了对齐技术",{"2":{"96":1}}],["正是通过人类反馈",{"2":{"83":1}}],["正如顶尖",{"2":{"110":1}}],["正如",{"2":{"82":1}}],["正面",{"2":{"63":5,"106":2}}],["正负对配对",{"2":{"57":1}}],["正确",{"2":{"96":1}}],["正确答案",{"2":{"53":1}}],["正确输出",{"2":{"53":1}}],["正确的异常处理",{"2":{"39":1}}],["正则化防止过拟合",{"2":{"66":1}}],["正则",{"2":{"40":1}}],["裁剪",{"2":{"40":1,"41":1}}],["退火",{"2":{"40":1,"41":1}}],["变得",{"2":{"114":1}}],["变得更像一个有道德与常识的助手",{"2":{"82":1}}],["变成",{"2":{"75":1}}],["变种算法来优化模型参数",{"2":{"66":1}}],["变体",{"2":{"40":2}}],["变量位",{"2":{"33":1}}],["交流连贯",{"2":{"122":1}}],["交叉熵",{"2":{"40":1,"41":1}}],["交互与控制",{"2":{"33":1}}],["损失会平滑地降低",{"2":{"110":1}}],["损失才小",{"2":{"93":1}}],["损失",{"2":{"40":1}}],["拼接输出",{"2":{"107":1}}],["拼接",{"2":{"40":1}}],["截断",{"2":{"40":1}}],["策略组合",{"2":{"65":1}}],["策略优化",{"2":{"57":1}}],["策略",{"2":{"40":1,"41":1,"90":1,"124":1}}],["词表",{"2":{"40":2}}],["网络中完成",{"2":{"56":1}}],["网页爬取内容",{"2":{"100":1}}],["网页",{"2":{"40":1}}],["网站",{"2":{"36":1}}],["网站描述",{"2":{"36":1}}],["网站链接",{"2":{"36":1}}],["网站名称",{"2":{"36":1}}],["网站结构清晰",{"2":{"29":1}}],["网站性能",{"2":{"29":1}}],["语气却略显啰嗦",{"2":{"90":1}}],["语气更友善",{"2":{"83":1}}],["语法以及一定的常识知识",{"2":{"79":1}}],["语法约束",{"2":{"65":1}}],["语料与分词",{"2":{"40":1}}],["语言模型",{"2":{"79":1}}],["语言模型会将这个概率拆解为每个词逐次出现的条件概率的乘积",{"2":{"48":1}}],["语言及生态相关的内容",{"2":{"60":1}}],["语言理解与生成",{"2":{"33":1}}],["语言与框架相关内容",{"2":{"15":1}}],["语言官方文档",{"2":{"12":1}}],["语言",{"2":{"7":1,"11":1}}],["摘要这类需要读写的任务",{"2":{"99":1}}],["摘要等",{"2":{"93":1}}],["摘要蒸馏",{"2":{"54":1}}],["摘要",{"2":{"40":1}}],["摘要压缩",{"2":{"33":1}}],["翻译以下句子",{"2":{"75":1}}],["翻译",{"2":{"40":1,"75":1,"80":1}}],["抽取式问答",{"2":{"40":1}}],["抽取",{"2":{"40":1}}],["掩码建模",{"2":{"40":1}}],["掩码语言模型等",{"2":{"99":1}}],["掩码语言模型好比给模型出阅读理解题",{"2":{"86":1}}],["掩码语言模型",{"2":{"33":1,"86":1,"103":1}}],["对训练长序列本身没有提高模型能力",{"2":{"116":1}}],["对长度",{"2":{"114":1}}],["对实践的影响是",{"2":{"110":1}}],["对我们规划训练有指导意义",{"2":{"110":1}}],["对应的向量代表了这句话的大致语义",{"2":{"106":1}}],["对其他语言就相对较弱",{"2":{"100":1}}],["对初学者来说",{"2":{"96":1}}],["对不受偏好的降低",{"2":{"90":1}}],["对不起",{"2":{"67":1,"82":1}}],["对象是好朋友",{"2":{"89":1}}],["对当前世界的知识只来自训练截断的语料",{"2":{"89":1}}],["对零基础的学习者来说",{"2":{"87":1}}],["对输出进行打分",{"2":{"83":1}}],["对这些回答打分",{"2":{"82":1}}],["对用户历史对话做缓存",{"2":{"81":1}}],["对使用者而言不需要深入了解原理",{"2":{"81":1}}],["对同一道题",{"2":{"72":1}}],["对复杂任务",{"2":{"64":1}}],["对于长文本",{"2":{"118":1}}],["对于长序列任务",{"2":{"118":1}}],["对于给定算力预算",{"2":{"110":1}}],["对于超大模型",{"2":{"107":1}}],["对于入门学习者",{"2":{"94":1}}],["对于输入",{"2":{"93":1}}],["对于复杂任务",{"2":{"89":1}}],["对于更新的事实或上下文不敏感",{"2":{"89":1}}],["对于句子",{"2":{"86":1}}],["对于缓存",{"2":{"81":1}}],["对于学习者",{"2":{"81":1}}],["对于学习者而言",{"2":{"73":1}}],["对于",{"2":{"74":1,"81":1}}],["对于一句评论",{"2":{"63":1}}],["对于大型的序列生成模型",{"2":{"63":1}}],["对",{"2":{"63":1,"64":1,"72":1,"74":2,"75":1}}],["对抗样本",{"2":{"57":1}}],["对答如流",{"2":{"48":1}}],["对话微调可以被视为指令微调的一个特例",{"2":{"74":1}}],["对话微调",{"2":{"74":1}}],["对话的入口",{"2":{"64":1}}],["对话内容",{"2":{"64":1}}],["对话",{"2":{"40":1}}],["对齐模型",{"2":{"124":1}}],["对齐成为焦点",{"2":{"124":1}}],["对齐将继续作为",{"2":{"96":1}}],["对齐始终面临一个核心挑战",{"2":{"96":1}}],["对齐的思想",{"2":{"83":1}}],["对齐的重要性愈发凸显",{"2":{"96":1}}],["对齐的重要性不言而喻",{"2":{"82":1}}],["对齐的重要性可以通过",{"2":{"67":1}}],["对齐后的模型",{"2":{"82":1}}],["对齐效果对比示例",{"2":{"82":1}}],["对齐就是让模型更安全可靠地服务于人类",{"2":{"82":1}}],["对齐就是让大模型",{"2":{"67":1}}],["对齐步骤会教模型避免复述这些偏见",{"2":{"82":1}}],["对齐可以来自多方面的人类指导",{"2":{"82":1}}],["对齐相关微调",{"2":{"74":1}}],["对齐让模型更贴近一个负责",{"2":{"67":1}}],["对齐工作既是技术问题也是伦理问题",{"2":{"67":1}}],["对齐变得更加重要",{"2":{"67":1}}],["对齐涵盖了各种让",{"2":{"67":1}}],["对齐特别关注两个方面",{"2":{"67":1}}],["对齐过程就是要矫正这些偏差",{"2":{"67":1}}],["对齐过渡",{"2":{"41":1}}],["对齐概述",{"0":{"67":1}}],["对齐",{"0":{"49":1,"57":1},"1":{"57":1,"67":2,"75":2,"83":2,"90":2,"96":2},"2":{"33":2,"34":1,"40":1,"57":1,"67":1,"82":1,"106":1}}],["对齐与安全",{"2":{"33":2}}],["对齐技术",{"2":{"27":1}}],["用接近模型已知范围的",{"2":{"120":1}}],["用的是一种相对位置方案",{"2":{"120":1}}],["用的就是",{"2":{"104":1}}],["用固定的正弦波位置编码",{"2":{"104":1}}],["用了网络内容",{"2":{"100":1}}],["用了",{"2":{"100":1,"103":1}}],["用于分类",{"2":{"99":1}}],["用于真实应用时",{"2":{"81":1}}],["用机器生成",{"2":{"90":1}}],["用柱状图表示提升幅度",{"2":{"88":1}}],["用各类扩展后的模型成功率",{"2":{"88":1}}],["用更多计算和自我检验",{"2":{"88":1}}],["用更强力的搜索找到更好的输出",{"2":{"88":1}}],["用更少的内存和计算",{"2":{"81":1}}],["用示例",{"2":{"88":1}}],["用上一步大量的人类偏好数据",{"2":{"83":1}}],["用来进一步调整模型的输出使其符合人类偏好",{"2":{"83":1}}],["用一个轻量级过滤模型挑掉含有不当内容的",{"2":{"90":1}}],["用一个框图表示模板",{"2":{"64":1}}],["用一组原则",{"2":{"82":1}}],["用强化学习的方法",{"2":{"82":1}}],["用人类精心准备的指令",{"2":{"82":1}}],["用颜色高亮重复部分被跳过的情形",{"2":{"81":1}}],["用颜色标出不同行为",{"2":{"73":1}}],["用得快",{"2":{"81":1}}],["用专门的深度学习编译器或",{"2":{"81":1}}],["用图表展示优化前后提示长度的对比",{"2":{"80":1}}],["用微调让模型熟悉某种任务格式",{"2":{"80":1}}],["用弱模型学会这些知识",{"2":{"80":1}}],["用弱模型",{"2":{"75":1}}],["用相同开头让模型在不同温度下生成句子",{"2":{"73":1}}],["用束搜索",{"2":{"73":1}}],["用三个不同措辞的提示让模型生成三个版本的摘要",{"2":{"72":1}}],["用",{"2":{"64":1,"80":1,"89":1,"90":1}}],["用许多标注了",{"2":{"63":1}}],["用带有情感标签的句子微调整个网络的参数",{"2":{"63":1}}],["用途",{"2":{"40":3}}],["用户几乎从不会看到模型的不当回答了",{"2":{"90":1}}],["用户请求不当内容",{"2":{"83":1}}],["用户要求模型讲笑话",{"2":{"82":1}}],["用户问",{"2":{"82":1,"83":1}}],["用户问科普问题",{"2":{"82":1}}],["用户问句",{"2":{"74":1}}],["用户问题",{"2":{"72":1}}],["用户问它",{"2":{"67":1}}],["用户提问",{"2":{"72":1}}],["用户如果提出模棱两可的问题",{"2":{"67":1}}],["用户体验良好",{"2":{"29":1}}],["用户权限验证",{"2":{"24":1}}],["用户信息管理",{"2":{"24":1}}],["用户注册",{"2":{"24":1}}],["下次遇到同样请求直接返回已有答案",{"2":{"81":1}}],["下一步",{"0":{"130":1}}],["下一节详述",{"2":{"114":1}}],["下一句预测",{"2":{"103":1}}],["下一句话怎么说",{"2":{"79":1}}],["下一词",{"2":{"40":1,"41":1}}],["下模型生成三句话的对比",{"2":{"73":1}}],["下面我们分别说明每种架构常用的预训练任务",{"2":{"71":1}}],["下划线分隔",{"2":{"32":1}}],["范式已经形成",{"2":{"124":1}}],["范式的有效性",{"2":{"109":1}}],["范式",{"2":{"40":1}}],["+",{"2":{"39":1,"102":1,"104":1,"106":1}}],["xl引入了循环记忆",{"2":{"116":1}}],["xl",{"2":{"114":1,"116":2,"120":1}}],["xlnet",{"2":{"86":1}}],["xlm",{"2":{"33":1}}],["xx",{"2":{"72":1}}],["xi​∣x",{"2":{"66":1}}],["xi∣x",{"2":{"66":1}}],["xm​",{"2":{"66":1}}],["xm",{"2":{"66":1}}],["x1​",{"2":{"66":1}}],["x1",{"2":{"66":1}}],["x0​",{"2":{"66":1}}],["x0",{"2":{"66":1}}],["x=",{"2":{"66":2}}],["x",{"2":{"48":3,"66":14,"110":1}}],["x3c",{"2":{"38":2,"52":5}}],["共同存储计算",{"2":{"81":1}}],["共同推进技术社区发展",{"2":{"36":1}}],["共享后的模型其实有一种循环特性",{"2":{"118":1}}],["共享",{"2":{"40":1,"122":1}}],["共享词表",{"2":{"33":1}}],["我爱",{"2":{"103":1}}],["我爱机器学习",{"2":{"103":1}}],["我感到很抱歉",{"2":{"89":1}}],["我昨晚错过了好朋友的生日聚会",{"2":{"89":1}}],["我昨天去",{"2":{"86":1}}],["我无法帮助执行这个请求",{"2":{"83":1}}],["我很难过",{"2":{"83":1}}],["我理解你的情绪",{"2":{"67":1}}],["我的歌单",{"2":{"42":1}}],["我还喜欢",{"2":{"42":1}}],["我们或许终有一天可以有模型读完整部百科全书后一气回答问题",{"2":{"122":1}}],["我们已经部分突破了限制",{"2":{"122":1}}],["我们付出指数增加的计算",{"2":{"110":1}}],["我们才能在合理时间和成本内训练出超大模型",{"2":{"107":1}}],["我们把同一时间的一个大批次",{"2":{"107":1}}],["我们把一句完整的话偷偷改乱",{"2":{"93":1}}],["我们在这个向量后接一个分类器层",{"2":{"106":1}}],["我们在",{"2":{"104":1}}],["我们在子类中微调一些参数",{"2":{"63":1}}],["我们来看一个经典的预训练模型",{"2":{"103":1}}],["我们介绍了三类主要的预训练任务",{"2":{"99":1}}],["我们介绍了预填充",{"2":{"94":1}}],["我们了解到",{"2":{"96":1}}],["我们了解到大语言模型的提示技巧对于引导模型行为至关重要",{"2":{"87":1}}],["我们还需要不断改进算法让模型高效利用每一点上下文",{"2":{"122":1}}],["我们还需要对",{"2":{"103":1}}],["我们还讨论了推理时的扩展方法",{"2":{"94":1}}],["我们还有另一种不改变模型参数的方法",{"2":{"63":1}}],["我们描述了多种高效推理的技术",{"2":{"94":1}}],["我们讨论了大型语言模型",{"2":{"94":1}}],["我们并没有特定的下游任务让模型去翻译某种语言或摘要新闻",{"2":{"93":1}}],["我们采用",{"2":{"90":1}}],["我们收集了一些带标注步骤的数学题解答",{"2":{"90":1}}],["我们手头偏好数据有限",{"2":{"90":1}}],["我们能",{"2":{"90":1}}],["我们选最好的一篇",{"2":{"90":1}}],["我们宁可多花几倍算力采用推理扩展以确保正确",{"2":{"88":1}}],["我们常在关键要求高准确的任务上使用一些搜索扩展",{"2":{"88":1}}],["我们常使用提示模板",{"2":{"64":1}}],["我们之前说过",{"2":{"88":1}}],["我们稍后介绍",{"2":{"86":1}}],["我们再通过新增数据或规则去进一步对齐",{"2":{"82":1}}],["我们再让模型综合",{"2":{"72":1}}],["我们往往很难事先穷举所有",{"2":{"82":1}}],["我们往往需要的数据少",{"2":{"74":1}}],["我们喂给模型大量例子",{"2":{"82":1}}],["我们有没有可能让模型",{"2":{"81":1}}],["我们有一个海量语料库",{"2":{"66":1}}],["我们经常会组合使用",{"2":{"81":1}}],["我们想让模型在回答时一直采用正式礼貌的语气",{"2":{"80":1}}],["我们平常给模型的提示都是自然语言的文本",{"2":{"80":1}}],["我们给模型同一个问题生成两份回答",{"2":{"83":1}}],["我们给模型很多自然语言序列",{"2":{"79":1}}],["我们给它不同的短语",{"2":{"80":1}}],["我们希望模型不只会按训练过的指令套路回答",{"2":{"75":1}}],["我们让模型自己生成一组关于礼貌用语的对话",{"2":{"90":1}}],["我们让模型对比哪种更简洁正确",{"2":{"88":1}}],["我们让它列出两种不同提示下的诊断结果进行比较",{"2":{"72":1}}],["我们让",{"2":{"72":1,"88":1}}],["我们需要在技术上精益求精",{"2":{"96":1}}],["我们需要收集微调数据",{"2":{"75":1}}],["我们需要让模型通过检索外部信息来帮助回答",{"2":{"72":1}}],["我们需要一些进阶的提示技巧",{"2":{"72":1}}],["我们需要稍微调整模型使其在目标任务上表现更好",{"2":{"63":1}}],["我们不再完全靠直觉猜测提示",{"2":{"80":1}}],["我们不会每次用完整语料去算梯度",{"2":{"66":1}}],["我们不直接关心这个概率有多大",{"2":{"48":1}}],["我们用对数似然衡量模型对序列的拟合程度",{"2":{"66":1}}],["我们可能给模型的输入是",{"2":{"93":1}}],["我们可能尝试不同措辞",{"2":{"64":1}}],["我们可以每",{"2":{"107":1}}],["我们可以给它更多信息",{"2":{"88":1}}],["我们可以综合信息后得到更稳健的结果",{"2":{"88":1}}],["我们可以用较便宜的硬件服务更多用户且速度更快",{"2":{"81":1}}],["我们可以用一批标注好的情感评论数据来微调它",{"2":{"63":1}}],["我们可以怎样确保模型依然获得完成任务所需的信息",{"2":{"80":1}}],["我们可以让另一批人专门给一些回答的",{"2":{"90":1}}],["我们可以让编码器学到把文本编码成有用表示的方法",{"2":{"86":1}}],["我们可以让模型自己学会提示",{"2":{"80":1}}],["我们可以让同一个模型既能严谨答题",{"2":{"73":1}}],["我们可以训练一个软提示向量",{"2":{"80":1}}],["我们可以在不改动模型本身的情况下显著增强其解题能力和可靠性",{"2":{"94":1}}],["我们可以在医学论文和问答数据上微调它",{"2":{"74":1}}],["我们可以在提示中指明模型的身份或上下文",{"2":{"64":1}}],["我们可以把",{"2":{"73":1}}],["我们可以把复杂任务拆给模型",{"2":{"72":1}}],["我们可以通过提示让模型优化自己的输出",{"2":{"72":1}}],["我们可以直接问它",{"2":{"63":1}}],["我们会在第",{"2":{"89":1}}],["我们会在后续章节更深入讨论提示和微调的高级技巧",{"2":{"63":1}}],["我们会讲述如何通过大规模数据和分布式技术来扩大模型训练",{"2":{"41":1}}],["我们通常选择低学习率",{"2":{"74":1}}],["我们通常需要让它适应特定任务",{"2":{"63":1}}],["我们通过不同的输入",{"2":{"63":1}}],["我们巧妙地设计输入让模型发挥出解决新任务的能力",{"2":{"63":1}}],["我们设计一个",{"2":{"53":1}}],["我们先对一段原始文本进行",{"2":{"93":1}}],["我们先让模型翻译一段文本",{"2":{"72":1}}],["我们先",{"2":{"46":1}}],["我们期待与更多优秀的技术博主建立友谊",{"2":{"36":1}}],["我是",{"0":{"1":1},"1":{"4":1,"7":1,"11":1,"16":1,"21":1,"28":1,"35":1,"42":1}}],["友链互换",{"2":{"36":1}}],["友情链接",{"0":{"2":1},"1":{"5":1,"8":1,"12":1,"17":1,"22":1,"29":1,"36":1}}],["邮件联系",{"2":{"36":1}}],["创建您的第一个插件",{"2":{"130":1}}],["创建插件包",{"2":{"101":1}}],["创建",{"2":{"36":1}}],["创建专业领域的定制化工具",{"2":{"9":1}}],["仓库",{"2":{"36":1}}],["qa",{"2":{"89":1}}],["qps",{"2":{"65":1}}],["q",{"2":{"64":2}}],["qq",{"2":{"35":1,"36":1}}],["quot",{"2":{"21":2,"48":2,"53":16,"56":2,"63":4,"71":2,"79":4,"82":2,"86":8,"89":6,"93":4,"100":4,"103":2,"116":2}}],["hierarchical",{"2":{"114":1}}],["hystrixcommand",{"2":{"102":1}}],["https",{"2":{"115":3}}],["httpstatus",{"2":{"38":1}}],["html",{"2":{"100":1}}],["human",{"2":{"83":1}}],["host",{"2":{"105":1}}],["how",{"2":{"67":1}}],["holddie",{"2":{"35":1,"36":1}}],["happy",{"2":{"130":1}}],["handleordercreated",{"2":{"61":1}}],["handler",{"2":{"43":2}}],["hashmap",{"2":{"52":1}}],["headers",{"2":{"115":1}}],["headers=self",{"2":{"115":1}}],["heroku",{"2":{"108":1}}],["here",{"2":{"18":1,"63":2}}],["heuristic",{"2":{"100":1}}],["hello",{"0":{"1":1},"1":{"4":1,"7":1,"11":1,"16":1,"21":1,"28":1,"35":1,"42":1}}],["联系方式",{"0":{"35":1}}],["安全边界也更牢靠",{"2":{"90":1}}],["安全中占据核心地位",{"2":{"67":1}}],["安全性",{"2":{"59":1}}],["安全治理",{"2":{"57":1}}],["安全",{"2":{"40":1,"41":1}}],["安全对齐",{"2":{"34":1}}],["安装依赖",{"2":{"18":1}}],["训练如此巨大的模型往往需要借助==分布式并行技术",{"2":{"124":1}}],["训练中若遇到",{"2":{"104":1}}],["训练中常见的问题如不稳定",{"2":{"66":1}}],["训练过程常出现不稳定甚至发散的问题",{"2":{"104":1}}],["训练时",{"2":{"103":1}}],["训练也需要更多算力",{"2":{"99":1}}],["训练模型的编码器读取这段被损坏的文本",{"2":{"93":1}}],["训练复杂度",{"2":{"90":1}}],["训练了奖励模型",{"2":{"83":1}}],["训练一个更精细的奖励模型",{"2":{"90":1}}],["训练一个",{"2":{"83":1}}],["训练奖励模型",{"2":{"83":1}}],["训练出一个奖励模型",{"2":{"82":1}}],["训练的目标就是使正确的下一个词概率被模型尽量提高",{"2":{"79":1}}],["训练它在每个位置上预测下一个词",{"2":{"79":1}}],["训练轮次也少",{"2":{"74":1}}],["训练集而不能泛化",{"2":{"66":1}}],["训练就是不断调整模型参数",{"2":{"66":1}}],["训练大型语言模型在本质上与训练一般的语言模型类似",{"2":{"66":1}}],["训练配置",{"2":{"57":1}}],["训练",{"0":{"66":1},"2":{"41":1,"53":1,"66":3,"96":1,"100":2,"103":1,"104":1,"107":1,"124":1}}],["训练流程",{"2":{"40":1}}],["训练微调",{"2":{"34":1}}],["训练与扩展",{"2":{"33":1}}],["bf16",{"2":{"104":1}}],["builder",{"2":{"102":1}}],["build",{"2":{"101":1,"102":1}}],["bufferedreader",{"2":{"39":1}}],["bdist",{"2":{"101":1}}],["b",{"2":{"83":1,"88":2,"90":1,"103":2,"104":1}}],["bigbird",{"2":{"114":1}}],["biglist",{"2":{"52":1}}],["bias",{"2":{"104":2,"120":1}}],["bidirectional",{"2":{"103":1}}],["bit",{"2":{"81":3}}],["backoff",{"2":{"126":2}}],["bart",{"2":{"86":1,"93":2,"99":2,"109":1}}],["base",{"2":{"75":1,"115":3}}],["batching",{"2":{"81":1}}],["batch",{"2":{"66":1,"74":1,"104":2,"107":2}}],["best",{"2":{"88":2,"90":2}}],["beam",{"2":{"73":1,"88":1}}],["bert是这一方法的代表性模型",{"2":{"86":1}}],["bert",{"0":{"103":1,"106":1},"2":{"63":2,"74":1,"86":1,"99":2,"103":11,"106":13,"109":2,"118":1}}],["bert与变体",{"2":{"40":1}}],["bert模型",{"2":{"34":1}}],["bpe",{"2":{"40":1}}],["bookscorpus",{"2":{"103":1}}],["boot",{"2":{"11":1}}],["bomb",{"2":{"67":1}}],["body",{"2":{"38":1}}],["blog",{"2":{"35":1}}],["无人工标签",{"2":{"109":1}}],["无服务器函数",{"2":{"108":1}}],["无需更聪明的模型",{"2":{"88":1}}],["无需人工标签",{"2":{"71":1}}],["无论是提问",{"2":{"87":1}}],["无一例外都经历了这些对齐过程",{"2":{"82":1}}],["无害",{"2":{"82":1}}],["无监督",{"0":{"53":1}}],["无监督预训练是指在训练过程中不需要人工标注的正确答案",{"2":{"53":1}}],["无监督预训练",{"2":{"34":1,"53":1}}],["无标注",{"2":{"40":1}}],["无法读取文件",{"2":{"39":1}}],["无梯度优化",{"2":{"33":1}}],["第二种可能成功",{"2":{"88":1}}],["第二张有缓存",{"2":{"81":1}}],["第二章讨论生成式的大型语言模型",{"2":{"41":1}}],["第一",{"2":{"124":1}}],["第一张无缓存",{"2":{"81":1}}],["第一个插件示例",{"0":{"23":1}}],["第",{"0":{"54":1,"57":1,"65":1},"1":{"64":1,"67":1,"72":1,"73":1,"75":1,"80":1,"81":1,"83":1,"87":1,"88":1,"90":1,"94":1,"96":1},"2":{"107":1,"120":2}}],["第5章",{"0":{"55":1},"1":{"65":1,"73":1,"81":1,"88":1,"94":1},"2":{"34":1,"65":1}}],["第4章",{"0":{"49":1},"1":{"57":1,"67":1,"75":1,"83":1,"90":1,"96":1},"2":{"34":1,"57":1}}],["第3章",{"0":{"47":1},"1":{"54":1,"64":1,"72":1,"80":1,"87":1},"2":{"34":1,"54":1}}],["第2章",{"0":{"41":1},"1":{"48":1,"56":1,"66":1,"74":1,"82":1,"89":1,"95":1,"100":1,"104":1,"107":1,"110":1,"112":1,"114":1,"116":1,"118":1,"120":1,"122":1,"124":1},"2":{"34":1,"41":1}}],["第1章",{"0":{"40":1},"1":{"46":1,"53":1,"63":1,"71":1,"79":1,"86":1,"93":1,"99":1,"103":1,"106":1,"109":1},"2":{"34":1,"40":1}}],["结合起来可以兼顾效率和全局视野",{"2":{"114":1}}],["结合前一句知道谈论的是法国巴黎",{"2":{"86":1}}],["结果性能超过了原本用同算力训练的",{"2":{"110":1}}],["结果",{"2":{"106":1,"120":1}}],["结果发现模型一样变得更听话了",{"2":{"90":1}}],["结果是模型变得更懂我们的需求和雷区",{"2":{"83":1}}],["结果是模型对用户要求更敏感",{"2":{"75":1}}],["结果小模型也学会了很多",{"2":{"75":1}}],["结果监督",{"2":{"33":1}}],["结构优化",{"2":{"81":1}}],["结构也更清晰",{"2":{"75":1}}],["结构模板",{"2":{"65":1}}],["结构化格式",{"2":{"64":1}}],["结构合规率",{"2":{"54":1}}],["结构",{"2":{"40":1,"104":1}}],["结构与共享",{"2":{"33":1}}],["结构与记忆技巧支持更长上下文",{"2":{"33":1}}],["头与层参数共享",{"2":{"33":1}}],["头与层共享以及稀疏路由",{"2":{"33":1}}],["外部记忆网络等",{"2":{"116":1}}],["外部记忆与检索",{"2":{"33":2}}],["外推",{"2":{"33":1}}],["旋转位置编码",{"2":{"120":1}}],["旋转位置",{"2":{"33":1}}],["去查询数据库",{"2":{"116":1}}],["去除偏置项",{"2":{"104":1}}],["去公园",{"2":{"93":2}}],["去帮助训练更强但未对齐的模型",{"2":{"75":1}}],["去郊游",{"2":{"64":1}}],["去nsp",{"2":{"40":1}}],["去毒",{"2":{"40":1}}],["去噪清洗",{"2":{"57":1}}],["去噪",{"2":{"33":1,"40":1}}],["去重",{"2":{"33":1,"40":2}}],["过了几个段落就忘记前面细节",{"2":{"116":1}}],["过度近似可能损失模型精度",{"2":{"114":1}}],["过多的切分会导致通信开销增大",{"2":{"107":1}}],["过多信息模型未必消化得完",{"2":{"88":1}}],["过长的提示既增加计算量也可能导致相关信息被淹没",{"2":{"80":1}}],["过高随机度下",{"2":{"73":1}}],["过程有据可循",{"2":{"90":1}}],["过程也清晰严谨",{"2":{"90":1}}],["过程也更令人信服",{"2":{"88":1}}],["过程拒绝",{"2":{"57":1}}],["过程奖励",{"2":{"57":1}}],["过程监督会针对每一步判断正误",{"2":{"90":1}}],["过程监督",{"2":{"33":3,"57":1,"90":2}}],["过优化",{"2":{"57":1}}],["过拟合防护",{"2":{"57":1}}],["过滤脏话",{"2":{"100":1}}],["过滤",{"2":{"33":1,"40":1}}],["到后来每天多跑",{"2":{"110":1}}],["到什么是好的回答",{"2":{"83":1}}],["到用已有模型协助生成数据",{"2":{"75":1}}],["到小数据也出效果",{"2":{"75":1}}],["到执行检索",{"2":{"72":1}}],["到",{"2":{"33":1,"110":1}}],["兆级",{"2":{"33":1}}],["处理长文档让",{"2":{"122":1}}],["处理长序列",{"2":{"114":1}}],["处理后",{"2":{"106":1}}],["处理响应结果",{"2":{"43":1}}],["处理用户输入",{"2":{"43":1}}],["处理",{"2":{"33":1,"40":1,"100":1}}],["处理特定格式的数据",{"2":{"9":1}}],["序列到序列重建",{"2":{"99":1}}],["序列到序列",{"2":{"33":1,"40":1}}],["片段重排",{"2":{"65":1}}],["片段还原",{"2":{"40":1}}],["片段掩码",{"2":{"33":1}}],["片段选择",{"2":{"33":1,"54":1}}],["编译优化",{"2":{"65":1}}],["编码",{"2":{"122":1}}],["编码理解",{"2":{"56":1}}],["编码器可以看作是阅读全文然后把文本变成某种内部理解表示的模型",{"2":{"86":1}}],["编码器解码器",{"2":{"33":1}}],["编码器",{"0":{"93":1},"2":{"33":1,"40":2,"93":3,"99":1,"109":1}}],["编解码器",{"2":{"40":1}}],["编辑式",{"2":{"33":1}}],["端到端总览",{"2":{"33":1}}],["目前都是在效率和效果间折中",{"2":{"122":1}}],["目前主流还是改进注意力为主",{"2":{"116":1}}],["目前许多开源模型通过量化在消费级",{"2":{"81":1}}],["目的是一个",{"2":{"122":1}}],["目的",{"2":{"33":1}}],["目标是最大化模型对训练语料的概率",{"2":{"66":1}}],["目标函数",{"2":{"65":1}}],["目标语言",{"2":{"64":1}}],["目标语言句子",{"2":{"53":1}}],["目标",{"2":{"33":1,"40":3,"41":1}}],["目标清楚输出可检查",{"2":{"33":1}}],["目标与能力",{"2":{"33":1}}],["软提示将提示搬进模型隐层",{"2":{"80":1}}],["软提示对人来说不可读",{"2":{"80":1}}],["软提示的好处是",{"2":{"80":1}}],["软提示不以文字呈现",{"2":{"80":1}}],["软提示则是一种隐藏的",{"2":{"80":1}}],["软提示",{"2":{"33":1,"41":1,"54":1,"80":3}}],["方法",{"2":{"33":5,"40":1,"72":1,"74":1,"82":1,"120":1}}],["方法名和变量名",{"2":{"32":1}}],["学到了细粒度的词语关系和句子理解",{"2":{"103":1}}],["学到了在各种指令下应该如何回答更符合人类期望",{"2":{"82":1}}],["学到通用语言知识",{"2":{"33":1}}],["学会了如何续写各种风格的文本",{"2":{"79":1}}],["学会用礼貌开头",{"2":{"75":1}}],["学会语言的一般规律和知识",{"2":{"46":1}}],["学会提示",{"2":{"33":1}}],["学习资源",{"0":{"129":1}}],["学习率",{"2":{"40":1,"74":1,"104":1}}],["学习提示是为了让提示更高效",{"2":{"80":1}}],["学习提示",{"0":{"80":1},"2":{"34":1,"54":1,"80":1}}],["学习人类喜欢的风格与边界",{"2":{"33":1}}],["的艺术",{"2":{"124":1}}],["的瓶颈在长距离依赖上依然存在",{"2":{"122":1}}],["的位置上",{"2":{"120":1}}],["的架构其实某种程度上可以看作多层块重复",{"2":{"118":1}}],["的轻量版",{"2":{"118":1}}],["的方式有效缓解了纯",{"2":{"116":1}}],["的方法是不训练奖励模型和用",{"2":{"90":1}}],["的方法",{"2":{"75":1}}],["的上下文",{"2":{"114":1}}],["的上下文上限约",{"2":{"112":1}}],["的序列",{"2":{"114":1}}],["的自注意力机制计算复杂度是o",{"2":{"114":1}}],["的缩放规律",{"2":{"110":1}}],["的缩写",{"2":{"83":1}}],["的预训练时代",{"2":{"106":1}}],["的应用都会经过微调阶段",{"2":{"106":1}}],["的应用中已经展现出威力",{"2":{"72":1}}],["的微调",{"2":{"106":1}}],["的最后一层我们会得到每个输入词的位置的向量表示",{"2":{"106":1}}],["的线性层中去掉",{"2":{"104":1}}],["的线性变换拆成两部分",{"2":{"104":1}}],["的平滑版",{"2":{"104":1}}],["的效果可能有限",{"2":{"103":1}}],["的续句",{"2":{"103":1}}],["的数据通常来自互联网的各个角落",{"2":{"100":1}}],["的事",{"2":{"96":1}}],["的基础上",{"2":{"96":1}}],["的基本概念",{"2":{"41":1}}],["的推理问题",{"2":{"94":1}}],["的一整套方法学",{"2":{"107":1}}],["的一些痛点",{"2":{"90":1}}],["的一种应用",{"2":{"80":1}}],["的质量",{"2":{"90":1}}],["的理念",{"2":{"90":1}}],["的奖励模型",{"2":{"90":1}}],["的研究也尝试让",{"2":{"90":1}}],["的技术",{"2":{"90":1}}],["的表现有显著提升",{"2":{"89":1}}],["的要领",{"2":{"89":1}}],["的威力",{"2":{"88":1}}],["的模型太大",{"2":{"107":1}}],["的模型形式",{"2":{"93":1}}],["的模型回答同样的问题",{"2":{"83":1}}],["的模型和一个经过",{"2":{"83":1}}],["的模型更可信和友好",{"2":{"82":1}}],["的参数",{"2":{"83":1}}],["的参数很多",{"2":{"74":1}}],["的解码器可以看作一个只能看见前文的模型",{"2":{"79":1}}],["的本领",{"2":{"75":1,"114":1}}],["的小模型",{"2":{"75":1}}],["的前身",{"2":{"75":1}}],["的指令数据集",{"2":{"75":1}}],["的能力",{"2":{"74":1}}],["的示例",{"2":{"74":1}}],["的词",{"2":{"103":1}}],["的词集合里选",{"2":{"73":1}}],["的词中随机选一个",{"2":{"73":1}}],["的语言能力和外部符号能力结合起来",{"2":{"72":1}}],["的例子来说明",{"2":{"67":1}}],["的例子训练模型",{"2":{"63":1}}],["的成功秘诀之一正是巨量的数据",{"2":{"66":1}}],["的挑战在于规模",{"2":{"66":1}}],["的所有词",{"2":{"66":1}}],["的回答质量",{"2":{"64":1}}],["的原则通常能提高模型输出质量",{"2":{"64":1}}],["的分工",{"2":{"56":1}}],["的仅解码器架构",{"2":{"56":1}}],["的大脑中会浮现出无数小说",{"2":{"48":1}}],["的概率分布",{"2":{"106":1}}],["的概率",{"2":{"48":1}}],["的概率被分解为",{"2":{"48":1}}],["的",{"2":{"41":1,"72":1,"79":1,"82":1,"88":2,"90":2,"93":2,"100":3,"110":1,"114":3,"116":1}}],["的构建原理和技术细节",{"2":{"41":1}}],["的权衡",{"2":{"33":1}}],["的天气",{"2":{"23":1}}],["把位置作为一个连续角度相位插入注意力计算",{"2":{"120":1}}],["把注意力用核技巧近似成线性点积",{"2":{"114":1}}],["把它代回原问题条件检验",{"2":{"88":1}}],["把解码的搜索空间和深度加大",{"2":{"88":1}}],["把相关资料拼到提示里",{"2":{"88":1}}],["把",{"2":{"82":1}}],["把模型的推理速度尽可能榨干硬件能力",{"2":{"81":1}}],["把用户常问的问题及对应答案存在数据库里",{"2":{"81":1}}],["把长提示带来的知识融入模型参数",{"2":{"80":1}}],["把结果并排展示",{"2":{"73":1}}],["把产生的键值对缓存下来",{"2":{"73":1}}],["把句子改成",{"2":{"53":1}}],["把证据拼入提示",{"2":{"33":1}}],["把线索记下来避免重复计算",{"2":{"33":1}}],["动态批尺寸",{"2":{"65":1}}],["动态调度",{"2":{"65":1}}],["动态分解",{"2":{"33":1,"54":1}}],["动作",{"2":{"33":1}}],["汇总答案",{"2":{"33":1}}],["步骤反馈",{"2":{"90":1}}],["步骤级别",{"2":{"90":1}}],["步骤级信号约束推理路径",{"2":{"33":1}}],["步骤标注",{"2":{"57":1}}],["步骤",{"2":{"33":3}}],["可拓展位置偏置",{"2":{"104":1}}],["可画两张对比",{"2":{"81":1}}],["可用词汇等",{"2":{"80":1}}],["可在解码时扣掉模型生成重复短语或不良词汇的概率",{"2":{"73":1}}],["可能更擅长长期推理",{"2":{"118":1}}],["可能变为",{"2":{"103":1}}],["可能导致模型输出有偏",{"2":{"100":1}}],["可能导致内容缺乏创意或重复",{"2":{"73":1}}],["可能引导",{"2":{"90":1}}],["可能尝试一遍链式思维",{"2":{"88":1}}],["可能回答",{"2":{"83":1}}],["可能被模型",{"2":{"83":1}}],["可能直接输出一段攻略",{"2":{"82":1}}],["可能输出事实性错误甚至胡编乱造",{"2":{"82":1}}],["可能一条回答要",{"2":{"81":1}}],["可能味道几乎一样",{"2":{"81":1}}],["可能会有一些额外开销",{"2":{"81":1}}],["可能仍然接近",{"2":{"81":1}}],["可能仍然选",{"2":{"73":1}}],["可能通过训练让模型学会",{"2":{"80":1}}],["可能首先链式思维列出可能疾病",{"2":{"72":1}}],["可能擅长生成内容",{"2":{"67":1}}],["可能给出一些通用建议如",{"2":{"64":1}}],["可读",{"2":{"65":1}}],["可视化建议",{"2":{"64":1,"72":1,"73":1,"80":1,"81":1,"88":1,"90":1}}],["可见",{"2":{"64":1,"89":1}}],["可组合性",{"2":{"59":1}}],["可以看作长序列建模的成功示范",{"2":{"122":1}}],["可以自然扩展长度",{"2":{"120":1}}],["可以无限重复应用已学到的模式来处理任意长输入",{"2":{"118":1}}],["可以边读边在笔记本上记下各章要点",{"2":{"116":1}}],["可以预见",{"2":{"114":1}}],["可以让最终效果最大化",{"2":{"110":1}}],["可以让模型在每一步生成后调用另一个过程来审核这一步是否合理",{"2":{"88":1}}],["可以让模型将复杂问题拆解为一系列简单的步骤",{"2":{"72":1}}],["可以兼顾学习语义理解和语言生成",{"2":{"99":1}}],["可以通过逐步提示的方式",{"2":{"89":1}}],["可以通过训练让模型",{"2":{"80":1}}],["可以准备一张对比图表",{"2":{"88":1}}],["可以用一个已初步对齐的模型产生大量问题和多种回答",{"2":{"90":1}}],["可以用决策树形式",{"2":{"88":1}}],["可以用成对的对话数据",{"2":{"74":1}}],["可以理解为模型带有",{"2":{"88":1}}],["可以理解为教模型",{"2":{"82":1}}],["可以显著缩短模型响应时间",{"2":{"81":1}}],["可以线性缩短推理时间",{"2":{"81":1}}],["可以使用算法自动压缩提示内容",{"2":{"80":1}}],["可以反复使用",{"2":{"80":1}}],["可以随机试",{"2":{"80":1}}],["可以人工标注",{"2":{"75":1}}],["可以设计一个解码树形图",{"2":{"73":1}}],["可以说",{"2":{"73":1,"100":1}}],["可以提示模型再检查",{"2":{"88":1}}],["可以提示模型将复杂问题拆解",{"2":{"72":1}}],["可以提供示例作为提示的一部分",{"2":{"63":1}}],["可以绘制一张",{"2":{"64":1}}],["可以有效地构建提示内容",{"2":{"64":1}}],["可以在提示中说明",{"2":{"89":1}}],["可以在提示中示范",{"2":{"89":1}}],["可以在提示里注明源语言",{"2":{"64":1}}],["可以在机器翻译的平行语料",{"2":{"53":1}}],["可以暗示模型进行问答任务",{"2":{"64":1}}],["可以这样写模板",{"2":{"64":1}}],["可以把更长的诗也定位进去",{"2":{"120":1}}],["可以把输入第",{"2":{"120":1}}],["可以把缩放看作跑步训练的经验法则",{"2":{"110":1}}],["可以把训练",{"2":{"107":1}}],["可以把矩阵按列块或行块分到多",{"2":{"107":1}}],["可以把它想象成模型脑海里的",{"2":{"80":1}}],["可以把提示想象成对模型下指令的方式",{"2":{"64":1}}],["可以把",{"2":{"48":1,"88":1}}],["可规模",{"2":{"40":1}}],["可选",{"2":{"36":1}}],["可解释",{"2":{"33":1}}],["可维护的分布式系统",{"2":{"14":1}}],["在给",{"2":{"120":1}}],["在给出答案前",{"2":{"88":1}}],["在逐字生成时",{"2":{"116":1}}],["在生成场景下",{"2":{"116":1}}],["在生成文本时",{"2":{"79":1}}],["在对数尺度下",{"2":{"110":1}}],["在不改模型参数的情况下让模型按照要求输出",{"2":{"109":1}}],["在单台机器",{"2":{"107":1}}],["在单纯的解码器架构基础上",{"2":{"99":1}}],["在输入序列开头引入一个特殊标记",{"2":{"106":1}}],["在输入后加上",{"2":{"63":1}}],["在位置嵌入上做了修改",{"2":{"104":1}}],["在每个子层内部先",{"2":{"104":1}}],["在每个句子中随机选择",{"2":{"103":1}}],["在每一步扩展这些候选",{"2":{"73":1}}],["在伦理上未雨绸缪",{"2":{"96":1}}],["在必要时让模型",{"2":{"94":1}}],["在本章中",{"2":{"94":1}}],["在数据需求",{"2":{"90":1}}],["在某些任务上",{"2":{"90":1}}],["在某个专门领域的数据上继续训练",{"2":{"74":1}}],["在强化学习时有更正确的",{"2":{"90":1}}],["在推理时用记忆缓存",{"2":{"122":1}}],["在推理时理论上可以不断迭代处理延长的序列",{"2":{"118":1}}],["在推理时根据当前问题检索文档",{"2":{"88":1}}],["在推理时给模型提供更多有帮助的上下文信息",{"2":{"88":1}}],["在提示里加入相关数学定理或例题作为参考",{"2":{"88":1}}],["在提示里加入示例",{"2":{"88":1}}],["在提示方法中",{"2":{"63":1}}],["在后面的第四章中还有更深入的对齐方法讨论",{"2":{"82":1}}],["在后续生成时不用每次都重新处理整个输入",{"2":{"73":1}}],["在回答中更加有益",{"2":{"82":1}}],["在保证输出一致的前提下",{"2":{"81":1}}],["在保守与创意之间调节",{"2":{"33":1}}],["在一个实际对话系统中",{"2":{"81":1}}],["在一句话中遮住某些单词",{"2":{"53":1}}],["在资源有限的情况下",{"2":{"80":1}}],["在资源有限情况下",{"2":{"75":1}}],["在这个过程中",{"2":{"80":1}}],["在训练中用了",{"2":{"122":1}}],["在训练时对每个序列中的位置都会形成某种位置表示",{"2":{"120":1}}],["在训练",{"2":{"75":1,"82":1,"107":1}}],["在指令对齐中",{"2":{"75":1}}],["在预训练时已经学会了",{"2":{"106":1}}],["在预训练时",{"2":{"99":1}}],["在预训练阶段",{"2":{"93":1}}],["在预训练后已经具备处理语言的通用能力",{"2":{"74":1}}],["在预填充阶段",{"2":{"73":1}}],["在解码过程中",{"2":{"73":1}}],["在解码阶段",{"2":{"73":1}}],["在技术上通常把这个过程划分为两个阶段",{"2":{"73":1}}],["在什么情况下",{"2":{"72":1}}],["在日常生活中",{"2":{"67":1}}],["在医疗咨询场景下",{"2":{"67":1}}],["在大语言模型领域指的是让模型的行为符合人类的期望",{"2":{"67":1}}],["在大语言模型",{"2":{"64":1}}],["在实践中",{"2":{"80":1}}],["在实践中我们鼓励多尝试",{"2":{"64":1}}],["在实现上",{"2":{"56":1,"107":1}}],["在实际应用中",{"2":{"48":1,"87":1}}],["在自然语言处理",{"2":{"46":1}}],["在",{"2":{"36":1,"48":3,"63":1,"67":2,"72":1,"83":1,"93":1,"96":1,"103":1,"106":1}}],["在上下文中学习任务",{"2":{"33":1}}],["通俗地讲",{"2":{"88":1}}],["通俗来说",{"2":{"79":1}}],["通才智能",{"2":{"48":1}}],["通常是固定且有限的",{"2":{"112":1}}],["通常结合流水线技术",{"2":{"107":1}}],["通常",{"2":{"106":1}}],["通常分三步",{"2":{"83":1}}],["通常需要用填充",{"2":{"81":1}}],["通常通过在训练过程中学习一段额外参数来实现",{"2":{"80":1}}],["通常仍使用梯度下降",{"2":{"74":1}}],["通常采用随机梯度下降",{"2":{"66":1}}],["通常采用仅解码器的",{"2":{"48":1}}],["通常指我们提供给模型的输入文本",{"2":{"64":1}}],["通常指参数规模极大",{"2":{"48":1}}],["通常在特定任务上性能更高",{"2":{"63":1}}],["通识知识",{"2":{"46":1}}],["通过有监督微调和",{"2":{"124":1}}],["通过最大化训练语料的概率",{"2":{"124":1}}],["通过稀疏地看或粗略地看",{"2":{"114":1}}],["通过学习这个任务",{"2":{"103":1}}],["通过后期的微调和提示工程",{"2":{"99":1}}],["通过将损坏文本恢复来训练",{"2":{"99":1}}],["通过在推理阶段投入更多计算和策略",{"2":{"94":1}}],["通过这种递归",{"2":{"116":1}}],["通过这种方式",{"2":{"79":1,"103":1}}],["通过这些多样化的自监督任务",{"2":{"93":1}}],["通过无数这样的解谜",{"2":{"93":1}}],["通过无数次这样的练习",{"2":{"86":1}}],["通过重排序或筛选",{"2":{"90":1}}],["通过不断试验和改进提示",{"2":{"89":1}}],["通过不断地猜测并根据真实下文调整参数",{"2":{"79":1}}],["通过集成我们也许能拼出一个完整正确的答案",{"2":{"88":1}}],["通过巧妙地利用推理步骤",{"2":{"88":1}}],["通过本章学习",{"2":{"87":1}}],["通过类似的过程学习",{"2":{"86":1}}],["通过横向扩展硬件",{"2":{"81":1}}],["通过收集大量",{"2":{"74":1}}],["通过调整解码算法",{"2":{"73":1}}],["通过提示",{"2":{"72":1}}],["通过提示来引导模型完成任务",{"2":{"63":1}}],["通过显式要求模型",{"2":{"72":1}}],["通过对齐训练学会了礼貌用语和中立表述",{"2":{"67":1}}],["通过奖励和引导让它成为一只",{"2":{"67":1}}],["通过喂给它海量的",{"2":{"66":1}}],["通过模板和结构化方法",{"2":{"64":1}}],["通过特定格式组织提示内容",{"2":{"64":1}}],["通过预训练",{"2":{"46":1,"86":1}}],["通过插件",{"2":{"9":1}}],["通用提示设计",{"0":{"64":1},"2":{"34":1}}],["通用设计",{"2":{"33":1,"54":1}}],["从简单的工具函数开始",{"2":{"130":1}}],["从原来的",{"2":{"120":1}}],["从",{"2":{"110":2}}],["从数据自身生成训练信号",{"2":{"109":1}}],["从指令微调到人类反馈强化学习",{"2":{"96":1}}],["从缓存",{"2":{"94":1}}],["从中选出最符合人类偏好的那个作为最终答复",{"2":{"90":1}}],["从普通单线推理对比到多分支推理",{"2":{"88":1}}],["从人类反馈中进行强化学习",{"2":{"83":1}}],["从人类反馈中学习",{"2":{"82":1}}],["从候选集中搜索出对特定任务效果最好的提示",{"2":{"80":1}}],["从前有座山",{"2":{"79":1}}],["从前有一个国王",{"2":{"48":1}}],["从开头开始一个词接一个词地往后写",{"2":{"79":1}}],["从获取数据",{"2":{"75":1}}],["从而模型可以推理出更长位置的表示",{"2":{"120":1}}],["从而持久",{"2":{"118":1}}],["从而把参数量大幅减少",{"2":{"118":1}}],["从而在理论上做到线性复杂度的近似注意力",{"2":{"114":1}}],["从而在不大量人类标注的情况下做出了高质量对齐模型",{"2":{"90":1}}],["从而分类器能学会分辨",{"2":{"106":1}}],["从而塑造出见多识广的",{"2":{"100":1}}],["从而训练这种架构",{"2":{"93":1}}],["从而得到伪偏好标签",{"2":{"90":1}}],["从而提高准确性",{"2":{"89":1}}],["从而提高准确性和逻辑性",{"2":{"72":1}}],["从而减轻人工负担并提升交互效率",{"2":{"87":1}}],["从而大幅提升了回答质量和安全性",{"2":{"83":1}}],["从而节省上下文空间",{"2":{"80":1}}],["从而解决原任务",{"2":{"72":1}}],["从而学到一般化的能力",{"2":{"66":1}}],["从而获得监督信号",{"2":{"53":1}}],["从而产生连贯的输出",{"2":{"48":1}}],["从概念上",{"2":{"48":1}}],["从基础到应用",{"2":{"33":1}}],["从会用到用好",{"2":{"33":1}}],["从anthropic获取您的api密钥",{"2":{"18":1}}],["稳定训练",{"2":{"104":1}}],["稳定训练与高效结构避免发散",{"2":{"33":1}}],["稳定指标",{"2":{"54":1}}],["稳定",{"2":{"40":2,"65":1}}],["稳定性好",{"2":{"90":1}}],["稳定性",{"2":{"33":1}}],["混合并行",{"2":{"107":1}}],["混合精度训练",{"2":{"104":1}}],["混合精度",{"2":{"40":1,"41":1,"65":1}}],["混合",{"2":{"33":2}}],["混合策略",{"2":{"33":1}}],["滑动窗口",{"2":{"65":1}}],["滑动",{"2":{"33":1}}],["固定",{"2":{"33":1}}],["单元测试",{"0":{"119":1}}],["单",{"2":{"107":1}}],["单个人",{"2":{"107":1}}],["单卡内存常不足以装下",{"2":{"107":1}}],["单词顺序被打乱",{"2":{"93":1}}],["单块",{"2":{"81":1}}],["单例模式",{"0":{"78":1}}],["单位token",{"2":{"65":1}}],["单位成本",{"2":{"33":1}}],["单一职责",{"2":{"59":1}}],["单一职责原则",{"0":{"24":1}}],["吞吐",{"2":{"33":1,"41":1,"65":1}}],["以分工捕捉不同关系",{"2":{"118":1}}],["以符合更优配比",{"2":{"110":1}}],["以加速训练和突破单机内存限制",{"2":{"107":1}}],["以确保如此大规模的模型依然可训练",{"2":{"104":1}}],["以确保输出不违背设定的要求",{"2":{"73":1}}],["以此增加训练数据",{"2":{"90":1}}],["以进一步完善对齐效果或降低成本",{"2":{"90":1}}],["以进一步提高模型性能",{"2":{"88":1}}],["以量化展示推理扩展的效果",{"2":{"88":1}}],["以解决一个复杂问题为例",{"2":{"88":1}}],["以减少错误",{"2":{"88":1}}],["以后弱模型回答类似问题就不需要完整的上下文了",{"2":{"80":1}}],["以后只需很简短的指令就能触发复杂行为",{"2":{"80":1}}],["以防止模型性能下降或发生灾难性遗忘",{"2":{"74":1}}],["以提升它在该领域的表现",{"2":{"74":1}}],["以下是主要的高效推理策略",{"2":{"81":1}}],["以下是几种常用的进阶提示方法",{"2":{"72":1}}],["以下是一些优秀的技术博客",{"2":{"5":1}}],["以",{"2":{"64":1,"79":1,"93":1,"100":1}}],["以及著名的缩放定律",{"2":{"95":1}}],["以及利用推理阶段技巧提升输出品质",{"2":{"90":1}}],["以及我们希望模型遵循的格式等",{"2":{"89":1}}],["以及自行检查纠错",{"2":{"88":1}}],["以及",{"2":{"88":1}}],["以及调用外部知识或多模型协作",{"2":{"87":1}}],["以及提示长度的缩减",{"2":{"80":1}}],["以及提示的作用",{"2":{"41":1}}],["以及理想的回答",{"2":{"75":1}}],["以及符合人类价值观",{"2":{"67":1}}],["以及正确的初始化防止梯度消失或爆炸等",{"2":{"66":1}}],["以及解决长文本序列处理的方案",{"2":{"41":1}}],["以终为始按场景调参",{"2":{"33":1}}],["漂移要有对策",{"2":{"33":1}}],["越界",{"2":{"33":1,"41":1}}],["幻觉",{"2":{"33":1,"41":1,"54":1}}],["闭环看效果与持续优化",{"2":{"33":1}}],["离线与在线",{"2":{"33":1}}],["观测与评估",{"2":{"33":1}}],["聊天",{"2":{"33":1}}],["看见",{"2":{"116":1}}],["看哪个短语能让鹦鹉正确回应",{"2":{"80":1}}],["看到指令",{"2":{"75":1}}],["看电影",{"2":{"64":1}}],["看看模型给出的回答哪种更符合预期",{"2":{"64":1}}],["看它输出",{"2":{"63":1}}],["看输出好不好快不快贵不贵",{"2":{"33":1}}],["看懂上下文并连贯续写",{"2":{"33":1}}],["成功扩展到",{"2":{"114":1}}],["成为现实的幕后功臣",{"2":{"107":1}}],["成对比较",{"2":{"57":1}}],["成对的源语言",{"2":{"53":1}}],["成本指标",{"2":{"54":1}}],["成本质量延迟平衡",{"2":{"33":1}}],["成本",{"2":{"33":1,"41":1,"65":2}}],["成长感悟",{"2":{"21":1}}],["质量控制",{"2":{"100":1}}],["质量好的数据对最后效果很重要",{"2":{"75":1}}],["质量审校",{"2":{"57":1}}],["质量指标",{"2":{"54":1}}],["质量",{"2":{"33":3,"41":1,"65":1}}],["搜索引擎",{"2":{"116":1}}],["搜索引擎友好",{"2":{"29":1}}],["搜索策略",{"2":{"80":1}}],["搜索扩展会显著增加计算量",{"2":{"88":1}}],["搜索扩展",{"2":{"65":1,"88":2}}],["搜索式",{"2":{"33":1}}],["搜索更好问法向量前缀缩短上下文",{"2":{"33":1}}],["搜索",{"2":{"33":1}}],["量化版本部署在多",{"2":{"81":1}}],["量化剪枝让模型精简",{"2":{"81":1}}],["量化可以极大降低模型内存占用和计算量",{"2":{"81":1}}],["量化就好比用简略版菜谱做披萨",{"2":{"81":1}}],["量化和剪枝",{"2":{"81":1}}],["量化掉质",{"2":{"65":1}}],["量化",{"2":{"33":1,"65":1,"81":3,"94":1}}],["温度和",{"2":{"73":1}}],["温度很高相当于每次基本骰子决定下个词",{"2":{"73":1}}],["温度=0",{"2":{"73":1}}],["温度低",{"2":{"73":1}}],["温度高",{"2":{"73":1}}],["温度与权重",{"2":{"57":1}}],["温度按场景取舍",{"2":{"33":1}}],["温度",{"2":{"33":1,"40":1,"41":1,"65":1}}],["温度25°c",{"2":{"23":1}}],["束宽",{"2":{"88":1}}],["束宽选择",{"2":{"65":1}}],["束搜索是几条平行前进",{"2":{"73":1}}],["束搜索会比较这些完整句子的总概率",{"2":{"73":1}}],["束搜索更全面探索",{"2":{"73":1}}],["束搜索倾向于收敛在相似的高概率套路上",{"2":{"73":1}}],["束搜索在翻译等任务中常用",{"2":{"73":1}}],["束搜索",{"2":{"41":1,"65":1,"73":1}}],["束",{"2":{"33":2}}],["贪婪搜索快但保守",{"2":{"73":1}}],["贪婪搜索",{"2":{"73":1}}],["贪婪",{"2":{"33":2,"41":1,"65":1}}],["预估容量避免扩容",{"2":{"52":1}}],["预归一",{"2":{"40":1}}],["预热",{"2":{"40":1,"41":1}}],["预训练赋予模型广博知识",{"2":{"109":1}}],["预训练+微调",{"2":{"109":1}}],["预训练范式包括无监督",{"2":{"109":1}}],["预训练通过海量数据的自监督任务",{"2":{"109":1}}],["预训练打底",{"2":{"106":1}}],["预训练提供泛化的语言表示",{"2":{"106":1}}],["预训练阶段",{"2":{"106":1}}],["预训练任务因模型架构而异",{"2":{"109":1}}],["预训练任务包括掩码语言模型和下一句预测",{"2":{"103":1}}],["预训练任务的比较",{"0":{"99":1}}],["预训练后本身就能独立生成连贯文本",{"2":{"99":1}}],["预训练时",{"2":{"79":1}}],["预训练的另一任务",{"2":{"103":1}}],["预训练的语言模型虽然能生成流畅文本",{"2":{"82":1}}],["预训练的",{"2":{"75":1}}],["预训练让它学会很多本领",{"2":{"67":1}}],["预训练模型是一个已经写好的函数",{"2":{"63":1}}],["预训练模型提供了通用能力",{"2":{"63":1}}],["预训练模型好比一个阅读了百科全书的大脑",{"2":{"46":1}}],["预训练完模型后",{"2":{"63":1}}],["预训练指的是先用海量的文本数据训练一个通用的模型",{"2":{"46":1}}],["预训练",{"0":{"40":1,"46":1},"1":{"46":1,"53":2,"63":2,"71":1,"79":1,"86":1,"93":1,"99":1,"103":1,"106":1,"109":1},"2":{"34":1,"40":1,"106":1}}],["预训练基座",{"2":{"33":1}}],["预测下一个",{"2":{"33":1}}],["预测下一个词打底能力",{"2":{"33":1}}],["预填充相当于",{"2":{"73":1}}],["预填充解耦",{"2":{"65":1}}],["预填充解码",{"2":{"34":1}}],["预填充算力受限",{"2":{"65":1}}],["预填充",{"2":{"33":1,"65":1,"73":2}}],["预填充建",{"2":{"33":1}}],["预填充与解码",{"0":{"73":1},"2":{"33":1}}],["不必穷举每个方法的公式细节",{"2":{"122":1}}],["不如让模型学会根据相对距离来判断相关性",{"2":{"120":1}}],["不是天然循环的",{"2":{"118":1}}],["不支持的服务",{"2":{"115":1}}],["不妨尝试调小学习率",{"2":{"104":1}}],["不妨反思一下提示是否清楚具体",{"2":{"89":1}}],["不希望模型模仿",{"2":{"100":1}}],["不那么生硬了",{"2":{"90":1}}],["不需要复杂的在线训练",{"2":{"90":1}}],["不需要反复试采样调整",{"2":{"90":1}}],["不需要再把你的长问题过一遍",{"2":{"81":1}}],["不可能无限塞入信息",{"2":{"88":1}}],["不满意的就惩罚",{"2":{"83":1}}],["不当",{"2":{"82":1}}],["不用扩展",{"2":{"88":1}}],["不用明确编写规则",{"2":{"83":1}}],["不用每次都现做",{"2":{"81":1}}],["不用改模型参数",{"2":{"80":1}}],["不会遗漏关键信息",{"2":{"116":1}}],["不会仅为了正确答案忽略逻辑错误",{"2":{"90":1}}],["不会直接呈现给用户",{"2":{"88":1}}],["不会占用很长的上下文窗口",{"2":{"80":1}}],["不会刻意遮盖任何词",{"2":{"53":1}}],["不能同时工作",{"2":{"107":1}}],["不能直接用于实际",{"2":{"103":1}}],["不能窥视后面的未生成单词",{"2":{"79":1}}],["不能看见后面的词",{"2":{"56":1}}],["不过如果直接重复可能混淆",{"2":{"120":1}}],["不过主要挑战是外推",{"2":{"120":1}}],["不过实践中会受限于位置编码等",{"2":{"118":1}}],["不过一般",{"2":{"118":1}}],["不过纯模型并行的瓶颈在于通信",{"2":{"107":1}}],["不过预训练完的",{"2":{"103":1}}],["不过值得一提",{"2":{"103":1}}],["不过这类方法训练复杂且效果不稳定",{"2":{"116":1}}],["不过这些模型不能直接生成新句子",{"2":{"99":1}}],["不过这次使用的是针对某个下游任务的标注数据",{"2":{"63":1}}],["不过受限于上下文长度",{"2":{"88":1}}],["不过对",{"2":{"81":1}}],["不过也可以预先用一些人工构造的规则数据进行有监督微调",{"2":{"74":1}}],["不断缩短优化",{"2":{"80":1}}],["不断预测下一个可能的词",{"2":{"73":1}}],["不断调整",{"2":{"64":1}}],["不同层可以专注不同抽象级别特征",{"2":{"118":1}}],["不同层同时处理不同",{"2":{"81":1}}],["不同部分放在不同",{"2":{"107":1}}],["不同预训练范式的界限变得模糊",{"2":{"99":1}}],["不同次生成的答案可能各说一部分对",{"2":{"88":1}}],["不同策略影响了创造性",{"2":{"73":1}}],["不同算法就是不同的",{"2":{"73":1}}],["不同的提示或不同的模型可能产生不同答案",{"2":{"72":1}}],["不同顺序的信息",{"2":{"64":1}}],["不仅要教会它技能",{"2":{"96":1}}],["不仅要模型聪明",{"2":{"81":1}}],["不仅仅是模型本身够强",{"2":{"94":1}}],["不仅因为模型更大更聪明",{"2":{"67":1}}],["不仅能编故事",{"2":{"48":1}}],["不要产生歧视言论",{"2":{"67":1}}],["不乱叫",{"2":{"67":1}}],["不乱咬人",{"2":{"67":1}}],["不准确或不适当的内容",{"2":{"67":1}}],["不经过额外训练",{"2":{"63":1}}],["不去偷看还没写的结局",{"2":{"56":1}}],["不看未来",{"2":{"41":1}}],["不改模型也能更强",{"2":{"33":1}}],["不只看结果对也看步骤对",{"2":{"33":1}}],["不训练奖励模型也能学偏好",{"2":{"33":1}}],["喂标准问答学会听指令",{"2":{"33":1}}],["先分章节看",{"2":{"114":1}}],["先处理小块得到摘要",{"2":{"114":1}}],["先同步算部分张量",{"2":{"107":1}}],["先采用数据并行把数据分到",{"2":{"107":1}}],["先小",{"2":{"104":1}}],["先由人类比较模型的两段回答孰优",{"2":{"82":1}}],["先准备很多模型回答的备选",{"2":{"82":1}}],["先用监督微调",{"2":{"74":1}}],["先读懂输入再逐步写出回答",{"2":{"73":1}}],["先读后写",{"2":{"56":1}}],["先读后写的两阶段流程",{"2":{"33":1}}],["先让它决定用何种工具获取中间结果",{"2":{"72":1}}],["先让模型给出初步回答",{"2":{"72":1}}],["先在大型翻译语料上训练",{"2":{"53":1}}],["先检索或调用工具",{"2":{"33":1}}],["先检索或先计算再生成",{"2":{"33":1}}],["先答后审多次生成投票",{"2":{"33":1}}],["先把任务和输出说清楚",{"2":{"33":1}}],["先想步骤再给结论",{"2":{"33":1}}],["模板泛化",{"2":{"57":1}}],["模板",{"2":{"33":1,"41":1}}],["模板化",{"2":{"33":1}}],["模板角色格式",{"2":{"33":1}}],["模型逐渐学会语言规律",{"2":{"124":1}}],["模型逐渐学会模式",{"2":{"66":1}}],["模型一次也难以全部处理",{"2":{"116":1}}],["模型仍可以捕获局部依赖",{"2":{"114":1}}],["模型有一个固有限制",{"2":{"112":1}}],["模型有时会在回答中使用不礼貌或偏激的语言",{"2":{"67":1}}],["模型不断扩大规模",{"2":{"110":1}}],["模型不对齐可能带来哪些风险和后果",{"2":{"67":1}}],["模型自行找规律",{"2":{"109":1}}],["模型自我验证的可靠性如何",{"2":{"88":1}}],["模型时",{"2":{"107":1}}],["模型时代",{"2":{"106":1}}],["模型参数的最后几层",{"2":{"106":1}}],["模型参数规模和计算规模",{"2":{"95":1}}],["模型做情感分类",{"2":{"106":1}}],["模型修改",{"0":{"104":1}}],["模型已经对语言有了相当深入的理解",{"2":{"103":1}}],["模型要填回",{"2":{"103":1}}],["模型生成的是基于训练文本概括出的类似内容",{"2":{"100":1}}],["模型训练就是让",{"2":{"100":1}}],["模型据称使用了",{"2":{"100":1}}],["模型结构修改",{"2":{"95":1}}],["模型解码器需要还原出诸如",{"2":{"93":1}}],["模型必须理解这些词的关系",{"2":{"93":1}}],["模型开始学会更自然地道歉和感谢",{"2":{"90":1}}],["模型开始一个字",{"2":{"73":1}}],["模型也许给出一个模板化的道歉信",{"2":{"89":1}}],["模型也许会尝试一些不一样的词",{"2":{"73":1}}],["模型也会倾向于遵循",{"2":{"89":1}}],["模型善于模仿提示中的模式",{"2":{"89":1}}],["模型并行",{"2":{"107":2,"124":1}}],["模型并行将模型不同层分给不同",{"2":{"81":1}}],["模型并不知道你心中的具体意图",{"2":{"89":1}}],["模型先想出一个方案",{"2":{"88":1}}],["模型先读完输入",{"2":{"73":1}}],["模型可以学到段间如何衔接",{"2":{"120":1}}],["模型可以学习哪些信息需要存",{"2":{"116":1}}],["模型可以跨",{"2":{"116":1}}],["模型可以借助这些信息完成原本单靠内部知识难以完成的任务",{"2":{"88":1}}],["模型可能确实能一字不差背出来",{"2":{"100":1}}],["模型可能接着输出",{"2":{"73":1}}],["模型可能立即给出结果",{"2":{"72":1}}],["模型可能只",{"2":{"66":1}}],["模型采用的就是这种策略",{"2":{"93":1}}],["模型采用",{"2":{"86":1}}],["模型习惯了看到",{"2":{"86":1}}],["模型需要双向地考虑上下文",{"2":{"86":1}}],["模型需要充分利用句子中其他未被遮盖的词来推断答案",{"2":{"86":1}}],["模型需要自己续写后面的词",{"2":{"79":1}}],["模型该如何对齐",{"2":{"83":1}}],["模型该如何抉择",{"2":{"75":1}}],["模型因此学会了拒绝技巧",{"2":{"83":1}}],["模型大概率回复拒绝语",{"2":{"83":1}}],["模型为了得到高分",{"2":{"83":1}}],["模型倾向于给出积极温馨",{"2":{"83":1}}],["模型调整策略以赢得高分",{"2":{"83":1}}],["模型尝试不同回答风格",{"2":{"83":1}}],["模型从",{"2":{"110":1}}],["模型从一个冷冰冰的概率机器",{"2":{"82":1}}],["模型从海量未标注文本中学习模式和结构",{"2":{"53":1}}],["模型只有成功",{"2":{"93":1}}],["模型只有在实际交互中暴露问题后",{"2":{"82":1}}],["模型只处理增量部分",{"2":{"81":1}}],["模型预训练语料里可能含有偏见",{"2":{"82":1}}],["模型预测正面",{"2":{"106":1}}],["模型预测下一个词的概率分布",{"2":{"73":1}}],["模型预测后可以直接与原句比对对错",{"2":{"53":1}}],["模型给出准确易懂的解释",{"2":{"82":1}}],["模型就能处理",{"2":{"120":1}}],["模型就无能为力",{"2":{"112":1}}],["模型就像学生一样",{"2":{"86":1}}],["模型就学到偏差偏好",{"2":{"83":1}}],["模型就真的讲一个无攻击性的笑话",{"2":{"82":1}}],["模型就会把",{"2":{"75":1}}],["模型每次处理整段文本",{"2":{"81":1}}],["模型记住了背景的计算结果",{"2":{"81":1}}],["模型用",{"2":{"81":1}}],["模型用这种填空游戏不断训练",{"2":{"53":1}}],["模型剪枝则是删除不重要的权重或神经元",{"2":{"81":1}}],["模型回答第一句时已经处理过这段话",{"2":{"81":1}}],["模型在这个反复试错中学会了迎合人类的口味",{"2":{"83":1}}],["模型在大约",{"2":{"81":1}}],["模型在生成时会不断用到之前的计算结果",{"2":{"81":1}}],["模型在解码中会主动避开不当内容",{"2":{"73":1}}],["模型内部向量",{"2":{"80":1}}],["模型内部使用的提示表示",{"2":{"80":1}}],["模型执行",{"2":{"80":1}}],["模型响应也又快又好",{"2":{"80":1}}],["模型被迫真正",{"2":{"79":1}}],["模型提示",{"2":{"79":1}}],["模型学会了写故事的能力",{"2":{"79":1}}],["模型学会遵循指令后",{"2":{"75":1}}],["模型的性能",{"2":{"110":1}}],["模型的编码能力和生成能力都得到提高",{"2":{"93":1}}],["模型的",{"2":{"86":1}}],["模型的预训练",{"2":{"86":1}}],["模型的预测能力不断提高",{"2":{"66":1}}],["模型的输入窗口是有限的",{"2":{"80":1}}],["模型的变化就很明显",{"2":{"75":1}}],["模型表现出了惊人的指令遵循能力",{"2":{"75":1}}],["模型看过很多问句",{"2":{"75":1}}],["模型甚至可能说出",{"2":{"73":1}}],["模型输出的是一个概率分布",{"2":{"79":1}}],["模型输出和高温度相比有何明显区别",{"2":{"73":1}}],["模型输出更确定趋于贪婪",{"2":{"73":1}}],["模型输出概率分布",{"2":{"63":1}}],["模型对",{"2":{"114":1}}],["模型对输入序列做一次前向计算",{"2":{"73":1}}],["模型对长距离依赖的建模能力越强",{"2":{"56":1}}],["模型会学习到根据上下文",{"2":{"86":1}}],["模型会变得富有同理心",{"2":{"83":1}}],["模型会明显更符合人类喜好",{"2":{"83":1}}],["模型会逐渐掌握语言结构",{"2":{"79":1}}],["模型会自我优化",{"2":{"72":1}}],["模型会对自己的翻译进行反馈调整",{"2":{"72":1}}],["模型会先分别列出爱因斯坦和牛顿的主要贡献",{"2":{"72":1}}],["模型会先算",{"2":{"72":1}}],["模型中",{"2":{"72":1}}],["模型越大",{"2":{"110":1}}],["模型越强大",{"2":{"67":1}}],["模型越可能学会细致复杂的语言现象",{"2":{"48":1}}],["模型相当于从提示里的示例中即时学习如何完成任务",{"2":{"63":1}}],["模型本身的参数不变",{"2":{"63":1}}],["模型后",{"2":{"63":1}}],["模型通过内存单元查看记忆向量",{"2":{"116":1}}],["模型通过模仿这些高质量回应",{"2":{"82":1}}],["模型通过统计词在上下文中共同出现的频率来学习词语的向量表示",{"2":{"53":1}}],["模型通过阅读大量",{"2":{"46":1}}],["模型规模超过某个阈值后",{"2":{"48":1}}],["模型",{"0":{"46":1,"103":1,"106":1},"1":{"53":1,"63":1},"2":{"33":1,"63":1,"75":1,"80":1,"89":1,"93":1,"104":1,"110":1,"118":1}}],["模型与分布式",{"2":{"33":1}}],["模型与数据与算力的投入产出边界",{"2":{"33":1}}],["模型与架构",{"2":{"33":1}}],["模型改造",{"2":{"33":1}}],["多采用仅解码器",{"2":{"124":1}}],["多高算力才能充分发挥",{"2":{"110":1}}],["多想一会儿",{"2":{"94":1}}],["多角度思考",{"2":{"88":1}}],["多步骤推理",{"2":{"88":1}}],["多步骤工作流",{"0":{"84":1}}],["多找一些线索",{"2":{"88":1}}],["多个用户问题批处理",{"2":{"81":1}}],["多路复用",{"2":{"65":1}}],["多候选投票",{"2":{"65":1}}],["多机并行",{"2":{"65":1}}],["多机与量化与编译优化与推测式解码",{"2":{"33":1}}],["多对比不同提示的效果",{"2":{"64":1}}],["多目标权衡",{"2":{"57":1}}],["多目标选择",{"2":{"54":1}}],["多奖励集成",{"2":{"57":1}}],["多维打分",{"2":{"57":1}}],["多样化的提示或模型输出能带来更稳健的结果",{"2":{"72":1}}],["多样化采样",{"2":{"57":1,"65":1}}],["多样覆盖",{"2":{"57":1}}],["多样本",{"2":{"54":1}}],["多样性",{"2":{"33":1}}],["多任务",{"2":{"41":1}}],["多条思路采样",{"2":{"33":1}}],["多例",{"2":{"33":1}}],["多少钱配多大模型更划算",{"2":{"33":1}}],["多卡多机协同把大模型拆着训",{"2":{"33":1}}],["多语与跨域",{"2":{"40":1}}],["多语与跨语迁移",{"2":{"33":1}}],["多语言",{"2":{"33":1,"40":1}}],["多语",{"2":{"33":1,"40":1}}],["张量并行等",{"2":{"124":1}}],["张量并行可以很有效地减小单卡显存占用",{"2":{"107":1}}],["张量并行把每层内部的矩阵拆分到多",{"2":{"81":1}}],["张量并行",{"2":{"33":3,"65":1,"107":1}}],["自然很慢",{"2":{"114":1}}],["自然更快",{"2":{"81":1}}],["自举数据",{"2":{"90":1}}],["自举生成",{"2":{"57":1}}],["自助来获取额外偏好数据",{"2":{"90":1}}],["自己提出对抗性问题检验自己",{"2":{"90":1}}],["自己来提出候选提示",{"2":{"80":1}}],["自检纠错",{"2":{"88":1}}],["自造数据",{"2":{"75":1}}],["自我评估改进",{"2":{"87":1}}],["自我优化利用模型本身进行结果改进",{"2":{"72":1}}],["自我优化",{"2":{"72":3}}],["自我反思",{"2":{"54":1}}],["自我反思与集成",{"2":{"33":1}}],["自娱自乐",{"2":{"71":1}}],["自生成指令",{"2":{"57":1}}],["自注意力",{"2":{"41":1}}],["自回归语言模型",{"2":{"99":1}}],["自回归",{"2":{"41":1}}],["自回归预训练",{"2":{"33":1}}],["自监督预训练任务",{"0":{"71":1},"1":{"79":1,"86":1,"93":1,"99":1}}],["自监督预训练",{"2":{"53":1}}],["自监督预训练是一种介于两者之间的方法",{"2":{"53":1}}],["自监督让我们利用海量原始文本",{"2":{"53":1}}],["自监督",{"2":{"40":1}}],["自监督学习",{"2":{"34":1}}],["自洽投票",{"2":{"54":1}}],["自洽",{"2":{"33":1}}],["自动数据",{"2":{"90":1}}],["自动生成偏好数据",{"2":{"90":2}}],["自动找到了一个奇怪但有效的短语作为指令",{"2":{"80":1}}],["自动偏好数据",{"2":{"57":1}}],["自动搜索",{"2":{"54":1}}],["自动提示设计利用算法寻找最优提示",{"2":{"80":1}}],["自动提示设计",{"2":{"80":1}}],["自动提示优化是否有可能找到人类意想不到但对模型有效的提示",{"2":{"80":1}}],["自动提示优化",{"2":{"33":1}}],["自动提示与软提示与压缩",{"2":{"33":1}}],["自动提示与软提示与提示压缩",{"2":{"33":1}}],["自动化的数据",{"2":{"96":1}}],["自动化机器学习",{"2":{"80":1}}],["自动化",{"2":{"33":1}}],["自动化复杂的工作流程",{"2":{"9":1}}],["支持多种云平台部署",{"2":{"108":1}}],["支持长文本不迷路",{"2":{"33":1}}],["支持移动端访问",{"2":{"29":1}}],["插值支持长上下文",{"2":{"33":1}}],["插值",{"2":{"33":2}}],["插件市场",{"2":{"128":1}}],["插件配置管理",{"0":{"91":1}}],["插件和有浏览功能的模型就是将这种理念付诸实践的例子",{"2":{"72":1}}],["插件应该能够相互组合使用",{"2":{"59":1}}],["插件架构",{"0":{"43":1}}],["插件开发完全指南",{"2":{"26":1}}],["插件",{"2":{"26":1}}],["长对话上下文让聊天机器人记住先前细节",{"2":{"122":1}}],["长文问答中发挥作用",{"2":{"116":1}}],["长文本拼接与窗口管理",{"2":{"33":1}}],["长时记忆",{"2":{"116":1}}],["长时间序列数据等",{"2":{"112":1}}],["长篇对话",{"2":{"112":1}}],["长训",{"2":{"40":1}}],["长度用于文档摘要等任务",{"2":{"114":1}}],["长度分组",{"2":{"65":1}}],["长度分组与左填充平衡吞吐与时延",{"2":{"33":1}}],["长度正则",{"2":{"65":1}}],["长度限制",{"2":{"54":1}}],["长度",{"2":{"40":1,"114":1,"120":2}}],["长序列能力",{"2":{"33":1}}],["长序列与记忆",{"2":{"33":1}}],["长序列建模是让",{"2":{"122":1}}],["长序列建模",{"0":{"112":1},"1":{"114":1,"116":1,"118":1,"120":1,"122":1},"2":{"33":1,"34":1}}],["长期有耐心",{"2":{"21":1}}],["分段处理",{"2":{"122":1}}],["分段位置编码",{"2":{"120":1}}],["分块处理",{"2":{"114":1}}],["分析csv文件并生成报告",{"2":{"113":1}}],["分钟效果就有限了",{"2":{"110":1}}],["分钟耐力提升明显",{"2":{"110":1}}],["分钟才能都回复",{"2":{"81":1}}],["分步骤提问",{"2":{"89":1}}],["分步推理",{"2":{"72":1}}],["分布偏置",{"2":{"57":1}}],["分布式带来的复杂度很高",{"2":{"107":1}}],["分布式链路追踪",{"0":{"98":1}}],["分布式训练就是这",{"2":{"107":1}}],["分布式训练是让",{"2":{"107":1}}],["分布式训练的核心思想是将工作并行化",{"2":{"107":1}}],["分布式训练",{"0":{"107":1},"2":{"33":1,"95":1}}],["分布式与工程化相关内容",{"2":{"10":1}}],["分类整理等等",{"2":{"100":1}}],["分类",{"2":{"40":1}}],["分类头",{"2":{"40":1}}],["分词",{"2":{"40":1,"100":1}}],["分词与长度分布",{"2":{"33":2}}],["分解",{"2":{"33":1}}],["原始论文中采用的是后置",{"2":{"104":1}}],["原因是错过生日聚会",{"2":{"89":1}}],["原因是如果模型知道了答案",{"2":{"79":1}}],["原本一句长指令",{"2":{"80":1}}],["原先",{"2":{"75":1}}],["原料配比决定模型口味",{"2":{"33":1}}],["原创技术内容",{"2":{"29":1}}],["领域微调",{"2":{"74":1}}],["领域依旧扮演着重要角色",{"2":{"74":1}}],["领域",{"2":{"33":1}}],["领域的内容与子栏目",{"2":{"3":1}}],["泛化与稳健",{"2":{"33":1}}],["优秀的插件不仅仅是代码",{"2":{"130":1}}],["优秀博主",{"0":{"5":1},"1":{"8":1,"12":1,"17":1}}],["优于回答",{"2":{"83":1}}],["优先级队列",{"2":{"65":1}}],["优雅处理api限制和网络错误",{"2":{"59":1}}],["优化法则",{"2":{"110":1}}],["优化器将优化器状态分散到各卡",{"2":{"107":1}}],["优化器状态分片等具体技术",{"2":{"107":1}}],["优化过程中的技巧非常重要",{"2":{"66":1}}],["优化策略",{"2":{"33":1}}],["优化",{"2":{"33":1,"40":1,"41":1,"114":1}}],["概念",{"2":{"33":1,"41":1,"120":1}}],["概要图",{"0":{"33":1},"2":{"34":1}}],["全栈应用",{"2":{"108":1}}],["全量",{"2":{"40":1,"41":1}}],["全景",{"2":{"33":1}}],["全大写",{"2":{"32":1}}],["8k",{"2":{"112":1,"114":1,"120":1}}],["8000",{"2":{"105":2}}],["80",{"2":{"85":1}}],["8080",{"2":{"77":1,"85":1}}],["8gb",{"2":{"81":1}}],["8",{"2":{"32":1,"81":2,"100":1,"107":2}}],["大数据预训练通用模型",{"2":{"124":1}}],["大家更倾向不惜参数直推性能",{"2":{"118":1}}],["大家流水作业",{"2":{"107":1}}],["大幅增大了模型参数",{"2":{"110":1}}],["大脑助推",{"2":{"88":1}}],["大脑蓄力",{"2":{"73":1}}],["大多数人都能猜出",{"2":{"86":1}}],["大量工程上的改进",{"2":{"124":1}}],["大量用户在早期对话中点哪个回复好",{"2":{"83":1}}],["大量迭代",{"2":{"66":1}}],["大大提升了体验",{"2":{"81":1}}],["大显身手",{"2":{"73":1}}],["大语言模型的推理",{"2":{"73":1}}],["大语言模型的预训练主要是通过自监督任务来完成的",{"2":{"71":1}}],["大语言模型简介",{"0":{"48":1},"1":{"56":1,"66":1,"74":1,"82":1,"89":1}}],["大型模型往往结合两种手段",{"2":{"109":1}}],["大型",{"2":{"48":1}}],["大型语言模型可以基于上述任何一种架构预训练",{"2":{"99":1}}],["大型语言模型往往先预训练",{"2":{"63":1}}],["大型语言模型",{"2":{"48":1,"124":1}}],["大小等",{"2":{"74":1}}],["大小",{"2":{"40":1}}],["大规模训练",{"0":{"95":1},"1":{"100":1,"104":1,"107":1,"110":1},"2":{"34":1}}],["大模型时代的",{"2":{"124":1}}],["大模型训练是门",{"2":{"104":1}}],["大模型训练不稳定",{"2":{"33":1}}],["大模型往往可以一模型多用",{"2":{"99":1}}],["大模型在学习小模型的输出",{"2":{"75":1}}],["大模型才真正成为让人放心的智能助手",{"2":{"67":1}}],["大模型可能答非所问甚至",{"2":{"67":1}}],["大模型大多选择前者",{"2":{"56":1}}],["大模型基础知识全景图",{"2":{"34":1}}],["大模型基础",{"0":{"27":1},"1":{"34":1},"2":{"3":1}}],["大写驼峰",{"2":{"32":1}}],["命名规范",{"0":{"32":1}}],["│",{"2":{"31":8}}],["┌─────────────────┐",{"2":{"31":2}}],["2f",{"2":{"125":1}}],["2800",{"2":{"110":1}}],["200",{"2":{"120":1}}],["2000",{"2":{"120":1}}],["2022",{"2":{"110":1}}],["20240229",{"2":{"23":1,"113":1}}],["20的关系来分配训练",{"2":{"110":1}}],["2048",{"2":{"107":1,"112":1,"120":3}}],["2018",{"2":{"103":1}}],["20=30",{"2":{"72":1}}],["20",{"2":{"72":1}}],["2",{"0":{"31":1,"39":1,"43":1,"48":1,"56":1,"61":1,"62":1,"63":1,"66":2,"71":1,"74":1,"79":1,"82":1,"85":1,"86":2,"89":1,"93":1,"95":2,"99":1,"100":2,"102":1,"104":3,"105":1,"107":2,"110":2,"112":1,"114":1,"116":2,"118":1,"120":1,"122":1,"124":1},"1":{"56":1,"66":1,"74":1,"79":1,"82":1,"86":1,"89":1,"93":1,"99":1,"100":2,"104":2,"107":2,"110":2,"114":1,"116":1,"118":1,"120":1,"122":1},"2":{"56":1,"63":1,"66":2,"72":1,"73":1,"74":1,"75":1,"79":1,"80":1,"82":2,"89":1,"100":3,"104":1,"106":1,"107":1,"110":1,"116":1,"120":2,"122":1,"126":1}}],["核心在于准备大量高质量的指令",{"2":{"75":1}}],["核心概念",{"0":{"30":1},"1":{"37":1,"43":1,"50":1,"59":1,"68":1}}],["核心原则",{"0":{"19":1},"1":{"24":1,"31":1,"38":1}}],["访问速度快",{"2":{"29":1}}],["更是解决实际问题的创新方案",{"2":{"130":1}}],["更是干脆不给超长位置限制",{"2":{"120":1}}],["更重要是理解",{"2":{"122":1}}],["更聪明的重要方向",{"2":{"122":1}}],["更实用",{"2":{"122":1}}],["更偏指长距离上下文记忆",{"2":{"116":1}}],["更大模型",{"2":{"110":1}}],["更大的模型+更多训练数据=更好的表现",{"2":{"110":1}}],["更多数据",{"2":{"110":1}}],["更多缓存",{"2":{"81":1}}],["更具泛化性",{"2":{"120":1}}],["更具体的",{"2":{"110":1}}],["更具有奇思妙想的色彩",{"2":{"73":1}}],["更强",{"2":{"104":1}}],["更近一步",{"2":{"104":1}}],["更可靠的系统",{"2":{"96":1}}],["更要教会它做",{"2":{"96":1}}],["更直接的训练",{"2":{"96":1}}],["更准确的奖励",{"2":{"96":1}}],["更省资源",{"2":{"94":1}}],["更好的奖励模型能让",{"2":{"90":1}}],["更好的奖励建模",{"2":{"90":2}}],["更好奖励",{"2":{"57":1}}],["更加听从用户",{"2":{"74":1}}],["更加便利",{"2":{"73":1}}],["更有趣",{"2":{"73":1}}],["更智能",{"2":{"73":1,"80":1}}],["更方便",{"2":{"73":1}}],["更美好",{"2":{"73":2}}],["更随机",{"2":{"73":1}}],["更受欢迎",{"2":{"67":1}}],["更糟的是",{"2":{"67":1}}],["更长思维链",{"2":{"65":1}}],["更宽搜索",{"2":{"65":1}}],["更新库存",{"2":{"61":1}}],["更新频率稳定",{"2":{"29":1}}],["更稳定",{"2":{"104":1}}],["更稳",{"2":{"33":1,"104":1}}],["更高效的代码",{"2":{"20":1}}],["申请方式",{"0":{"36":1}}],["申请要求",{"0":{"29":1}}],["申请友链",{"0":{"22":1},"1":{"29":1,"36":1}}],["维护多个",{"2":{"28":1}}],["贡献代码和文档",{"2":{"28":1}}],["🎥",{"2":{"129":1}}],["🏃",{"2":{"42":1}}],["🎧",{"2":{"42":1}}],["🎵",{"0":{"42":1}}],["🌟",{"0":{"28":1,"127":1},"1":{"128":1,"129":1}}],["🎯",{"0":{"4":1,"9":1,"19":1,"25":1,"59":1,"130":1},"1":{"7":1,"11":1,"16":1,"24":1,"31":1,"32":1,"38":1,"39":1},"2":{"29":1}}],["推测式解码",{"2":{"65":1}}],["推理的标配了",{"2":{"116":1}}],["推理能力的重要手段之一",{"2":{"94":1}}],["推理重排序",{"2":{"90":1}}],["推理阶段的调整",{"2":{"96":1}}],["推理阶段既涉及工程优化",{"2":{"94":1}}],["推理阶段也是有效的",{"2":{"88":1}}],["推理阶段还可以引入额外约束",{"2":{"73":1}}],["推理步数",{"2":{"54":1}}],["推理",{"0":{"55":1,"65":1},"1":{"65":1,"73":2,"81":2,"88":2,"94":2},"2":{"33":1,"34":1,"65":1}}],["推理时扩展的方法会不会也有极限",{"2":{"88":1}}],["推理时扩展的方法可以从多个角度展开",{"2":{"88":1}}],["推理时扩展为",{"2":{"88":1}}],["推理时扩展充分利用了模型在推理阶段的灵活性",{"2":{"88":1}}],["推理时扩展",{"0":{"88":1},"2":{"33":2,"34":1,"65":1,"88":1}}],["推理时对齐的思路使得对齐可以作为后处理来做",{"2":{"90":1}}],["推理时对齐还有扩展",{"2":{"90":1}}],["推理时对齐",{"2":{"33":3,"57":1,"90":2}}],["推理与部署",{"2":{"33":1}}],["推理与效率",{"2":{"33":1}}],["推理与规划",{"2":{"33":1}}],["推理优化等内容",{"2":{"27":1}}],["推荐大家关注",{"2":{"5":1}}],["生活爱好",{"0":{"42":1}}],["生成的",{"2":{"90":1}}],["生成的文本往往最平淡常见",{"2":{"73":1}}],["生成+验证",{"2":{"88":1}}],["生成和验证思维路径",{"2":{"88":1}}],["生成过程中一边计算下一步一边传输之前结果",{"2":{"81":1}}],["生成了",{"2":{"75":1}}],["生成文字的内在流程",{"2":{"73":1}}],["生成新闻概要可能需要稳健",{"2":{"73":1}}],["生成与验证",{"2":{"65":1}}],["生成最终提示的过程",{"2":{"64":1}}],["生成",{"2":{"40":1,"88":1}}],["生成式模型",{"0":{"41":1},"1":{"48":1,"56":1,"66":1,"74":1,"82":1,"89":1,"95":1,"100":1,"104":1,"107":1,"110":1,"112":1,"114":1,"116":1,"118":1,"120":1,"122":1,"124":1},"2":{"34":1,"41":1}}],["生成式模型架构",{"2":{"27":1}}],["生成子问题",{"2":{"33":1}}],["生成多版再挑最优",{"2":{"33":1}}],["生态官方文档",{"2":{"12":1}}],["l",{"2":{"107":1}}],["lt",{"2":{"66":6}}],["llama2",{"2":{"90":1}}],["llama",{"2":{"56":1,"100":2,"104":3,"107":1}}],["llm仍然重要",{"2":{"124":1}}],["llm需要庞大的数据和算力支撑",{"2":{"124":1}}],["llms",{"2":{"94":1}}],["llm",{"0":{"41":1,"66":1,"67":1,"74":1,"89":1},"1":{"48":1,"56":1,"66":1,"74":1,"82":1,"89":1,"95":1,"100":1,"104":1,"107":1,"110":1,"112":1,"114":1,"116":1,"118":1,"120":1,"122":1,"124":1},"2":{"27":1,"33":2,"34":1,"41":2,"48":8,"56":1,"64":5,"66":4,"67":2,"72":3,"73":3,"74":8,"75":2,"80":3,"81":6,"82":6,"83":3,"87":1,"88":3,"89":5,"90":3,"94":1,"95":1,"96":1,"100":5,"104":5,"107":3,"112":1,"114":1,"118":2,"122":1,"124":5}}],["learning",{"2":{"63":1,"83":1}}],["least",{"2":{"33":1}}],["length",{"2":{"52":1}}],["linear",{"2":{"104":2,"120":1}}],["lines",{"2":{"39":1}}],["list",{"2":{"52":3}}],["lm",{"2":{"33":1,"86":2}}],["lambda",{"2":{"108":1}}],["layernorm",{"2":{"104":4,"124":1}}],["layer",{"2":{"104":2}}],["lastletter",{"2":{"33":1}}],["laws",{"2":{"33":3,"110":1}}],["load",{"2":{"119":1}}],["low",{"2":{"114":1}}],["local",{"2":{"114":1}}],["location",{"2":{"23":4}}],["loss",{"2":{"104":1}}],["love",{"2":{"63":2}}],["lora",{"2":{"40":1,"41":1,"74":1}}],["logging",{"2":{"125":3}}],["logger",{"2":{"39":1}}],["logpr",{"2":{"66":1}}],["log",{"2":{"66":1}}],["log⁡pr",{"2":{"66":1}}],["logo",{"2":{"36":1}}],["longnet",{"2":{"114":1}}],["longformer",{"2":{"114":1}}],["long",{"2":{"32":1,"114":1}}],["与其他开发者交流经验",{"2":{"130":1}}],["与其给每个绝对位置一个向量",{"2":{"120":1}}],["与前一章推理时对齐的",{"2":{"88":1}}],["与此同时",{"2":{"87":1}}],["与世界对齐",{"2":{"82":1}}],["与工具使用",{"2":{"72":1}}],["与我们最终想解决的任务",{"2":{"63":1}}],["与我交流",{"2":{"42":1}}],["与微服务架构设计与实践相关的内容",{"2":{"58":1}}],["与claude",{"2":{"43":1}}],["与",{"2":{"26":1,"33":22,"60":1}}],["订单查询统计",{"2":{"24":1}}],["订单状态管理",{"2":{"24":1}}],["订单创建",{"2":{"24":1}}],["o",{"2":{"114":6}}],["opensubtitles",{"2":{"100":1}}],["openjdk",{"2":{"77":1}}],["openai",{"2":{"67":1,"72":1,"74":2,"75":1,"79":1,"82":1,"83":1,"88":1,"90":1,"100":1,"110":1,"114":1,"116":1,"120":1,"122":1}}],["of",{"2":{"72":1,"88":2,"90":2}}],["only",{"2":{"56":1}}],["output",{"2":{"43":1}}],["ok",{"2":{"38":1,"90":1}}],["ordercreatedevent",{"2":{"61":1}}],["ordercontroller",{"2":{"38":1}}],["ordereventhandler",{"2":{"61":1}}],["order>",{"2":{"38":2}}],["orderid",{"2":{"38":3}}],["orderservice",{"2":{"38":2}}],["orders",{"2":{"38":1}}],["order",{"2":{"24":1,"31":2,"38":3}}],["object>",{"2":{"52":1}}],["object",{"2":{"23":1,"37":1}}],["登录",{"2":{"24":1}}],["149",{"2":{"120":1}}],["16k",{"2":{"114":1}}],["16gb",{"2":{"81":1}}],["150",{"2":{"120":2}}],["15",{"2":{"81":1,"103":1}}],["175b",{"2":{"81":1}}],["1750",{"2":{"66":1}}],["101",{"2":{"120":1}}],["10",{"2":{"81":7,"91":1,"110":4,"114":1,"122":1}}],["10000",{"2":{"110":2}}],["1000",{"2":{"81":1,"110":2,"120":1}}],["100",{"2":{"75":1,"81":5,"91":1,"107":1,"120":1}}],["11",{"2":{"77":1}}],["1i−1",{"2":{"66":1}}],["1",{"0":{"24":1,"32":1,"37":1,"46":2,"48":1,"51":1,"52":1,"53":3,"56":2,"63":2,"66":1,"71":1,"74":1,"77":1,"78":1,"79":2,"82":1,"86":1,"89":1,"93":1,"98":1,"99":1,"100":1,"101":1,"103":1,"106":1,"109":1,"114":1},"1":{"53":2,"56":1,"63":2,"66":1,"74":1,"79":1,"82":1,"86":1,"89":1,"93":1,"99":1},"2":{"63":1,"66":1,"72":1,"73":1,"74":1,"80":1,"81":4,"82":1,"89":2,"90":3,"106":1,"107":2,"110":4,"126":1}}],["城市名称",{"2":{"23":1}}],["n+2",{"2":{"120":1}}],["n+1",{"2":{"120":1}}],["none",{"2":{"119":1}}],["not",{"2":{"115":1,"119":1}}],["notion",{"2":{"115":2}}],["norm",{"2":{"104":5}}],["normalization",{"2":{"104":1}}],["nk",{"2":{"114":3}}],["nn×n的注意力简化为n×kn",{"2":{"114":1}}],["n^2",{"2":{"114":2,"116":1}}],["n2",{"2":{"114":4}}],["null",{"2":{"78":2}}],["n候选保留",{"2":{"57":1}}],["nlp",{"0":{"46":1},"1":{"53":1,"63":1},"2":{"46":1,"53":1,"75":1,"93":1,"99":1,"103":1,"106":2,"124":1}}],["nsp",{"2":{"40":1,"103":3}}],["newspan",{"2":{"98":1}}],["new",{"2":{"39":1,"52":2,"62":1,"78":1}}],["newbufferedreader",{"2":{"39":1}}],["n",{"2":{"39":1,"88":2,"90":8,"107":5,"113":1,"114":2,"120":1}}],["name",{"2":{"23":1,"37":1,"51":1,"84":4,"85":1,"102":1,"125":2}}],["npm",{"2":{"18":1}}],["32k",{"2":{"112":1,"120":1}}],["32",{"2":{"81":1}}],["300",{"2":{"91":1}}],["30+30=60",{"2":{"72":1}}],["30",{"2":{"72":1}}],["3",{"0":{"38":1,"50":1,"54":1,"74":1,"93":1,"103":1,"107":1,"108":1,"112":1,"114":1,"116":1,"118":2,"120":1,"122":1},"1":{"59":1,"64":1,"68":1,"72":1,"80":1,"87":1,"114":1,"116":1,"118":1,"120":1,"122":1},"2":{"23":1,"56":2,"64":1,"66":3,"67":2,"74":3,"75":1,"79":3,"80":1,"81":1,"82":1,"89":1,"90":1,"100":2,"104":2,"105":1,"106":1,"107":1,"110":2,"112":1,"113":1,"116":1,"118":1,"126":1}}],["url",{"2":{"115":3}}],["uvicorn",{"2":{"105":1}}],["unittest",{"2":{"119":1}}],["unit",{"2":{"104":2}}],["utf",{"2":{"32":1}}],["usercontroller",{"2":{"98":1}}],["userdto",{"2":{"51":1}}],["users",{"2":{"51":1,"98":1,"102":1}}],["userserviceclient",{"2":{"51":1,"102":1}}],["userservice",{"2":{"32":1,"98":1}}],["userrepository",{"2":{"32":1}}],["userid",{"2":{"32":2,"51":2,"98":3,"102":4}}],["user",{"2":{"23":3,"24":1,"31":2,"32":1,"51":1,"77":1,"85":2,"98":2,"102":4,"113":1}}],["ui",{"2":{"7":1}}],["晴朗",{"2":{"23":1}}],["full",{"2":{"121":1}}],["functools",{"2":{"125":1}}],["functions",{"2":{"108":1}}],["function",{"2":{"84":2}}],["func",{"2":{"84":2,"125":5,"126":2}}],["fp16",{"2":{"104":1}}],["ffn",{"2":{"104":4}}],["factor",{"2":{"126":2}}],["facebook",{"2":{"90":1,"93":1,"118":1}}],["fallbackmethod",{"2":{"102":1}}],["fastapi",{"2":{"11":1}}],["from",{"2":{"77":1,"83":1,"105":1,"119":1,"125":1}}],["food",{"2":{"63":2}}],["for",{"2":{"62":1,"84":1,"126":1}}],["fetch",{"2":{"121":2}}],["feedme",{"2":{"116":1}}],["feedback",{"2":{"83":1}}],["feignclient",{"2":{"51":1}}],["few",{"2":{"33":2,"88":1,"89":1}}],["filter",{"2":{"52":1}}],["file",{"2":{"113":2}}],["files",{"2":{"39":1}}],["filename",{"2":{"39":4}}],["fileprocessor",{"2":{"39":1}}],["fine",{"2":{"63":1}}],["findbyid",{"2":{"32":1,"38":1,"98":1}}],["final",{"2":{"32":1}}],["f",{"2":{"23":1,"84":1,"113":1,"115":2,"125":2}}],["实战案例",{"0":{"111":1},"1":{"113":1,"115":1}}],["实践表明",{"2":{"120":1}}],["实践证明",{"2":{"90":1}}],["实践中",{"2":{"81":1,"88":1}}],["实现上比数据并行复杂",{"2":{"107":1}}],["实现上",{"2":{"88":1}}],["实现了提示的信息压缩和快速调用",{"2":{"80":1}}],["实现了以小搏大",{"2":{"75":1}}],["实现智能缓存机制",{"2":{"68":1}}],["实例互相讨论或投票",{"2":{"88":1}}],["实例",{"2":{"64":1,"67":1,"72":1,"73":1,"75":1,"80":1,"81":1,"83":1,"88":1,"90":1}}],["实际选择哪种",{"2":{"99":1}}],["实际应用时不会出现",{"2":{"86":1}}],["实际的大模型训练往往是上述方法的组合",{"2":{"107":1}}],["实际的大模型",{"2":{"82":1}}],["实际上也",{"2":{"116":1}}],["实际上",{"2":{"116":1}}],["实际上经历了两阶段微调",{"2":{"74":1}}],["实际上是当今预训练的核心",{"2":{"53":1}}],["实际问题",{"2":{"63":1}}],["实际实现中会调用天气api",{"2":{"23":1}}],["实体保护",{"2":{"40":1}}],["实操与优化",{"2":{"33":1}}],["实用技术",{"2":{"21":1}}],["==这些技术结合起来",{"2":{"124":1}}],["==来完成",{"2":{"124":1}}],["==比如",{"2":{"118":1}}],["==比如之前提过的",{"2":{"88":1}}],["==为了扩展上下文长度",{"2":{"124":1}}],["==为了那逐步变小的收益",{"2":{"110":1}}],["==为此",{"2":{"96":1}}],["==缩放定律就是在告诉我们",{"2":{"110":1}}],["==在",{"2":{"110":1}}],["==chinchilla",{"2":{"110":1}}],["==ai",{"2":{"96":1}}],["==本节我们讨论在训练超大模型时的一些工程挑战和解决方案",{"2":{"95":1}}],["==真正让",{"2":{"95":1}}],["==最简单的例子是增大",{"2":{"88":1}}],["==搜索扩展",{"2":{"88":1}}],["==上下文扩展",{"2":{"88":1}}],["==所以",{"2":{"82":1}}],["==对齐是一个持续的过程",{"2":{"82":1}}],["==",{"2":{"78":2,"121":1,"126":1}}],["=i=0∏m​pr",{"2":{"66":1}}],["=∏i=0mpr",{"2":{"66":1}}],["=",{"2":{"23":2,"32":1,"37":1,"38":1,"39":1,"51":1,"52":3,"62":1,"66":2,"78":1,"84":3,"102":1,"104":1,"113":4,"115":2,"119":3,"121":2,"125":3,"126":3}}],["欢迎通过邮件或",{"2":{"42":1}}],["欢迎交流",{"2":{"42":1}}],["欢迎与我们交换友链",{"2":{"22":1}}],["欢迎来到claude插件开发的世界",{"2":{"6":1}}],["工作流",{"2":{"33":1}}],["工程实践",{"2":{"21":1}}],["工具使用和集成联合应用的强大威力",{"2":{"72":1}}],["工具使用与检索增强",{"2":{"33":1}}],["工具调用",{"2":{"54":1}}],["工具函数",{"0":{"37":1}}],["工具编排",{"2":{"33":1}}],["工具与生态相关的内容",{"2":{"26":1}}],["工具",{"2":{"7":1,"33":1,"72":2}}],["前端集成插件",{"2":{"108":1}}],["前端技术",{"0":{"7":1,"8":1}}],["前向传播时",{"2":{"107":1}}],["前置",{"2":{"104":2}}],["前面",{"2":{"89":1}}],["前面提到过",{"2":{"81":1}}],["前提是合理平衡",{"2":{"110":1}}],["前提",{"2":{"64":2}}],["前馈",{"2":{"41":1}}],["前缀向量",{"2":{"54":1}}],["前缀",{"2":{"40":1,"41":1}}],["前缀语言模型",{"2":{"33":1}}],["前缀鍵值注入",{"2":{"33":1}}],["前缀微调",{"2":{"33":1}}],["前沿动态",{"2":{"21":1}}],["这让模型的",{"2":{"120":1}}],["这不管多少行都适用",{"2":{"120":1}}],["这位顾问因为反复阅览可能比一群各看一段的顾问更连贯",{"2":{"118":1}}],["这减少了独立头参数数量",{"2":{"118":1}}],["这减少了参数量",{"2":{"104":1}}],["这解决的是知识获取问题",{"2":{"116":1}}],["这将复杂度降低到近似线性",{"2":{"114":1}}],["这将使模型既训练得好",{"2":{"90":1}}],["这使得生成长段落的时间复杂度从本来平方级",{"2":{"116":1}}],["这使得标准",{"2":{"114":1}}],["这使开发者可以高效地针对不同任务调教同一个基础模型",{"2":{"63":1}}],["这部电影情节紧凑",{"2":{"106":1}}],["这部分内容显示出",{"2":{"81":1}}],["这也解释了为什么许多近年的模型架构看似跟原始",{"2":{"104":1}}],["这也是为什么后期对齐和外部知识补充很重要",{"2":{"100":1}}],["这也是为什么近几年大家追求更大规模的模型",{"2":{"48":1}}],["这么多数据放进模型",{"2":{"100":1}}],["这包括去除乱码",{"2":{"100":1}}],["这包括使用更紧凑的格式",{"2":{"80":1}}],["这说明不是一味堆模型参数就好",{"2":{"110":1}}],["这说明随着模型规模增大和训练策略改进",{"2":{"99":1}}],["这说明模型本身能力够强",{"2":{"90":1}}],["这说明模型已经学到了巴黎和埃菲尔铁塔之间的常识联系",{"2":{"86":1}}],["这说明模型已具备理解指令的大致能力",{"2":{"75":1}}],["这章内容传递的理念是",{"2":{"96":1}}],["这被认为是提升",{"2":{"94":1}}],["这训练了模型既能理解破损文本的大意",{"2":{"93":1}}],["这能引导模型既关注答案对",{"2":{"90":1}}],["这会误导强化学习认为整条解答路径都",{"2":{"90":1}}],["这代表着研究者在寻找更高效稳健的对齐训练方式",{"2":{"90":1}}],["这可看作",{"2":{"88":1}}],["这可能引入一些问题",{"2":{"83":1}}],["这可能是什么疾病",{"2":{"72":1}}],["这本身也是一门学问",{"2":{"88":1}}],["这本质上也是对齐",{"2":{"82":1}}],["这造成训练和使用时的不一致",{"2":{"86":1}}],["这构成了一条人类偏好数据",{"2":{"83":1}}],["这背后可能是什么原理",{"2":{"81":1}}],["这对单个用户来说",{"2":{"81":1}}],["这在学术上有研究",{"2":{"81":1}}],["这在小模型上难以观察",{"2":{"48":1}}],["这比每次都在文本里加一句",{"2":{"80":1}}],["这段参数接在输入之前或之间",{"2":{"80":1}}],["这正是传统所说的",{"2":{"79":1}}],["这属于对齐的哪个方面",{"2":{"75":1}}],["这属于监督信号",{"2":{"53":1}}],["这等于用强模型产出的",{"2":{"75":1}}],["这期间甚至发现",{"2":{"75":1}}],["这句话",{"2":{"75":1}}],["这句话的情感是",{"2":{"63":2,"89":1}}],["这句话的情感是积极",{"2":{"63":1}}],["这方向还在探索",{"2":{"75":1}}],["这听起来反直觉",{"2":{"75":1}}],["这需要训练数据的多样性覆盖尽可能广",{"2":{"75":1}}],["这其实类似传统模型的微调",{"2":{"74":1}}],["这就需要外推",{"2":{"120":1}}],["这就需要结合模型并行",{"2":{"107":1}}],["这就好像披萨店把热门披萨先做好一批",{"2":{"81":1}}],["这就像调教一只鹦鹉学舌",{"2":{"80":1}}],["这就像我们玩",{"2":{"79":1}}],["这就是数据去重重要性的原因",{"2":{"100":1}}],["这就是提示工程的威力所在",{"2":{"89":1}}],["这就是软提示",{"2":{"80":1}}],["这就是为什么我们需要平衡",{"2":{"73":1}}],["这就是无监督方法",{"2":{"53":1}}],["这就偏离常理了",{"2":{"73":1}}],["这展示了大规模并行的威力和必要性",{"2":{"107":1}}],["这展示了指令微调的威力",{"2":{"75":1}}],["这展示了同一个模型在不同解码策略下风格迥异",{"2":{"73":1}}],["这展示了链式思维",{"2":{"72":1}}],["这常通过kv",{"2":{"73":1}}],["这时可以通过提示引导模型去使用一个检索工具",{"2":{"72":1}}],["这时",{"2":{"72":1}}],["这些位置模型没学过",{"2":{"120":1}}],["这些分析有助于决策",{"2":{"110":1}}],["这些定律虽然不精确",{"2":{"110":1}}],["这些定律揭示了模型性能与规模之间的大致关系",{"2":{"110":1}}],["这些改进通常与长序列建模有关",{"2":{"104":1}}],["这些改进组合起来",{"2":{"90":1}}],["这些激活函数对参数量巨大的",{"2":{"104":1}}],["这些归一化策略能缓解梯度在层间传递时的分布变化问题",{"2":{"104":1}}],["这些努力旨在降低对齐的成本与风险",{"2":{"96":1}}],["这些探索解决了",{"2":{"90":1}}],["这些扩展通常以增加计算为代价",{"2":{"88":1}}],["这些例子都说明",{"2":{"81":1}}],["这些例子表明",{"2":{"67":1}}],["这些技巧结合起来",{"2":{"94":1}}],["这些技巧在当前主流大模型",{"2":{"72":1}}],["这些技术相辅相成",{"2":{"81":1}}],["这些都需要通过对齐手段来纠正",{"2":{"82":1}}],["这些都属于工程层面的改进",{"2":{"81":1}}],["这些都有较高概率",{"2":{"73":1}}],["这些方法都不需要改模型参数或重新训练",{"2":{"88":1}}],["这些方法都是让模型",{"2":{"71":1}}],["这些方法使",{"2":{"87":1}}],["这些方法让大模型的使用更加灵活",{"2":{"80":1}}],["这些回答有的由人类写",{"2":{"75":1}}],["这些可以是让人类专家写的问题和答案对",{"2":{"75":1}}],["这些通常结合人类反馈进行强化学习微调",{"2":{"74":1}}],["这些词经常一起出现",{"2":{"53":1}}],["这一思想为后续更大型的",{"2":{"109":1}}],["这一套路后来被无数模型采用",{"2":{"106":1}}],["这一点我们在",{"2":{"74":1}}],["这一步是",{"2":{"82":1}}],["这一步在模型已经能遵循指令的基础上",{"2":{"82":1}}],["这一步让模型学会遵循指令",{"2":{"82":1}}],["这一步几乎就是手把手教模型做题",{"2":{"75":1}}],["这一步模型会把输入通过其",{"2":{"73":1}}],["这一步称为模型的适配或微调",{"2":{"63":1}}],["这一切都是对齐训练让模型学会了遵守人类偏好的规则",{"2":{"67":1}}],["这是另一种形式的长信息处理",{"2":{"122":1}}],["这是科研热点之一",{"2":{"110":1}}],["这是最常见也最简单的并行方式",{"2":{"107":1}}],["这是最保守的策略",{"2":{"73":1}}],["这是近来提出的一种替代",{"2":{"90":1}}],["这是近年来非常重要的一种微调形式",{"2":{"74":1}}],["这是当前对齐大模型的关键方法之一",{"2":{"83":1}}],["这是唯一可行的方法",{"2":{"81":1}}],["这是硬提示",{"2":{"80":1}}],["这是利用机器学习方法",{"2":{"80":1}}],["这是",{"2":{"75":1,"83":1,"103":1}}],["这是个综合问题",{"2":{"72":1}}],["这是一个针对模型参数效率的技巧",{"2":{"118":1}}],["这是一个简单直接的提示",{"2":{"64":1}}],["这是一种更细粒度的模型并行",{"2":{"107":1}}],["这是一种更高级的推理扩展技巧",{"2":{"88":1}}],["这是一种鼓励模型逐步推理的提示策略",{"2":{"72":1}}],["这是非常危险的行为",{"2":{"67":1}}],["这导致训练一次需要巨大的算力和长时间",{"2":{"66":1}}],["这样让新位置的",{"2":{"120":1}}],["这样做相当于用有限的参数反复应用多次",{"2":{"118":1}}],["这样做的好处是",{"2":{"73":1}}],["这样下一个词的计算可以复用前面的内容",{"2":{"116":1}}],["这样全书也能较快了解",{"2":{"114":1}}],["这样可以显著提升零样本任务能力",{"2":{"110":1}}],["这样可以保证不选那些罕见得离谱的词",{"2":{"73":1}}],["这样既解决了模型太大单卡放不下的问题",{"2":{"107":1}}],["这样既高效又经济",{"2":{"74":1}}],["这样每个",{"2":{"107":1}}],["这样",{"2":{"107":1,"120":1}}],["这样的模型可能要数月甚至更久",{"2":{"107":1}}],["这样的模型先对一批指令生成回答",{"2":{"75":1}}],["这样的最新模型",{"2":{"99":1}}],["这样的完整句子",{"2":{"93":1}}],["这样的预训练让模型积累了大量知识",{"2":{"86":1}}],["这样的拒绝被人类标注为正确行为",{"2":{"83":1}}],["这样的故事更可能被评为",{"2":{"83":1}}],["这样的微调使得",{"2":{"74":1}}],["这样模型不关心",{"2":{"120":1}}],["这样模型在处理新段时",{"2":{"116":1}}],["这样模型本身没变",{"2":{"90":1}}],["这样模型会先去",{"2":{"72":1}}],["这样模型更明白任务要求",{"2":{"64":1}}],["这样确保模型生成下一个词时",{"2":{"56":1}}],["这类模型",{"2":{"99":3}}],["这类模型就是我们常说的聊天模型或文本生成",{"2":{"41":1}}],["这类似生活中的",{"2":{"110":1}}],["这类似人类解决难题时会",{"2":{"88":1}}],["这类似我们看侦探小说",{"2":{"81":1}}],["这类似于传统编程中的内存",{"2":{"116":1}}],["这类似于人写完文章后自己修改润色",{"2":{"72":1}}],["这类似于给模型一个",{"2":{"64":1}}],["这类似于在预训练模型基础上",{"2":{"63":1}}],["这种训练驱动模型学会如何将含糟糕信息的输入恢复成正确流畅的句子",{"2":{"93":1}}],["这种和模型互动调教的过程",{"2":{"89":1}}],["这种生成+验证的方法显著提高了解复杂推理问题的准确率",{"2":{"88":1}}],["这种",{"2":{"88":1,"116":1}}],["这种掩码预测过程",{"2":{"86":1}}],["这种任务迫使模型学会理解上下文语义和句法关系",{"2":{"86":1}}],["这种贴心和慎重就是从人类反馈中学来的",{"2":{"83":1}}],["这种自举式方法节省人力又能获得新奇的提示想法",{"2":{"80":1}}],["这种语言模型预训练任务使",{"2":{"79":1}}],["这种架构通过自回归方式生成序列",{"2":{"79":1}}],["这种微调实际上是给模型注入",{"2":{"74":1}}],["这种提示策略将",{"2":{"72":1}}],["这种多数表决往往比只解一次更可靠",{"2":{"72":1}}],["这种方式可以数学上外推",{"2":{"120":1}}],["这种方式不需要人工标注答案",{"2":{"53":1}}],["这种方法试图降低对大量人工标注的需求",{"2":{"90":1}}],["这种方法最快也最确定",{"2":{"73":1}}],["这种方法利用模型的指令遵循能力来迭代提升答案质量",{"2":{"72":1}}],["这种分解提示让模型逐一解决每个方面",{"2":{"72":1}}],["这种逐步推理对于数学",{"2":{"72":1}}],["这种利用上下文示例的做法被称为in",{"2":{"63":1}}],["这种结构没有独立的编码器",{"2":{"56":1}}],["这通过一个上三角的",{"2":{"56":1}}],["这称为自监督学习",{"2":{"53":1}}],["这有点类似有监督地",{"2":{"90":1}}],["这有点类似知识蒸馏",{"2":{"80":1}}],["这有点类似于函数式编程里的使用",{"2":{"63":1}}],["这有点类似于用特定任务直接训练模型",{"2":{"53":1}}],["这有点像",{"2":{"118":1}}],["这有点像人用眼睛既能看清近处细节",{"2":{"114":1}}],["这有点像用弱模型给强模型做教练",{"2":{"90":1}}],["这有点像你提问时提示对方",{"2":{"89":1}}],["这有点像在考试中不会的题时",{"2":{"88":1}}],["这有点像在正式工作前打好基础",{"2":{"46":1}}],["这有点像披萨店同时烤多张披萨",{"2":{"81":1}}],["这有点像知识蒸馏从弱到强的逆向应用",{"2":{"75":1}}],["这有点像走迷宫时一箭多雕",{"2":{"73":1}}],["这有点像把一个大任务拆成几步完成",{"2":{"72":1}}],["这有点像只让学生背几道题却希望他举一反三",{"2":{"66":1}}],["这有点像调味料配比",{"2":{"64":1}}],["这有点像继承已有的类然后改写",{"2":{"63":1}}],["这个方法有限但简单",{"2":{"120":1}}],["这个方法体现了",{"2":{"90":1}}],["这个属于经验性办法",{"2":{"120":1}}],["这个向量被映射成概率分布",{"2":{"106":1}}],["这个例子体现了在推理阶段给予模型",{"2":{"88":1}}],["这个概念和前面提示部分的集成类似",{"2":{"88":1}}],["这个符号只在训练时出现",{"2":{"86":1}}],["这个模型输入一段问答",{"2":{"83":1}}],["这个简单场景体现了对齐的效果",{"2":{"82":1}}],["这个请求不被允许",{"2":{"82":1}}],["这个请求我无法帮助",{"2":{"67":1}}],["这个短语本身对人毫无意义",{"2":{"80":1}}],["这个过程就是对",{"2":{"106":1}}],["这个过程需要额外计算资源",{"2":{"88":1}}],["这个过程反复进行",{"2":{"83":1}}],["这个过程纠正了许多模型不理想的行为",{"2":{"82":1}}],["这个过程是自回归的",{"2":{"73":1}}],["这个过程没有检索数据库里的现成句子",{"2":{"48":1}}],["这个详细的提示为模型提供了角色",{"2":{"64":1}}],["这个周末天气晴朗",{"2":{"64":1}}],["这个博客旨在分享",{"2":{"21":1}}],["这里介绍几项常见且重要的模型结构修改",{"2":{"104":1}}],["这里的规模包括",{"2":{"95":1}}],["这里总结几点提示",{"2":{"89":1}}],["这里包含几个概念",{"2":{"80":1}}],["这里",{"2":{"66":1,"82":1,"93":1}}],["这里每对句子都有明确的参考答案",{"2":{"53":1}}],["这里我们先介绍",{"2":{"41":1}}],["这里汇总",{"2":{"3":1}}],["一条精心设计的提示可以让模型完成复杂任务而无需额外训练",{"2":{"124":1}}],["一条影评",{"2":{"106":1}}],["一般",{"2":{"116":1}}],["一般用",{"2":{"104":1}}],["一字不落全比较",{"2":{"114":1}}],["一字一句顺序写下去",{"2":{"56":1}}],["一是微调参数",{"2":{"109":1}}],["一部分做变换",{"2":{"104":1}}],["一部分控制门",{"2":{"104":1}}],["一路成长为更安全",{"2":{"96":1}}],["一种粗略但长距",{"2":{"114":1}}],["一种精细但短距",{"2":{"114":1}}],["一种简单的模型并行是层并行",{"2":{"107":1}}],["一种简单方式叫n",{"2":{"90":1}}],["一种常见的编码器",{"2":{"93":1}}],["一种做法是针对同一问题设计多种提示",{"2":{"72":1}}],["一台机器读可能很慢",{"2":{"81":1}}],["一方面",{"2":{"80":1}}],["一方面数据量大",{"2":{"66":1}}],["一旦学好",{"2":{"80":1}}],["一旦某步选错",{"2":{"73":1}}],["一开始就选用前置",{"2":{"104":1}}],["一开始可能错很多",{"2":{"79":1}}],["一开始模型很",{"2":{"66":1}}],["一些架构为不同范围的信息设计不同子模型",{"2":{"114":1}}],["一些策略包括",{"2":{"114":1}}],["一些新模型尝试结合多种预训练任务或多种架构的优点",{"2":{"99":1}}],["一些实验显示",{"2":{"90":1}}],["一些开源模型已支持软提示",{"2":{"80":1}}],["一些开源尝试",{"2":{"75":1}}],["一些研究也提出了高效微调方法",{"2":{"74":1}}],["一句话",{"2":{"75":1}}],["一点点触发即可激活",{"2":{"75":1}}],["一个思路是共享参数",{"2":{"118":1}}],["一个解决思路是利用缓存",{"2":{"116":1}}],["一个著名发现是openai",{"2":{"110":1}}],["一个经过巧妙提示的大模型往往能胜任各种任务",{"2":{"89":1}}],["一个具体场景",{"2":{"88":1}}],["一个未对齐模型可能直接给出",{"2":{"83":1}}],["一个未对齐的模型可能给出误导信息",{"2":{"67":1}}],["一个未对齐的模型",{"2":{"67":1}}],["一个不加对齐的模型可能输出有害信息或造成误导",{"2":{"82":1}}],["一个用户的问题很长",{"2":{"81":1}}],["一个实际场景",{"2":{"80":1}}],["一个通用框架包括",{"2":{"80":1}}],["一个结合多种技巧的例子",{"2":{"72":1}}],["一个典型例子是自洽性",{"2":{"72":1}}],["一个商人有",{"2":{"72":1}}],["一个简单的提示模板可能是",{"2":{"64":1}}],["一个标准的仅解码器",{"2":{"56":1}}],["一段话",{"2":{"48":1}}],["一致性检查",{"2":{"65":1}}],["一致",{"2":{"41":1,"65":1}}],["一切才刚刚开始",{"2":{"21":1}}],["一名热爱技术的软件工程师",{"2":{"1":1}}],["帮助我们更好地应用和优化大型语言模型",{"2":{"124":1}}],["帮助理解温度影响",{"2":{"73":1}}],["帮助模型进行推理和分步思考",{"2":{"72":1}}],["帮助它以特定视角回答",{"2":{"64":1}}],["帮助开发者写出更优雅",{"2":{"20":1}}],["帮助团队构建可扩展",{"2":{"14":1}}],["本指南会持续更新",{"2":{"130":1}}],["本指南将带您从零开始",{"2":{"6":1}}],["本章我们探讨了对齐大型语言模型的一系列技术",{"2":{"96":1}}],["本章小结",{"0":{"87":1,"94":1,"96":1}}],["本节介绍几种应对长上下文的技术",{"2":{"112":1}}],["本节介绍几种改进思路",{"2":{"90":1}}],["本节介绍几种针对不同模型架构的自监督预训练方法",{"2":{"71":1}}],["本来需要",{"2":{"81":1}}],["本身来生成变种提示",{"2":{"80":1}}],["本身更强的",{"2":{"75":1}}],["本质上是个文本接续模型",{"2":{"89":1}}],["本质上",{"2":{"75":1}}],["本质是一个有监督学习",{"2":{"75":1}}],["本栏目整理大型语言模型",{"2":{"27":1}}],["本文总结了java开发中的最佳实践",{"2":{"20":1}}],["或许能让模型具备类似无限长记忆的能力",{"2":{"118":1}}],["或许补充询问病人年龄",{"2":{"72":1}}],["或使用现代工具",{"2":{"101":1}}],["或规则",{"2":{"90":1}}],["或给一个简短示例",{"2":{"89":1}}],["或模型推理还不够可靠的情况",{"2":{"88":1}}],["或完形填空",{"2":{"86":1}}],["或不给奖励",{"2":{"83":1}}],["或提醒对方这样做不当",{"2":{"82":1}}],["或者数据超多而模型太小",{"2":{"110":1}}],["或者把句子顺序打乱再重排回来",{"2":{"93":1}}],["或者用",{"2":{"93":1}}],["或者",{"2":{"90":1}}],["或者推理过程不严谨",{"2":{"90":1}}],["或者采用集成多个奖励模型",{"2":{"90":1}}],["或者给出你期待的答案格式提示模型",{"2":{"89":1}}],["或者给几个",{"2":{"89":1}}],["或者使用链式思维提示",{"2":{"89":1}}],["或者直接把两种解答的共同结论作为最终答案",{"2":{"88":1}}],["或者在最后让模型基于自己的多条推理链做一致性判断",{"2":{"88":1}}],["或者在法律文档上微调得到法律助手",{"2":{"74":1}}],["或者逐字比较融合",{"2":{"88":1}}],["或者做些让自己放松的事情",{"2":{"83":1}}],["或者剪掉一些影响小的神经元连接",{"2":{"81":1}}],["或者从现有问答社区中整理",{"2":{"75":1}}],["或者多任务微调等",{"2":{"74":1}}],["或者制作一张流程示意图",{"2":{"72":1}}],["或者借助额外信息",{"2":{"72":1}}],["或把它们合并成一个更全面的摘要",{"2":{"72":1}}],["或对话格式",{"2":{"64":1}}],["或",{"2":{"18":1,"33":2,"40":1,"73":1,"82":1,"86":1,"106":1,"112":1}}],["id",{"2":{"102":1}}],["if",{"2":{"78":2,"115":1,"126":1}}],["i−1i",{"2":{"66":1}}],["ix",{"2":{"66":1}}],["i​",{"2":{"66":2}}],["i=0",{"2":{"66":1}}],["it",{"2":{"63":2}}],["items",{"2":{"62":1}}],["item",{"2":{"52":2,"62":2}}],["i",{"2":{"63":2,"66":4}}],["ioexception",{"2":{"39":2}}],["is",{"2":{"119":1}}],["isnull",{"2":{"113":1}}],["issue",{"2":{"36":2}}],["istio",{"2":{"16":1}}],["icl示例",{"2":{"65":1}}],["icl",{"2":{"33":2}}],["info",{"2":{"125":1}}],["inference",{"0":{"55":1},"1":{"65":1,"73":1,"81":1,"88":1,"94":1},"2":{"34":1,"90":1}}],["interpolation",{"2":{"120":1}}],["interface",{"2":{"43":1,"51":1}}],["instance",{"2":{"78":5}}],["install",{"2":{"18":2,"105":1}}],["instruct",{"2":{"75":1}}],["instruction",{"2":{"75":1}}],["instructgpt",{"2":{"74":1,"75":1}}],["inventoryservice",{"2":{"61":1}}],["in",{"2":{"33":1,"84":1,"119":2,"126":1}}],["input",{"2":{"23":3,"37":1,"43":1,"84":2,"121":1}}],["init",{"2":{"23":1,"84":1,"115":1,"126":1}}],["import",{"2":{"23":1,"119":2,"125":3}}],["环境准备",{"0":{"18":1}}],["safe",{"2":{"126":1}}],["save",{"2":{"121":2}}],["sample",{"2":{"100":1}}],["sampling",{"2":{"73":1}}],["sleep",{"2":{"126":1}}],["slack",{"2":{"115":2}}],["slim",{"2":{"77":1,"105":1}}],["success",{"2":{"121":1}}],["summary",{"2":{"113":1}}],["sum",{"2":{"113":1}}],["superglue",{"2":{"40":1}}],["shape",{"2":{"113":2}}],["shot",{"2":{"33":2,"88":1,"89":1}}],["swiglu",{"2":{"104":2}}],["switched",{"2":{"118":1}}],["switch",{"2":{"33":1}}],["sdist",{"2":{"101":1}}],["sdk",{"2":{"18":1}}],["size",{"2":{"91":1}}],["sparse",{"2":{"114":2}}],["spec",{"2":{"85":1}}],["spring",{"2":{"11":1,"12":2,"16":1}}],["synchronized",{"2":{"78":1}}],["sgd",{"2":{"66":1}}],["s",{"2":{"63":2,"125":1}}],["sb",{"2":{"62":3}}],["softmax",{"2":{"56":1,"106":1}}],["sonnet",{"2":{"23":1,"113":1}}],["sft",{"2":{"33":3,"57":1,"74":1,"75":2,"82":2}}],["scaling",{"2":{"33":3,"110":1}}],["schema",{"2":{"23":1,"37":1}}],["segment",{"2":{"116":3}}],["session",{"2":{"115":2}}],["server",{"2":{"105":1}}],["service",{"2":{"24":2,"31":2,"51":1,"77":1,"85":4,"115":4}}],["setup",{"2":{"101":1}}],["seq2seq",{"2":{"93":1}}],["selector",{"2":{"85":1}}],["self",{"2":{"23":5,"33":1,"72":2,"75":1,"84":6,"88":1,"113":4,"115":4,"119":2,"126":7}}],["search",{"2":{"73":1}}],["sendorderconfirmation",{"2":{"61":1}}],["sentencepiece",{"2":{"40":1}}],["seo友好",{"2":{"29":1}}],["step",{"2":{"84":4,"121":3}}],["steps",{"2":{"84":3}}],["step来细调",{"2":{"74":1}}],["str",{"2":{"125":1}}],["strategyqa",{"2":{"33":1}}],["stringbuilder",{"2":{"62":2}}],["string>",{"2":{"52":2}}],["string",{"2":{"23":1,"32":1,"37":1,"38":1,"39":2,"51":1,"52":2,"62":1,"91":1,"98":1,"102":2}}],["start",{"2":{"125":2}}],["stanford",{"2":{"75":1}}],["stats",{"2":{"113":1}}],["status",{"2":{"38":1,"121":1}}],["static",{"2":{"32":1,"78":2}}],["stack",{"2":{"16":1}}],["kwargs",{"2":{"125":2,"126":2}}],["kn×k",{"2":{"114":1}}],["knn",{"2":{"33":1}}],["kind",{"2":{"85":1}}],["kernel",{"2":{"81":1}}],["key",{"2":{"18":1,"23":2,"91":2,"116":1,"119":2}}],["key=api",{"2":{"23":1}}],["key=",{"2":{"18":1}}],["k=3",{"2":{"73":1}}],["kl约束",{"2":{"57":1}}],["k",{"2":{"33":2,"41":1,"65":1,"73":7,"88":2,"107":1}}],["kv分页",{"2":{"65":1}}],["kv复用",{"2":{"65":1}}],["kv建立",{"2":{"65":1}}],["kv",{"2":{"33":5,"73":1,"81":1}}],["kubernetes",{"2":{"16":1,"17":2,"85":1}}],["kafka",{"2":{"11":1}}],["容器化部署",{"0":{"77":1}}],["容器化",{"2":{"16":1}}],["架构就采用了额外的记忆矩阵",{"2":{"116":1}}],["架构做了",{"2":{"114":1}}],["架构基础上做了许多改进和调整",{"2":{"104":1}}],["架构选择",{"2":{"57":1}}],["架构更简单直接",{"2":{"56":1}}],["架构",{"0":{"56":1},"2":{"41":1,"48":1,"124":1}}],["架构与运维",{"0":{"16":1}}],["架构设计和工程化思考",{"2":{"21":1}}],["架构设计",{"0":{"10":1}}],["rnn",{"2":{"118":1}}],["r",{"2":{"105":1}}],["run",{"2":{"105":1}}],["rl",{"2":{"90":1}}],["rlhf",{"0":{"83":1},"2":{"33":3,"34":1,"41":1,"57":1,"82":2,"83":12,"90":10,"96":2,"124":1}}],["rmsnorm",{"2":{"104":1}}],["rm",{"2":{"83":1}}],["range",{"2":{"126":1}}],["rank",{"2":{"114":1}}],["ranking",{"2":{"88":1}}],["raise",{"2":{"115":1,"125":1,"126":1}}],["rag",{"2":{"72":5,"88":1,"116":1}}],["rag证据",{"2":{"65":1}}],["rag流程",{"2":{"54":1}}],["rabbitmq",{"2":{"11":1}}],["roberta",{"2":{"40":1,"103":1}}],["rope",{"2":{"33":2,"41":1,"104":1,"120":4,"122":1}}],["root",{"2":{"33":4,"40":1,"41":1,"54":1,"57":1,"65":1}}],["role",{"2":{"23":1,"113":1}}],["relative",{"2":{"120":1}}],["relu",{"2":{"104":2}}],["reduce",{"2":{"107":1}}],["redis",{"2":{"11":1}}],["report",{"2":{"113":2}}],["reportedly",{"2":{"66":1}}],["representations",{"2":{"103":1}}],["re",{"2":{"88":1}}],["reinforcement",{"2":{"83":1}}],["retry",{"2":{"126":3}}],["retrieval",{"2":{"72":1}}],["return",{"2":{"23":2,"32":1,"38":2,"39":1,"62":1,"78":1,"84":1,"98":1,"102":2,"113":2,"115":1,"125":2,"126":1}}],["reflection",{"2":{"72":1}}],["registry",{"2":{"43":1}}],["read",{"2":{"113":1}}],["reader",{"2":{"39":2}}],["readfile",{"2":{"39":1}}],["react",{"2":{"7":1,"8":2}}],["reserveitems",{"2":{"61":1}}],["results",{"2":{"121":1}}],["result",{"2":{"52":1,"84":4,"119":3,"121":2,"125":2}}],["resttemplate",{"2":{"102":1}}],["restcontroller",{"2":{"38":1,"98":1}}],["restful",{"2":{"38":1}}],["responsibilities",{"2":{"24":2}}],["responseentity",{"2":{"38":4}}],["response",{"2":{"23":2,"113":2,"115":2}}],["requirements",{"2":{"105":2}}],["required",{"2":{"23":1,"37":1}}],["requests",{"2":{"91":1}}],["requestbody",{"2":{"38":1}}],["requestmapping",{"2":{"38":1}}],["request",{"2":{"23":1,"38":2}}],["meta",{"2":{"100":2,"104":1,"107":1}}],["metadata",{"2":{"85":1}}],["messages=",{"2":{"23":1,"113":1}}],["messages",{"2":{"23":1,"113":1}}],["missing",{"2":{"113":1}}],["mini",{"2":{"107":1}}],["mindmap",{"2":{"33":4,"40":1,"41":1,"54":1,"57":1,"65":1}}],["mid",{"2":{"66":1}}],["m",{"2":{"66":2}}],["manageable",{"2":{"114":1}}],["make",{"2":{"67":1}}],["mask2",{"2":{"93":2}}],["mask1",{"2":{"93":2}}],["mask",{"2":{"53":1,"56":2,"86":10,"93":1,"103":3}}],["map",{"2":{"52":3}}],["max",{"2":{"23":1,"91":1,"113":1}}],["mlm",{"2":{"40":1,"86":3,"103":2}}],["mbert",{"2":{"33":1,"40":1}}],["monitor",{"2":{"125":1}}],["mongodb",{"2":{"11":1}}],["mock",{"2":{"119":2}}],["most",{"2":{"33":1}}],["model=",{"2":{"23":1,"113":1}}],["mysql",{"2":{"11":1}}],["mdn",{"2":{"8":1}}],["gather",{"2":{"107":1}}],["gated",{"2":{"104":1}}],["gaussian",{"2":{"104":1}}],["gradeessay101",{"2":{"80":2}}],["grafana",{"2":{"16":1}}],["greedy",{"2":{"73":1}}],["gelu",{"2":{"124":1}}],["generate",{"2":{"113":2}}],["generation",{"2":{"72":1}}],["geglu",{"2":{"104":1}}],["getforobject",{"2":{"102":1}}],["getuserfallback",{"2":{"102":2}}],["getuser",{"2":{"98":1,"102":1}}],["getuserbyid",{"2":{"32":1,"51":1}}],["getinstance",{"2":{"78":1}}],["getorderitems",{"2":{"61":1}}],["getorder",{"2":{"38":1,"61":1}}],["getmapping",{"2":{"38":1,"51":1,"98":1}}],["get",{"2":{"23":2,"39":1,"98":1,"115":2,"119":1}}],["gpu",{"2":{"66":1,"81":10,"107":20}}],["gpt",{"2":{"41":1,"56":4,"63":2,"66":3,"67":2,"72":3,"74":3,"75":3,"79":7,"81":1,"82":1,"88":2,"90":1,"99":3,"100":2,"104":2,"106":1,"107":1,"109":2,"110":4,"112":2,"116":1,"118":1,"120":3}}],["gt",{"2":{"63":2,"74":2,"75":1,"88":2,"124":2}}],["glue",{"2":{"40":1}}],["gitlab",{"2":{"16":1}}],["github",{"2":{"16":1,"28":1,"35":2,"36":2,"42":1,"100":2,"115":2}}],["gin",{"2":{"11":1}}],["gopher",{"2":{"110":1}}],["google",{"2":{"88":1,"93":1,"103":1,"108":1,"114":1}}],["go",{"2":{"11":1,"12":2}}],["pd",{"2":{"113":1}}],["pytest",{"2":{"119":1}}],["python",{"2":{"11":1,"101":1,"105":1}}],["py",{"2":{"101":1}}],["performance",{"2":{"125":1}}],["performer使用随机特征的方法",{"2":{"114":1}}],["perplexity",{"2":{"110":1}}],["permutation",{"2":{"86":2}}],["penalty",{"2":{"73":1}}],["position",{"2":{"120":1}}],["post",{"2":{"115":1}}],["postmapping",{"2":{"38":1}}],["postgresql",{"2":{"11":1}}],["poetry",{"2":{"101":1}}],["pool",{"2":{"91":1}}],["port",{"2":{"85":1,"105":1}}],["ports",{"2":{"85":1}}],["ppo",{"2":{"83":2,"90":5}}],["ppo更新",{"2":{"57":1}}],["p=0",{"2":{"73":1}}],["p95延迟",{"2":{"65":1}}],["p50延迟",{"2":{"65":1}}],["patch",{"2":{"119":2}}],["path",{"2":{"113":2}}],["paths",{"2":{"39":1}}],["pathvariable",{"2":{"38":1,"51":1,"98":1}}],["palm",{"2":{"104":2}}],["parallelism",{"2":{"81":1}}],["parallelstream",{"2":{"52":1}}],["padding",{"2":{"81":1}}],["pluginerrorhandler",{"2":{"126":1}}],["pluginconfig",{"2":{"119":1}}],["plugins",{"2":{"91":1}}],["plugin",{"2":{"43":1,"91":1,"105":1,"119":4,"121":5}}],["plus",{"2":{"7":1}}],["p",{"2":{"33":2,"41":1,"65":1,"73":5}}],["public",{"2":{"32":2,"38":3,"39":2,"51":1,"61":2,"78":2,"98":2,"102":3}}],["precision",{"2":{"91":1}}],["prefix",{"2":{"80":1}}],["prefill",{"2":{"73":1}}],["print",{"2":{"84":1}}],["private",{"2":{"32":1,"78":2}}],["prm",{"2":{"33":2}}],["pr",{"2":{"28":1,"48":3,"66":5}}],["prod",{"2":{"66":1}}],["prompt",{"2":{"63":1,"73":1,"89":1,"113":2,"124":1}}],["prompting",{"0":{"47":1},"1":{"54":1,"64":1,"72":1,"80":1,"87":1},"2":{"34":1,"63":1}}],["prometheus",{"2":{"16":1}}],["properties",{"2":{"23":1,"37":1}}],["processor",{"2":{"43":1}}],["processingexception",{"2":{"39":1}}],["process",{"2":{"23":1,"121":2}}],["pipeline",{"2":{"107":1}}],["pip",{"2":{"18":1,"105":1}}],["💬",{"2":{"129":1}}],["📈",{"0":{"123":1},"1":{"125":1,"126":1}}],["📬",{"0":{"35":1}}],["📚",{"0":{"30":1},"1":{"37":1,"43":1,"50":1,"59":1,"68":1},"2":{"42":1,"129":1}}],["📱",{"2":{"29":1}}],["🔍",{"0":{"117":1},"1":{"119":1,"121":1},"2":{"29":1}}],["📝",{"0":{"22":1},"1":{"29":1,"36":1},"2":{"129":1}}],["💡",{"0":{"70":1,"111":1},"1":{"78":1,"113":1,"115":1},"2":{"21":1,"36":1,"42":1,"130":1}}],["🛠️",{"2":{"21":1}}],["🔥",{"2":{"21":1}}],["📖",{"0":{"21":1}}],["💼",{"2":{"9":1}}],["🚀",{"0":{"13":1,"45":1,"69":1,"97":1},"1":{"18":1,"23":1,"52":1,"62":1,"77":1,"85":1,"101":1,"105":1,"108":1},"2":{"9":1,"21":1,"29":1,"130":1}}],["📊",{"0":{"68":1,"92":1},"1":{"98":1,"102":1},"2":{"9":1}}],["🔧",{"0":{"44":1,"76":1},"1":{"51":1,"61":1,"84":1,"91":1},"2":{"9":1}}],["👋",{"0":{"1":1},"1":{"4":1,"7":1,"11":1,"16":1,"21":1,"28":1,"35":1,"42":1}}],["您可以",{"2":{"9":1}}],["技术上主要通过有监督微调和人类反馈强化来实现",{"2":{"82":1}}],["技术上",{"2":{"73":1}}],["技术",{"2":{"72":1,"120":1}}],["技术书籍和人文社科",{"2":{"42":1}}],["技术社区活跃贡献者",{"2":{"28":1}}],["技术人的职业发展心得",{"2":{"21":1}}],["技术趋势和新特性解读",{"2":{"21":1}}],["技术权威文档",{"2":{"8":1}}],["技术栈",{"0":{"4":1},"1":{"7":1,"11":1,"16":1}}],["dict",{"2":{"113":2}}],["distilbert",{"2":{"40":1}}],["df",{"2":{"113":5}}],["down",{"2":{"100":1}}],["docker化部署",{"0":{"105":1}}],["docker",{"2":{"16":1,"17":2}}],["docs",{"2":{"8":1}}],["data=none",{"2":{"115":1}}],["dataanalysisplugin",{"2":{"113":1}}],["database",{"2":{"91":1}}],["databricks",{"2":{"75":1}}],["data",{"2":{"84":2,"121":2}}],["davinci",{"2":{"75":1}}],["dropout",{"2":{"40":1}}],["dyck",{"2":{"33":1}}],["dpo",{"2":{"33":3,"41":1,"57":1,"90":5}}],["db",{"2":{"31":2,"91":1}}],["denoising",{"2":{"93":1}}],["dense",{"2":{"80":1}}],["deepmind",{"2":{"88":1,"110":1}}],["decode",{"2":{"73":1}}],["decoder",{"2":{"56":3}}],["delimiter",{"2":{"62":1}}],["describe",{"2":{"113":1}}],["description",{"2":{"23":2,"37":2}}],["design",{"2":{"7":1}}],["default",{"2":{"32":1}}],["def",{"2":{"23":3,"84":3,"113":2,"115":2,"119":2,"121":1,"125":2,"126":2}}],["官方文档",{"2":{"8":4,"12":4,"17":4,"129":1}}],["chinchilla",{"2":{"110":1,"124":1}}],["chain",{"2":{"72":1}}],["chatgpt",{"2":{"64":3,"67":4,"72":5,"74":2,"75":3,"82":3,"83":2,"88":7,"89":1,"116":1}}],["chat",{"2":{"33":1}}],["cmd",{"2":{"105":1}}],["crawl",{"2":{"100":1}}],["created",{"2":{"38":1}}],["createorderrequest",{"2":{"38":1}}],["createorder",{"2":{"38":2}}],["create",{"2":{"23":1,"113":1}}],["c",{"2":{"88":1}}],["call",{"2":{"115":1}}],["calculator",{"2":{"91":1}}],["calculate",{"2":{"37":1}}],["cache",{"2":{"81":1,"91":1,"116":2}}],["capacity",{"2":{"62":1}}],["catch",{"2":{"39":1}}],["csv",{"2":{"113":2}}],["csqa",{"2":{"33":1}}],["css",{"2":{"7":1}}],["coding",{"2":{"130":1}}],["code",{"2":{"33":1}}],["count",{"2":{"126":3}}],["columns",{"2":{"113":2}}],["collectors",{"2":{"39":1,"52":1}}],["collect",{"2":{"39":1,"52":1}}],["copy",{"2":{"77":1,"105":2}}],["combiner",{"2":{"114":1}}],["component",{"2":{"102":1}}],["complex",{"2":{"91":1}}],["common",{"2":{"100":1}}],["com",{"2":{"35":2,"36":1,"115":3}}],["connection",{"2":{"91":2}}],["configuration",{"2":{"119":1}}],["config",{"2":{"91":1,"119":3}}],["configmanager",{"2":{"78":6}}],["const",{"2":{"37":1}}],["consistency",{"2":{"33":1,"72":1,"88":1}}],["context",{"2":{"33":1,"63":1}}],["content",{"2":{"23":1,"113":2}}],["cot提示",{"2":{"65":1}}],["cot",{"2":{"33":1,"72":1}}],["cncf",{"2":{"17":1}}],["cd",{"2":{"16":1}}],["ci",{"2":{"16":2}}],["cls",{"2":{"106":3}}],["clientsession",{"2":{"115":1}}],["client",{"2":{"23":2,"51":1,"113":1}}],["class",{"2":{"23":1,"32":1,"38":1,"39":1,"61":1,"78":2,"84":1,"98":1,"102":2,"113":1,"115":1,"119":1,"126":1}}],["claude支持函数调用",{"2":{"37":1}}],["claude插件社区",{"2":{"128":1}}],["claude插件是扩展claude",{"2":{"9":1}}],["claude插件开发完全指南",{"0":{"6":1},"1":{"9":1,"13":1,"18":1,"23":1,"30":1,"37":1,"43":1,"50":1,"59":1,"68":1,"76":1,"84":1,"91":1,"97":1,"101":1,"105":1,"108":1,"111":1,"113":1,"115":1,"117":1,"119":1,"121":1,"123":1,"125":1,"126":1,"127":1,"128":1,"129":1,"130":1}}],["claude",{"0":{"26":1},"2":{"3":1,"23":1,"26":2,"41":1,"43":1,"56":2,"74":1,"82":2,"89":2,"113":1,"114":1,"116":1,"122":1}}],["cloud",{"2":{"16":1,"108":1}}],["txt",{"2":{"105":2}}],["t5",{"2":{"93":3,"99":2,"109":1,"114":2}}],["ttl",{"2":{"91":1}}],["times",{"2":{"114":2}}],["time",{"2":{"90":1,"125":9,"126":2}}],["tpu",{"2":{"81":1}}],["targetport",{"2":{"85":1}}],["target",{"2":{"77":1}}],["tailwind",{"2":{"7":1}}],["test",{"2":{"119":4,"121":2}}],["testclaudeplugin",{"2":{"119":1}}],["text",{"2":{"93":2}}],["temperature",{"2":{"73":1}}],["tech",{"2":{"35":1}}],["thoughts",{"2":{"88":1}}],["thought",{"2":{"72":1}}],["thetaθ",{"2":{"66":1}}],["the",{"2":{"63":2}}],["throw",{"2":{"39":1}}],["throws",{"2":{"39":1}}],["tuning",{"2":{"63":1,"75":1,"80":1}}],["true",{"2":{"91":1}}],["tree",{"2":{"88":1}}],["try",{"2":{"39":1,"125":1,"126":1}}],["transformers",{"2":{"118":1}}],["transformer",{"0":{"56":1},"2":{"33":1,"41":1,"48":1,"56":6,"73":1,"79":1,"81":2,"104":7,"107":2,"112":1,"114":7,"116":7,"118":5,"120":3,"122":1,"124":1}}],["type",{"2":{"23":2,"37":2}}],["typescript",{"2":{"7":1}}],["tostring",{"2":{"62":1}}],["tolist",{"2":{"52":1,"113":1}}],["touppercase",{"2":{"52":1}}],["tool",{"2":{"43":1}}],["tools",{"0":{"37":1},"2":{"37":1}}],["tools=",{"2":{"23":1}}],["tokens=2000",{"2":{"113":1}}],["tokens=1000",{"2":{"23":1}}],["tokens",{"2":{"110":1}}],["token",{"2":{"33":2,"73":1,"81":1,"110":3,"112":1,"114":2,"120":1,"122":1}}],["to",{"2":{"33":1,"67":1,"93":1,"113":2}}],["top",{"2":{"33":4,"41":2,"65":2,"73":4}}],["exception",{"2":{"125":1,"126":1}}],["except",{"2":{"125":1,"126":1}}],["execution",{"2":{"125":2}}],["execute",{"2":{"84":1,"121":1,"126":1}}],["extrapolation",{"2":{"120":1}}],["expose",{"2":{"77":1,"105":1}}],["export",{"2":{"18":1}}],["expectedsize",{"2":{"52":2}}],["expression",{"2":{"37":2}}],["endpoint",{"2":{"115":2}}],["endpoints",{"2":{"115":2}}],["encoder",{"2":{"103":1}}],["encoding",{"2":{"32":1}}],["entrypoint",{"2":{"77":1}}],["ensemble",{"2":{"72":1}}],["event",{"2":{"61":3}}],["eventlistener",{"2":{"61":1}}],["embedding",{"2":{"80":1,"120":2}}],["embeddings",{"2":{"53":1}}],["emailservice",{"2":{"61":1}}],["email",{"2":{"35":1}}],["error",{"2":{"39":1,"43":1,"104":1,"125":1}}],["e",{"2":{"39":3,"125":2,"126":1}}],["elk",{"2":{"16":1}}],["element",{"2":{"7":1}}],["eslint",{"2":{"7":1}}],["value",{"2":{"116":1}}],["valueerror",{"2":{"115":1}}],["values",{"2":{"113":1}}],["vercel",{"2":{"108":1}}],["volatile",{"2":{"78":1}}],["void",{"2":{"61":1}}],["vs",{"2":{"73":1,"88":1,"90":2,"114":1,"118":1}}],["v1",{"2":{"38":1,"51":1,"85":1,"115":1}}],["vite",{"2":{"7":1}}],["vue",{"2":{"7":1,"8":2}}],["jar",{"2":{"77":4}}],["java开发最佳实践",{"0":{"20":1},"1":{"25":1,"32":1,"39":1,"45":1,"52":1,"62":1,"70":1,"78":1}}],["java",{"0":{"60":1},"2":{"11":1,"12":2,"15":1,"60":2,"63":1,"77":1}}],["javascript",{"2":{"7":1}}],["jre",{"2":{"77":1}}],["joining",{"2":{"39":1}}],["jenkins",{"2":{"16":1}}],["json=data",{"2":{"115":1}}],["json",{"2":{"89":3,"115":1}}],["js",{"2":{"7":1,"8":2}}],["框架",{"2":{"7":1,"11":1,"65":1}}],["🤝",{"0":{"5":1},"1":{"8":1,"12":1,"17":1}}],["attempt",{"2":{"126":3}}],["attention",{"2":{"114":3,"120":1}}],["aws",{"2":{"108":1}}],["await",{"2":{"84":1,"115":1,"121":1,"125":1,"126":2}}],["add",{"2":{"84":1,"121":3}}],["autoencoder",{"2":{"93":1}}],["automl",{"2":{"80":1}}],["augmented",{"2":{"72":1}}],["albert",{"2":{"118":1}}],["all",{"2":{"107":1}}],["allow",{"2":{"91":1}}],["alpaca",{"2":{"75":1}}],["alignment",{"0":{"49":1},"1":{"57":1,"67":1,"75":1,"83":1,"90":1,"96":1},"2":{"34":1,"82":1,"90":1}}],["alibi",{"2":{"33":3,"41":1,"104":1,"120":1}}],["a",{"2":{"64":2,"67":1,"83":1,"88":2,"90":1,"103":2}}],["amazing",{"2":{"63":2}}],["assert",{"2":{"119":3,"121":1}}],["as",{"2":{"115":2,"125":1,"126":1}}],["asic",{"2":{"81":1}}],["asyncio",{"2":{"126":1}}],["async",{"2":{"61":1,"84":1,"115":3,"121":1,"125":1,"126":1}}],["asxing",{"0":{"1":1},"1":{"4":1,"7":1,"11":1,"16":1,"21":1,"28":1,"35":1,"42":1},"2":{"35":1}}],["args",{"2":{"125":2,"126":2}}],["arraylist",{"2":{"52":1}}],["architecture",{"2":{"43":1}}],["agent",{"2":{"33":1}}],["approximation",{"2":{"114":1}}],["app",{"2":{"77":2,"85":1,"105":2}}],["append",{"2":{"62":2,"84":1}}],["apiintegrationplugin",{"2":{"115":1}}],["api集成插件",{"0":{"115":1}}],["apiversion",{"2":{"85":1}}],["api交互",{"2":{"43":1}}],["api设计",{"0":{"38":1},"2":{"38":1}}],["api",{"2":{"18":2,"23":2,"38":1,"51":1,"81":1,"91":2,"115":4,"119":1}}],["apache",{"2":{"11":1}}],["actions",{"2":{"16":1}}],["analysis",{"2":{"113":4}}],["analyze",{"2":{"113":1}}],["anthropic",{"2":{"18":3,"23":3,"41":1,"74":1,"82":1,"90":1,"114":1,"116":1,"119":3,"122":1}}],["ant",{"2":{"7":1}}],["angular",{"2":{"7":1}}],["aiohttp",{"2":{"115":1}}],["ai能力的强大工具",{"2":{"9":1}}],["ai",{"2":{"3":1,"18":1,"41":1,"67":3,"73":1,"75":3,"81":2,"82":2,"83":1,"90":3,"96":4,"110":1,"122":2}}],["ai技术",{"0":{"3":1}}]],"serializationVersion":2}';export{t as default};
